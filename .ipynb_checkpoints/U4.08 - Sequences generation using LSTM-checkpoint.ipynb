{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling\n",
    "\n",
    "A recurrence Neural Network can be used as a Generative model once it was trained. Currently this is a common practice not only to study how well a model has learned a problem, but to learn more about the problem domain itself. In fact, this approach is being used for music generation and composition.\n",
    "\n",
    "The process of generation is explained in the picture below:\n",
    "\n",
    "<img src=\"Images/dinos3.png\" style=\"width:500;height:300px;\">\n",
    "<caption><center> **Figure **: In this picture, we assume the model is already trained. We pass in $x^{\\langle 1\\rangle} = \\vec{0}$ at the first time step, and have the network then sample one character at a time. </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Masking\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /home/julian/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "raw_text = nltk.corpus.gutenberg.raw('bible-kjv.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to traing a LSTM network using some passges from the bible, and we are going to use the trained netwrok to generate new \"Gospels\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Genesis\\n\\n\\n1:1 In the beginning God created the heaven and the earth.\\n\\n1:2 And the earth was without form, and void; and darkness was upon\\nthe face of the deep. And the Spirit of God moved upon the face of the\\nwaters.\\n\\n1:3 And God said, Let there be light: and there was light.\\n\\n1:4 And God saw the light, that it was good: and God divided the light\\nfrom the darkness.\\n\\n1:5 And God called the light Day, and the darkness he called Night.\\nAnd the evening and the morning were the first day.\\n\\n1:6 And God said, Let there be a firmament in the midst of the waters,\\nand let it divide the waters from the waters.\\n\\n1:7 And God made the firmament, and divided the waters which were\\nunder the firmament from the waters which were above the firmament:\\nand it was so.\\n\\n1:8 And God called the firmament Heaven. And the evening and the\\nmorning were the second day.\\n\\n1:9 And God said, Let the waters under the heav'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text[100:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'\\n': 0,\n",
       " u' ': 1,\n",
       " u'!': 2,\n",
       " u\"'\": 3,\n",
       " u'(': 4,\n",
       " u')': 5,\n",
       " u',': 6,\n",
       " u'-': 7,\n",
       " u'.': 8,\n",
       " u'0': 9,\n",
       " u'1': 10,\n",
       " u'2': 11,\n",
       " u'3': 12,\n",
       " u'4': 13,\n",
       " u'5': 14,\n",
       " u'6': 15,\n",
       " u'7': 16,\n",
       " u'8': 17,\n",
       " u'9': 18,\n",
       " u':': 19,\n",
       " u';': 20,\n",
       " u'?': 21,\n",
       " u'A': 22,\n",
       " u'B': 23,\n",
       " u'C': 24,\n",
       " u'D': 25,\n",
       " u'E': 26,\n",
       " u'F': 27,\n",
       " u'G': 28,\n",
       " u'H': 29,\n",
       " u'I': 30,\n",
       " u'J': 31,\n",
       " u'K': 32,\n",
       " u'L': 33,\n",
       " u'M': 34,\n",
       " u'N': 35,\n",
       " u'O': 36,\n",
       " u'P': 37,\n",
       " u'Q': 38,\n",
       " u'R': 39,\n",
       " u'S': 40,\n",
       " u'T': 41,\n",
       " u'U': 42,\n",
       " u'V': 43,\n",
       " u'W': 44,\n",
       " u'Y': 45,\n",
       " u'Z': 46,\n",
       " u'[': 47,\n",
       " u']': 48,\n",
       " u'a': 49,\n",
       " u'b': 50,\n",
       " u'c': 51,\n",
       " u'd': 52,\n",
       " u'e': 53,\n",
       " u'f': 54,\n",
       " u'g': 55,\n",
       " u'h': 56,\n",
       " u'i': 57,\n",
       " u'j': 58,\n",
       " u'k': 59,\n",
       " u'l': 60,\n",
       " u'm': 61,\n",
       " u'n': 62,\n",
       " u'o': 63,\n",
       " u'p': 64,\n",
       " u'q': 65,\n",
       " u'r': 66,\n",
       " u's': 67,\n",
       " u't': 68,\n",
       " u'u': 69,\n",
       " u'v': 70,\n",
       " u'w': 71,\n",
       " u'x': 72,\n",
       " u'y': 73,\n",
       " u'z': 74}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  4332554\n",
      "Total Vocab:  75\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print \"Total Characters: \", n_chars\n",
    "print \"Total Vocab: \", n_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model we are going to use sequences of 100 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  4332454\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print \"Total Patterns: \", n_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4332454, 100, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the data set is to large, we are going to use only the firs 200000 sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:200000,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[:200000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the entire dataset is used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "200000/200000 [==============================] - 522s 3ms/step - loss: 2.8729\n",
      "Epoch 2/20\n",
      "200000/200000 [==============================] - 553s 3ms/step - loss: 2.5480\n",
      "Epoch 3/20\n",
      "200000/200000 [==============================] - 581s 3ms/step - loss: 2.4234\n",
      "Epoch 4/20\n",
      "200000/200000 [==============================] - 582s 3ms/step - loss: 2.3348\n",
      "Epoch 5/20\n",
      "200000/200000 [==============================] - 544s 3ms/step - loss: 2.2630\n",
      "Epoch 6/20\n",
      "200000/200000 [==============================] - 566s 3ms/step - loss: 2.2026\n",
      "Epoch 7/20\n",
      "200000/200000 [==============================] - 551s 3ms/step - loss: 2.1519\n",
      "Epoch 8/20\n",
      "200000/200000 [==============================] - 549s 3ms/step - loss: 2.1066\n",
      "Epoch 9/20\n",
      "200000/200000 [==============================] - 544s 3ms/step - loss: 2.0620\n",
      "Epoch 10/20\n",
      "200000/200000 [==============================] - 552s 3ms/step - loss: 2.0222\n",
      "Epoch 11/20\n",
      "200000/200000 [==============================] - 542s 3ms/step - loss: 1.9862\n",
      "Epoch 12/20\n",
      "200000/200000 [==============================] - 555s 3ms/step - loss: 1.9538\n",
      "Epoch 13/20\n",
      "200000/200000 [==============================] - 557s 3ms/step - loss: 1.9219\n",
      "Epoch 14/20\n",
      "200000/200000 [==============================] - 556s 3ms/step - loss: 1.8940\n",
      "Epoch 15/20\n",
      "200000/200000 [==============================] - 545s 3ms/step - loss: 1.8649\n",
      "Epoch 16/20\n",
      "200000/200000 [==============================] - 530s 3ms/step - loss: 1.8412\n",
      "Epoch 17/20\n",
      "200000/200000 [==============================] - 532s 3ms/step - loss: 1.8178\n",
      "Epoch 18/20\n",
      "200000/200000 [==============================] - 529s 3ms/step - loss: 1.7936\n",
      "Epoch 19/20\n",
      "200000/200000 [==============================] - 531s 3ms/step - loss: 1.7730\n",
      "Epoch 20/20\n",
      "200000/200000 [==============================] - 529s 3ms/step - loss: 1.7541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f47bb728390>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" that man whom he hath ordained; whereof he hath given assurance\n",
      "unto all men, in that he hath raised \"\n",
      " and thet \n",
      "\n",
      "4:1 And the LORD Gad said unto him, Th thall be the lat of the erounn  and tooo the sanens of the land of the land of the eroued.\n",
      "\n",
      "1:: And the LORD said unto him, We taadl the lan whth the sooee, and thet thol shll thte the sooee of the land of the eroued.\n",
      "\n",
      "1:: And the LORD said unto him, We taadl the lan whth the sooee, and thet thol shll thte the sooee of the land of the eroued.\n",
      "\n",
      "1:: And the LORD said unto him, We taadl the lan whth the sooee, and thet thol shll thte the sooee of the land of the eroued.\n",
      "\n",
      "1:: And the LORD said unto him, We taadl the lan whth the sooee, and thet thol shll thte the sooee of the land of the eroued.\n",
      "\n",
      "1:: And the LORD said unto him, We taadl the lan whth the sooee, and thet thol shll thte the sooee of the land of the eroued.\n",
      "\n",
      "1:: And the LORD said unto him, We taadl the lan whth the sooee, and thet thol shll thte the sooee of the land of the eroued.\n",
      "\n",
      "1:: And the LORD said unto him, We taadl the lan whth the sooee, and thet thol shll thte the so\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print \"Seed:\"\n",
    "print \"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\"\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print \"\\nDone.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"models/modelgen.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"models/modelgen.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n",
    "# later...\n",
    " \n",
    "# load json and create model\n",
    "#json_file = open('models/modelgen.json', 'r')\n",
    "#loaded_model_json = json_file.read()\n",
    "#json_file.close()\n",
    "#loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "#loaded_model.load_weights(\"models/modelgen.h5\")\n",
    "#print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(4)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print \"Seed:\"\n",
    "print \"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\"\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print \"\\nDone.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
