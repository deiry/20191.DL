{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import io, transform\n",
    "from skimage.io import imread\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "import time\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \n",
    "img = imread()\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.2406 - val_loss: 0.1981\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 60s 1ms/step - loss: 0.1784 - val_loss: 0.1639\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 60s 999us/step - loss: 0.1627 - val_loss: 0.1558\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 60s 1ms/step - loss: 0.1548 - val_loss: 0.1534\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 60s 992us/step - loss: 0.1497 - val_loss: 0.1450\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 59s 989us/step - loss: 0.1460 - val_loss: 0.1412\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 59s 986us/step - loss: 0.1432 - val_loss: 0.1419\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 59s 990us/step - loss: 0.1410 - val_loss: 0.1481\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 60s 993us/step - loss: 0.1388 - val_loss: 0.1357\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 59s 992us/step - loss: 0.1370 - val_loss: 0.1328\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 59s 991us/step - loss: 0.1358 - val_loss: 0.1353\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 60s 993us/step - loss: 0.1345 - val_loss: 0.1312\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 60s 992us/step - loss: 0.1332 - val_loss: 0.1304\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 60s 994us/step - loss: 0.1323 - val_loss: 0.1313\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 60s 993us/step - loss: 0.1314 - val_loss: 0.1302\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 60s 993us/step - loss: 0.1304 - val_loss: 0.1327\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 60s 992us/step - loss: 0.1299 - val_loss: 0.1287\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 60s 993us/step - loss: 0.1295 - val_loss: 0.1269\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 60s 993us/step - loss: 0.1290 - val_loss: 0.1307\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 60s 993us/step - loss: 0.1286 - val_loss: 0.1253\n"
     ]
    }
   ],
   "source": [
    "def train_model():\n",
    "    input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same', name='encoder')(x)\n",
    "\n",
    "    # at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "    autoencoder.fit(x_train_noisy, x_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(x_test_noisy, x_test),\n",
    "                    callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False)])\n",
    "\n",
    "    autoencoder.save('autoencoder.h5')\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mnist dataset\n",
      "('mnist dataset loaded in: ', 3.654482841491699)\n",
      "Loading model :\n",
      "('Model loaded in: ', 3.463449001312256)\n"
     ]
    }
   ],
   "source": [
    "print('Loading mnist dataset')\n",
    "t0 = time.time()\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "noise_factor = 0.3\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "t1 = time.time()\n",
    "print('mnist dataset loaded in: ', t1-t0)\n",
    "\n",
    "print('Loading model :')\n",
    "t0 = time.time()\n",
    "# Load previously trained autoencoder\n",
    "autoencoder = load_model('autoencoder.h5')\n",
    "t1 = time.time()\n",
    "print('Model loaded in: ', t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_denoised_images():\n",
    "    denoised_images = autoencoder.predict(x_test_noisy.reshape(x_test_noisy.shape[0], x_test_noisy.shape[1], x_test_noisy.shape[2],1))\n",
    "    test_img = x_test_noisy[0]\n",
    "   # plt.figure(figsize=(4,2))\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(311)\n",
    "    plt.imshow(test_img.reshape(28,28), cmap=plt.cm.Greys_r)\n",
    "    plt.axis(\"off\")\n",
    "    #resized_test_img = cv2.resize(test_img, (280, 280))\n",
    "    #cv2.imshow('input', resized_test_img)\n",
    "    #cv2.waitKey(0)\n",
    "    output = denoised_images[0]\n",
    "    #plt.figure(figsize=(4,2))\n",
    "    R= test_img[0]-denoised_images[0] \n",
    "    plt.subplot(312)\n",
    "    plt.imshow( output.reshape(28,28), cmap=plt.cm.Greys_r)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.subplot(313)\n",
    "    plt.imshow( R.reshape(28,28), cmap=plt.cm.Greys_r)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    #resized_output = cv2.resize(output, (280, 280))\n",
    "    #cv2.imshow('output', resized_output)\n",
    "    #cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_denoised_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
