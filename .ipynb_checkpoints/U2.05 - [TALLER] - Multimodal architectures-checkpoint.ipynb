{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension de las imagenes y las clases (1500, 784) (1500,)\n"
     ]
    }
   ],
   "source": [
    "mnist = pd.read_csv(\"data/mnist1.5k.csv.gz\", compression=\"gzip\", header=None).values\n",
    "X=mnist[:,1:785]/255.\n",
    "y=mnist[:,0]\n",
    "print \"dimension de las imagenes y las clases\", X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 784) (300, 10) (1200, 784) (1200, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = X[:300], X[300:], y[:300], y[300:]\n",
    "y_train_oh = np.eye(10)[y_train]\n",
    "y_test_oh  = np.eye(10)[y_test]\n",
    "print X_train.shape, y_train_oh.shape,  X_test.shape, y_test_oh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network architectures lab\n",
    "\n",
    "\n",
    "from the notes we have two architectures:\n",
    "    \n",
    "- **A**: Three layer network accepting a 784 element vector as input and outputing a 10-class vector\n",
    "- **B**: Same as **A** but accepts an additional 2 element vector with _evenness_ information that is injected at the third layer.\n",
    "\n",
    "This lab requires you to do two things:\n",
    "\n",
    "**1**. Create a **C** architecture similar to **B** but where the 2 element vector is injected at the second layer. This will make the network have 41,650 parameters, distributed in the following way:\n",
    "   \n",
    "   \n",
    "\n",
    "        INPUT 1 to LAYER 1:              784*50 + 50 (bias) = 39250\n",
    "        LAYER 1 to LAYER 2:               50*30 + 30 (bias) = 1530\n",
    "        LAYER 2 + INPUT 2 to LAYER 3: (30+2)*20 + 20 (bias) = 660\n",
    "        LAYER 3 to OUTPUT:                20*10 + 10 (bias) = 210\n",
    "    \n",
    "                                                       TOTAL 41650\n",
    "                                                       \n",
    "**2**. Run an experimental setup where you train different network configurations and measure the accuracy on test data. Fix the number of neurons to 50, 30 and 20 for each layer and the following combination of parameters:\n",
    "\n",
    "- For architecture **A** (3 configurations)\n",
    "\n",
    "    `s3_activation` $\\in$ `[\"linear\", \"relu\", \"tanh\"]`\n",
    "\n",
    "- For architectures **B** and **C** (15 configurations for each architecture)\n",
    "\n",
    "    `s3_activation` $\\in$ `[\"linear\", \"relu\", \"tanh\"]`\n",
    "    \n",
    "    `k1,k2` $\\in$ `[(0,1), (-.5,2),(-.5,30), (0,15),(0,30)]`\n",
    "\n",
    "And create a heat map showing the accuracy in test obtained for each configuration, such as the following (your results should be approximate to this):\n",
    "\n",
    "![alt text](./Images/mm_results_1.png)\n",
    "\n",
    "\n",
    "And two bar plots with the average per architecture and k1,k2 configuration, such as the following (again, your results should be approximetely similar):\n",
    "\n",
    "![alt text](./Images/mm_results_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, concatenate, Input\n",
    "from tensorflow.keras.backend import clear_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_A(input_dim, s1, s2, s3, s3_activation=\"relu\"):\n",
    "    clear_session()\n",
    "    model = Sequential()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(s1, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dense(s2, activation='relu'))\n",
    "    model.add(Dense(s3, activation=s3_activation))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    model.reset_states()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_B(input_dim, extra_info_dim,  s1, s2, s3, s3_activation=\"relu\"):\n",
    "    clear_session()\n",
    "    inp1 = Input(shape=(input_dim,))\n",
    "    l11 = Dense(s1, activation=\"relu\")(inp1)\n",
    "    l12 = Dense(s2, activation=\"relu\")(l11)\n",
    "    l13 = Dense(s3, activation=s3_activation)(l12)\n",
    "    \n",
    "    inp2 = Input(shape=(extra_info_dim,))\n",
    "    cc1 = concatenate([l13, inp2],axis=1) # Merge row, same column\n",
    "    output = Dense(10, activation='softmax')(cc1)\n",
    "    model = Model(inputs=[inp1, inp2], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    model.reset_states()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_C(input_dim, extra_info_dim, s1, s2, s3, s3_activation=\"relu\"):\n",
    "    clear_session()\n",
    "    inp2 = Input(shape=(extra_info_dim,))\n",
    "    inp1 = Input(shape=(input_dim,))\n",
    "    l11 = Dense(s1, activation=\"relu\")(inp1)\n",
    "    l12 = Dense(s2, activation=\"relu\")(l11)\n",
    "    cc1 = concatenate([l12, inp2],axis=1) # Merge row, same column\n",
    "    l13 = Dense(s3, activation=s3_activation)(l12)\n",
    "    \n",
    "\n",
    "    output = Dense(10, activation='softmax')(cc1)\n",
    "    model = Model(inputs=[inp1, inp2], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    model.reset_states()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_extra(y_train, y_test, k0, k1):\n",
    "    X_train_extra = (np.eye(2)[y_train%2]+k0)*k1\n",
    "    X_test_extra  = (np.eye(2)[y_test%2]+k0)*k1\n",
    "    return X_train_extra, X_test_extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the following dataframe to record your data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(0, 1)</th>\n",
       "      <th>(-0.5, 2)</th>\n",
       "      <th>(-0.5, 30)</th>\n",
       "      <th>(0, 15)</th>\n",
       "      <th>(0, 30)</th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A-linear</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-relu</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-tanh</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-linear</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-relu</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-tanh</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-linear</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-relu</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-tanh</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          (0, 1)  (-0.5, 2)  (-0.5, 30)  (0, 15)  (0, 30)  None\n",
       "A-linear     NaN        NaN         NaN      NaN      NaN   NaN\n",
       "A-relu       NaN        NaN         NaN      NaN      NaN   NaN\n",
       "A-tanh       NaN        NaN         NaN      NaN      NaN   NaN\n",
       "B-linear     NaN        NaN         NaN      NaN      NaN   NaN\n",
       "B-relu       NaN        NaN         NaN      NaN      NaN   NaN\n",
       "B-tanh       NaN        NaN         NaN      NaN      NaN   NaN\n",
       "C-linear     NaN        NaN         NaN      NaN      NaN   NaN\n",
       "C-relu       NaN        NaN         NaN      NaN      NaN   NaN\n",
       "C-tanh       NaN        NaN         NaN      NaN      NaN   NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_set     = [(0,1), (-.5,2),(-.5,30), (0,15),(0,30), None]\n",
    "act_set   = [\"linear\", \"relu\", \"tanh\"]\n",
    "arch_set  = [\"A\", \"B\", \"C\"]\n",
    "\n",
    "\n",
    "r_test = pd.DataFrame(np.zeros((len(arch_set)*len(act_set), len(k_set)))*np.nan, \n",
    "                      index=[[a+\"-\"+b for a,b in itertools.product (arch_set, act_set)]],\n",
    "                      columns=[str(i) for i in k_set])\n",
    "r_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a loop over the configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    (0, 1)   linear A\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 2 arrays: [array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0....",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-b0e029f3da3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_C\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_info_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_extra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms3_activation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_extra\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_oh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_extra\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_oh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mpreds_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_extra\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/lib/python2.7/site-packages/tensorflow/python/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps_per_epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m         validation_split=validation_split)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/lib/python2.7/site-packages/tensorflow/python/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m         exception_prefix='input')\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/lib/python2.7/site-packages/tensorflow/python/keras/engine/training_utils.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    150\u001b[0m                        \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                        \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                        str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m       raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 2 arrays: [array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0...."
     ]
    }
   ],
   "source": [
    "for k, act, arch in itertools.product(k_set, act_set, arch_set):\n",
    "    \n",
    "    print \"%10s %8s %1s\"%(str(k), act, arch)    \n",
    "    \n",
    "    if arch == 'A':\n",
    "        model = get_model_A(input_dim=X.shape[1], s1=50, s2=30, s3=20,s3_activation=act)\n",
    "        model.fit(X_train, y_train_oh, epochs=200, batch_size=32, validation_data=(X_test, y_test_oh)) \n",
    "        preds_test = model.predict(X_test).argmax(axis=1)    \n",
    "      \n",
    "    if arch == 'B':\n",
    "        X_train_extra, X_test_extra = get_X_extra(y_train, y_test, k0=k[0], k1=k[1])\n",
    "        model = get_model_B(input_dim=X.shape[1], extra_info_dim=X_train_extra.shape[1], s1=50, s2=30, s3=20, s3_activation=act)\n",
    "        model.fit([X_train, X_train_extra], y_train_oh, epochs=200, batch_size=100, validation_data=([X_test, X_test_extra], y_test_oh))\n",
    "        preds_test = model.predict([X_test, X_test_extra]).argmax(axis=1)\n",
    "        \n",
    "   \n",
    "    if arch=='C' and k!=None:\n",
    "        X_train_extra, X_test_extra = get_X_extra(y_train, y_test, k0=k[0], k1=k[1])\n",
    "        model = get_model_C(input_dim=X.shape[1], extra_info_dim=X_train_extra.shape[1], s1=50, s2=30, s3=20, s3_activation=act)\n",
    "        model.fit([X_train, X_train_extra], y_train_oh, epochs=200, batch_size=32, validation_data=([X_test, X_test_extra], y_test_oh))\n",
    "        preds_test = model.predict([X_test, X_test_extra]).argmax(axis=1)\n",
    "\n",
    "    \n",
    "   \n",
    "    acc = np.mean(preds_test==y_test)\n",
    "    model_act = arch+\"-\"+act\n",
    "    r_test.set_value(model_act, str(k), str(acc))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,3))\n",
    "\n",
    "... YOUR CODE HERE ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(121)\n",
    "\n",
    "... YOUR CODE HERE ...\n",
    "\n",
    "plt.subplot(122)\n",
    "\n",
    "... YOUR CODE HERE ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
