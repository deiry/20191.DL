{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension de las imagenes y las clases (1500, 784) (1500,)\n"
     ]
    }
   ],
   "source": [
    "mnist = pd.read_csv(\"data/mnist1.5k.csv.gz\", compression=\"gzip\", header=None).values\n",
    "X=mnist[:,1:785]/255.\n",
    "y=mnist[:,0]\n",
    "print \"dimension de las imagenes y las clases\", X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 784) (300, 10) (1200, 784) (1200, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = X[:300], X[300:], y[:300], y[300:]\n",
    "y_train_oh = np.eye(10)[y_train]\n",
    "y_test_oh  = np.eye(10)[y_test]\n",
    "print X_train.shape, y_train_oh.shape,  X_test.shape, y_test_oh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network architectures lab\n",
    "\n",
    "\n",
    "from the notes we have two architectures:\n",
    "    \n",
    "- **A**: Three layer network accepting a 784 element vector as input and outputing a 10-class vector\n",
    "- **B**: Same as **A** but accepts an additional 2 element vector with _evenness_ information that is injected at the third layer.\n",
    "\n",
    "This lab requires you to do two things:\n",
    "\n",
    "**1**. Create a **C** architecture similar to **B** but where the 2 element vector is injected at the second layer. This will make the network have 41,650 parameters, distributed in the following way:\n",
    "   \n",
    "   \n",
    "\n",
    "        INPUT 1 to LAYER 1:              784*50 + 50 (bias) = 39250\n",
    "        LAYER 1 to LAYER 2:               50*30 + 30 (bias) = 1530\n",
    "        LAYER 2 + INPUT 2 to LAYER 3: (30+2)*20 + 20 (bias) = 660\n",
    "        LAYER 3 to OUTPUT:                20*10 + 10 (bias) = 210\n",
    "    \n",
    "                                                       TOTAL 41650\n",
    "                                                       \n",
    "**2**. Run an experimental setup where you train different network configurations and measure the accuracy on test data. Fix the number of neurons to 50, 30 and 20 for each layer and the following combination of parameters:\n",
    "\n",
    "- For architecture **A** (3 configurations)\n",
    "\n",
    "    `s3_activation` $\\in$ `[\"linear\", \"relu\", \"tanh\"]`\n",
    "\n",
    "- For architectures **B** and **C** (15 configurations for each architecture)\n",
    "\n",
    "    `s3_activation` $\\in$ `[\"linear\", \"relu\", \"tanh\"]`\n",
    "    \n",
    "    `k1,k2` $\\in$ `[(0,1), (-.5,2),(-.5,30), (0,15),(0,30)]`\n",
    "\n",
    "And create a heat map showing the accuracy in test obtained for each configuration, such as the following (your results should be approximate to this):\n",
    "\n",
    "![alt text](./Images/mm_results_1.png)\n",
    "\n",
    "\n",
    "And two bar plots with the average per architecture and k1,k2 configuration, such as the following (again, your results should be approximetely similar):\n",
    "\n",
    "![alt text](./Images/mm_results_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, concatenate, Input\n",
    "from tensorflow.keras.backend import clear_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_A(input_dim, s1, s2, s3, s3_activation=\"relu\"):\n",
    "    clear_session()\n",
    "    model = Sequential()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(s1, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dense(s2, activation='relu'))\n",
    "    model.add(Dense(s3, activation=s3_activation))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    model.reset_states()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_B(input_dim, extra_info_dim,  s1, s2, s3, s3_activation=\"relu\"):\n",
    "    clear_session()\n",
    "    inp1 = Input(shape=(input_dim,))\n",
    "    l11 = Dense(s1, activation=\"relu\")(inp1)\n",
    "    l12 = Dense(s2, activation=\"relu\")(l11)\n",
    "    l13 = Dense(s3, activation=s3_activation)(l12)\n",
    "    \n",
    "    inp2 = Input(shape=(extra_info_dim,))\n",
    "    cc1 = concatenate([l13, inp2],axis=1) # Merge row, same column\n",
    "    output = Dense(10, activation='softmax')(cc1)\n",
    "    model = Model(inputs=[inp1, inp2], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    model.reset_states()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_C(input_dim, extra_info_dim, s1, s2, s3, s3_activation=\"relu\"):\n",
    "    clear_session()\n",
    "    inp2 = Input(shape=(extra_info_dim,))\n",
    "    inp1 = Input(shape=(input_dim,))\n",
    "    l11 = Dense(s1, activation=\"relu\")(inp1)\n",
    "    l12 = Dense(s2, activation=\"relu\")(l11)\n",
    "    cc1 = concatenate([l12, inp2],axis=1) # Merge row, same column\n",
    "    l13 = Dense(s3, activation=s3_activation)(l12)\n",
    "    \n",
    "\n",
    "    output = Dense(10, activation='softmax')(cc1)\n",
    "    model = Model(inputs=[inp1, inp2], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    model.reset_states()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_extra(y_train, y_test, k0, k1):\n",
    "    X_train_extra = (np.eye(2)[y_train%2]+k0)*k1\n",
    "    X_test_extra  = (np.eye(2)[y_test%2]+k0)*k1\n",
    "    return X_train_extra, X_test_extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the following dataframe to record your data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(0, 1)</th>\n",
       "      <th>(-0.5, 2)</th>\n",
       "      <th>(-0.5, 30)</th>\n",
       "      <th>(0, 15)</th>\n",
       "      <th>(0, 30)</th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A-linear</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-relu</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-tanh</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-linear</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-relu</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-tanh</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-linear</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-relu</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-tanh</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          (0, 1)  (-0.5, 2)  (-0.5, 30)  (0, 15)  (0, 30)  None\n",
       "A-linear     NaN        NaN         NaN      NaN      NaN   NaN\n",
       "A-relu       NaN        NaN         NaN      NaN      NaN   NaN\n",
       "A-tanh       NaN        NaN         NaN      NaN      NaN   NaN\n",
       "B-linear     NaN        NaN         NaN      NaN      NaN   NaN\n",
       "B-relu       NaN        NaN         NaN      NaN      NaN   NaN\n",
       "B-tanh       NaN        NaN         NaN      NaN      NaN   NaN\n",
       "C-linear     NaN        NaN         NaN      NaN      NaN   NaN\n",
       "C-relu       NaN        NaN         NaN      NaN      NaN   NaN\n",
       "C-tanh       NaN        NaN         NaN      NaN      NaN   NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_set     = [(0,1), (-.5,2),(-.5,30), (0,15),(0,30), None]\n",
    "act_set   = [\"linear\", \"relu\", \"tanh\"]\n",
    "arch_set  = [\"A\", \"B\", \"C\"]\n",
    "\n",
    "\n",
    "r_test = pd.DataFrame(np.zeros((len(arch_set)*len(act_set), len(k_set)))*np.nan, \n",
    "                      index=[[a+\"-\"+b for a,b in itertools.product (arch_set, act_set)]],\n",
    "                      columns=[str(i) for i in k_set])\n",
    "r_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a loop over the configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    (0, 1)   linear A\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2243 - val_loss: 2.0683\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 1.8965 - val_loss: 1.8117\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 1.5712 - val_loss: 1.5389\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 483us/step - loss: 1.2547 - val_loss: 1.2924\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 434us/step - loss: 0.9940 - val_loss: 1.1046\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 438us/step - loss: 0.7794 - val_loss: 0.9543\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 527us/step - loss: 0.6181 - val_loss: 0.8621\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 400us/step - loss: 0.4969 - val_loss: 0.8024\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 0.4038 - val_loss: 0.7495\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.3356 - val_loss: 0.7518\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 534us/step - loss: 0.2599 - val_loss: 0.7258\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 396us/step - loss: 0.2214 - val_loss: 0.7086\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.1846 - val_loss: 0.7062\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.1512 - val_loss: 0.7108\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.1277 - val_loss: 0.6948\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.1038 - val_loss: 0.7076\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 421us/step - loss: 0.0901 - val_loss: 0.6916\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 702us/step - loss: 0.0756 - val_loss: 0.6999\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 609us/step - loss: 0.0647 - val_loss: 0.7027\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 601us/step - loss: 0.0557 - val_loss: 0.7151\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.0488 - val_loss: 0.7136\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 0.0434 - val_loss: 0.7265\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 349us/step - loss: 0.0374 - val_loss: 0.7169\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 376us/step - loss: 0.0345 - val_loss: 0.7287\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.0303 - val_loss: 0.7352\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 0.0267 - val_loss: 0.7316\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 526us/step - loss: 0.0245 - val_loss: 0.7420\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 474us/step - loss: 0.0224 - val_loss: 0.7452\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 428us/step - loss: 0.0205 - val_loss: 0.7478\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 518us/step - loss: 0.0186 - val_loss: 0.7586\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 464us/step - loss: 0.0172 - val_loss: 0.7586\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 493us/step - loss: 0.0159 - val_loss: 0.7613\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 530us/step - loss: 0.0148 - val_loss: 0.7695\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 480us/step - loss: 0.0138 - val_loss: 0.7781\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 469us/step - loss: 0.0128 - val_loss: 0.7722\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 436us/step - loss: 0.0119 - val_loss: 0.7815\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 418us/step - loss: 0.0111 - val_loss: 0.7876\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 509us/step - loss: 0.0105 - val_loss: 0.7897\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0098 - val_loss: 0.7977\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 440us/step - loss: 0.0093 - val_loss: 0.8019\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 415us/step - loss: 0.0088 - val_loss: 0.7999\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0083 - val_loss: 0.8023\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 403us/step - loss: 0.0078 - val_loss: 0.8028\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 0.0074 - val_loss: 0.8108\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0070 - val_loss: 0.8156\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 382us/step - loss: 0.0066 - val_loss: 0.8140\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.0063 - val_loss: 0.8195\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 253us/step - loss: 0.0060 - val_loss: 0.8231\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0057 - val_loss: 0.8292\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 371us/step - loss: 0.0055 - val_loss: 0.8320\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 0.0052 - val_loss: 0.8346\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 261us/step - loss: 0.0050 - val_loss: 0.8394\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0048 - val_loss: 0.8378\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 0.0046 - val_loss: 0.8373\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 493us/step - loss: 0.0044 - val_loss: 0.8454\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.0042 - val_loss: 0.8495\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.0041 - val_loss: 0.8471\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0039 - val_loss: 0.8524\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 390us/step - loss: 0.0038 - val_loss: 0.8579\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 0.0036 - val_loss: 0.8602\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.0035 - val_loss: 0.8580\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0034 - val_loss: 0.8628\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0033 - val_loss: 0.8674\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 449us/step - loss: 0.0032 - val_loss: 0.8707\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 698us/step - loss: 0.0031 - val_loss: 0.8710\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 615us/step - loss: 0.0030 - val_loss: 0.8708\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 814us/step - loss: 0.0028 - val_loss: 0.8763\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 486us/step - loss: 0.0028 - val_loss: 0.8783\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 910us/step - loss: 0.0027 - val_loss: 0.8783\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.0026 - val_loss: 0.8788\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.8825\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 585us/step - loss: 0.0024 - val_loss: 0.8888\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 622us/step - loss: 0.0023 - val_loss: 0.8894\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 627us/step - loss: 0.0023 - val_loss: 0.8898\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 0.0022 - val_loss: 0.8936\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 263us/step - loss: 0.0022 - val_loss: 0.8937\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0021 - val_loss: 0.8958\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0020 - val_loss: 0.8980\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 373us/step - loss: 0.0020 - val_loss: 0.8997\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 474us/step - loss: 0.0019 - val_loss: 0.9035\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 406us/step - loss: 0.0019 - val_loss: 0.9043\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 388us/step - loss: 0.0018 - val_loss: 0.9045\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 374us/step - loss: 0.0018 - val_loss: 0.9083\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 424us/step - loss: 0.0017 - val_loss: 0.9083\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 428us/step - loss: 0.0017 - val_loss: 0.9116\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 439us/step - loss: 0.0016 - val_loss: 0.9117\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 480us/step - loss: 0.0016 - val_loss: 0.9135\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.0016 - val_loss: 0.9148\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 445us/step - loss: 0.0015 - val_loss: 0.9181\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 449us/step - loss: 0.0015 - val_loss: 0.9226\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 497us/step - loss: 0.0015 - val_loss: 0.9237\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 500us/step - loss: 0.0014 - val_loss: 0.9252\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 499us/step - loss: 0.0014 - val_loss: 0.9253\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.9267\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 877us/step - loss: 0.0013 - val_loss: 0.9298\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 792us/step - loss: 0.0013 - val_loss: 0.9320\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 529us/step - loss: 0.0013 - val_loss: 0.9340\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 459us/step - loss: 0.0012 - val_loss: 0.9353\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 527us/step - loss: 0.0012 - val_loss: 0.9365\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0012 - val_loss: 0.9369\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 362us/step - loss: 0.0011 - val_loss: 0.9397\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 563us/step - loss: 0.0011 - val_loss: 0.9421\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 448us/step - loss: 0.0011 - val_loss: 0.9434\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 494us/step - loss: 0.0011 - val_loss: 0.9449\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 355us/step - loss: 0.0011 - val_loss: 0.9462\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 0.0010 - val_loss: 0.9471\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 0.0010 - val_loss: 0.9477\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 400us/step - loss: 9.9670e-04 - val_loss: 0.9520\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 9.7752e-04 - val_loss: 0.9532\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 256us/step - loss: 9.5692e-04 - val_loss: 0.9543\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 9.3923e-04 - val_loss: 0.9556\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 498us/step - loss: 9.2259e-04 - val_loss: 0.9563\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 489us/step - loss: 9.0468e-04 - val_loss: 0.9594\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 491us/step - loss: 8.8889e-04 - val_loss: 0.9588\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 440us/step - loss: 8.7035e-04 - val_loss: 0.9591\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 432us/step - loss: 8.5406e-04 - val_loss: 0.9604\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 475us/step - loss: 8.3679e-04 - val_loss: 0.9611\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 8.2107e-04 - val_loss: 0.9643\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 484us/step - loss: 8.0731e-04 - val_loss: 0.9664\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 398us/step - loss: 7.9253e-04 - val_loss: 0.9664\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 380us/step - loss: 7.7783e-04 - val_loss: 0.9687\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 483us/step - loss: 7.6482e-04 - val_loss: 0.9700\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 534us/step - loss: 7.5076e-04 - val_loss: 0.9708\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 485us/step - loss: 7.3723e-04 - val_loss: 0.9720\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 7.2615e-04 - val_loss: 0.9745\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 7.1227e-04 - val_loss: 0.9756\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 6.9956e-04 - val_loss: 0.9753\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 361us/step - loss: 6.8763e-04 - val_loss: 0.9764\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 414us/step - loss: 6.7808e-04 - val_loss: 0.9786\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 401us/step - loss: 6.6327e-04 - val_loss: 0.9809\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 6.5429e-04 - val_loss: 0.9834\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 6.4166e-04 - val_loss: 0.9831\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 6.3145e-04 - val_loss: 0.9832\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 6.1980e-04 - val_loss: 0.9848\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 6.1051e-04 - val_loss: 0.9868\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 6.0011e-04 - val_loss: 0.9875\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 5.9035e-04 - val_loss: 0.9887\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 5.8120e-04 - val_loss: 0.9888\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 409us/step - loss: 5.7149e-04 - val_loss: 0.9890\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 421us/step - loss: 5.6258e-04 - val_loss: 0.9901\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 410us/step - loss: 5.5366e-04 - val_loss: 0.9926\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 5.4483e-04 - val_loss: 0.9942\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 522us/step - loss: 5.3636e-04 - val_loss: 0.9944\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 517us/step - loss: 5.2933e-04 - val_loss: 0.9954\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 455us/step - loss: 5.2016e-04 - val_loss: 0.9967\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 354us/step - loss: 5.1415e-04 - val_loss: 0.9986\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 509us/step - loss: 5.0507e-04 - val_loss: 0.9989\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 482us/step - loss: 4.9728e-04 - val_loss: 1.0001\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 468us/step - loss: 4.9055e-04 - val_loss: 1.0016\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 371us/step - loss: 4.8278e-04 - val_loss: 1.0033\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 4.7544e-04 - val_loss: 1.0026\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 4.6970e-04 - val_loss: 1.0039\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 4.6202e-04 - val_loss: 1.0030\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 4.5530e-04 - val_loss: 1.0041\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 265us/step - loss: 4.4849e-04 - val_loss: 1.0065\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 4.4305e-04 - val_loss: 1.0078\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 4.3594e-04 - val_loss: 1.0099\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 4.2926e-04 - val_loss: 1.0106\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 4.2330e-04 - val_loss: 1.0119\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 256us/step - loss: 4.1791e-04 - val_loss: 1.0123\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 4.1230e-04 - val_loss: 1.0136\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 4.0573e-04 - val_loss: 1.0141\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 3.9991e-04 - val_loss: 1.0148\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 3.9520e-04 - val_loss: 1.0177\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 261us/step - loss: 3.8915e-04 - val_loss: 1.0178\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 256us/step - loss: 3.8371e-04 - val_loss: 1.0175\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 261us/step - loss: 3.8024e-04 - val_loss: 1.0164\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 3.7360e-04 - val_loss: 1.0199\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 3.6861e-04 - val_loss: 1.0219\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 3.6417e-04 - val_loss: 1.0237\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 3.5912e-04 - val_loss: 1.0232\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 261us/step - loss: 3.5438e-04 - val_loss: 1.0236\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 3.4911e-04 - val_loss: 1.0247\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 263us/step - loss: 3.4504e-04 - val_loss: 1.0260\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 3.4035e-04 - val_loss: 1.0266\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 3.3588e-04 - val_loss: 1.0286\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 263us/step - loss: 3.3097e-04 - val_loss: 1.0299\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 3.2679e-04 - val_loss: 1.0310\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 3.2306e-04 - val_loss: 1.0328\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 263us/step - loss: 3.1890e-04 - val_loss: 1.0325\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 3.1464e-04 - val_loss: 1.0337\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 3.1054e-04 - val_loss: 1.0347\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 3.0759e-04 - val_loss: 1.0365\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 256us/step - loss: 3.0301e-04 - val_loss: 1.0371\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 261us/step - loss: 2.9898e-04 - val_loss: 1.0361\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 259us/step - loss: 2.9519e-04 - val_loss: 1.0380\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 256us/step - loss: 2.9160e-04 - val_loss: 1.0384\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 255us/step - loss: 2.8814e-04 - val_loss: 1.0398\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 2.8468e-04 - val_loss: 1.0411\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 255us/step - loss: 2.8073e-04 - val_loss: 1.0423\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 2.7736e-04 - val_loss: 1.0431\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 261us/step - loss: 2.7458e-04 - val_loss: 1.0426\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 261us/step - loss: 2.7088e-04 - val_loss: 1.0440\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 261us/step - loss: 2.6762e-04 - val_loss: 1.0456\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 261us/step - loss: 2.6452e-04 - val_loss: 1.0458\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 2.6152e-04 - val_loss: 1.0462\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 2.5831e-04 - val_loss: 1.0481\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 263us/step - loss: 2.5503e-04 - val_loss: 1.0491\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 2.5250e-04 - val_loss: 1.0503\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 2.4927e-04 - val_loss: 1.0511\n",
      "    (0, 1)   linear B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/lib/python2.7/site-packages/ipykernel_launcher.py:27: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 2.2376 - val_loss: 2.1503\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 2.0812 - val_loss: 2.0449\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 1.9432 - val_loss: 1.9378\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 141us/step - loss: 1.8000 - val_loss: 1.8215\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 137us/step - loss: 1.6557 - val_loss: 1.6970\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 1.5151 - val_loss: 1.5787\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 1.3769 - val_loss: 1.4702\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 1.2445 - val_loss: 1.3680\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 1.1231 - val_loss: 1.2709\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 192us/step - loss: 1.0050 - val_loss: 1.1805\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.8994 - val_loss: 1.0994\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 134us/step - loss: 0.8018 - val_loss: 1.0233\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 139us/step - loss: 0.7103 - val_loss: 0.9569\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.6263 - val_loss: 0.8975\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 169us/step - loss: 0.5536 - val_loss: 0.8476\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.4872 - val_loss: 0.8073\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 131us/step - loss: 0.4286 - val_loss: 0.7767\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 196us/step - loss: 0.3785 - val_loss: 0.7467\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.3339 - val_loss: 0.7228\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 229us/step - loss: 0.2956 - val_loss: 0.7045\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 232us/step - loss: 0.2629 - val_loss: 0.6917\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.2333 - val_loss: 0.6812\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 140us/step - loss: 0.2087 - val_loss: 0.6748\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.1856 - val_loss: 0.6612\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.1647 - val_loss: 0.6543\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 219us/step - loss: 0.1474 - val_loss: 0.6491\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.1324 - val_loss: 0.6473\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 214us/step - loss: 0.1195 - val_loss: 0.6491\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.1075 - val_loss: 0.6435\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 141us/step - loss: 0.0968 - val_loss: 0.6394\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 133us/step - loss: 0.0878 - val_loss: 0.6413\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.0793 - val_loss: 0.6433\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 195us/step - loss: 0.0722 - val_loss: 0.6415\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 237us/step - loss: 0.0652 - val_loss: 0.6411\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0597 - val_loss: 0.6405\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.0547 - val_loss: 0.6449\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 219us/step - loss: 0.0500 - val_loss: 0.6513\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0461 - val_loss: 0.6538\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0425 - val_loss: 0.6536\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 0.0393 - val_loss: 0.6558\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0365 - val_loss: 0.6562\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 203us/step - loss: 0.0341 - val_loss: 0.6612\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 188us/step - loss: 0.0315 - val_loss: 0.6619\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 176us/step - loss: 0.0297 - val_loss: 0.6639\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.0278 - val_loss: 0.6713\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 229us/step - loss: 0.0258 - val_loss: 0.6755\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 0.0243 - val_loss: 0.6784\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.0229 - val_loss: 0.6768\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 138us/step - loss: 0.0216 - val_loss: 0.6785\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 140us/step - loss: 0.0204 - val_loss: 0.6829\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0194 - val_loss: 0.6873\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 171us/step - loss: 0.0183 - val_loss: 0.6903\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.0174 - val_loss: 0.6921\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 173us/step - loss: 0.0166 - val_loss: 0.6939\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0158 - val_loss: 0.6956\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0150 - val_loss: 0.6986\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.0144 - val_loss: 0.7023\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.0137 - val_loss: 0.7066\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 236us/step - loss: 0.0131 - val_loss: 0.7086\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 189us/step - loss: 0.0126 - val_loss: 0.7108\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.0121 - val_loss: 0.7116\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.0116 - val_loss: 0.7141\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 171us/step - loss: 0.0111 - val_loss: 0.7179\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 140us/step - loss: 0.0107 - val_loss: 0.7212\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 139us/step - loss: 0.0103 - val_loss: 0.7242\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 138us/step - loss: 0.0099 - val_loss: 0.7248\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0095 - val_loss: 0.7263\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0092 - val_loss: 0.7285\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 170us/step - loss: 0.0089 - val_loss: 0.7297\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0086 - val_loss: 0.7317\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 0.0083 - val_loss: 0.7354\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 406us/step - loss: 0.0080 - val_loss: 0.7387\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0077 - val_loss: 0.7405\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.009 - 0s 307us/step - loss: 0.0075 - val_loss: 0.7414\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0073 - val_loss: 0.7415\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.005 - 0s 304us/step - loss: 0.0070 - val_loss: 0.7433\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 0.0068 - val_loss: 0.7458\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0066 - val_loss: 0.7486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0064 - val_loss: 0.7516\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0062 - val_loss: 0.7536\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0061 - val_loss: 0.7553\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0059 - val_loss: 0.7568\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0057 - val_loss: 0.7595\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0056 - val_loss: 0.7613\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0054 - val_loss: 0.7632\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0053 - val_loss: 0.7638\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 0.0051 - val_loss: 0.7655\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0050 - val_loss: 0.7678\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 0.0049 - val_loss: 0.7692\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0048 - val_loss: 0.7712\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.0046 - val_loss: 0.7728\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0045 - val_loss: 0.7752\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0044 - val_loss: 0.7768\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0043 - val_loss: 0.7783\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 363us/step - loss: 0.0042 - val_loss: 0.7795\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0041 - val_loss: 0.7803\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0040 - val_loss: 0.7818\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.0039 - val_loss: 0.7840\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 406us/step - loss: 0.0039 - val_loss: 0.7866\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0038 - val_loss: 0.7880\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 0.0037 - val_loss: 0.7895\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0036 - val_loss: 0.7910\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0035 - val_loss: 0.7922\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0035 - val_loss: 0.7945\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.0034 - val_loss: 0.7965\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 263us/step - loss: 0.0033 - val_loss: 0.7977\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0032 - val_loss: 0.7992\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0032 - val_loss: 0.8005\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 181us/step - loss: 0.0031 - val_loss: 0.8015\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 137us/step - loss: 0.0031 - val_loss: 0.8029\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 137us/step - loss: 0.0030 - val_loss: 0.8043\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.0029 - val_loss: 0.8061\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.0029 - val_loss: 0.8066\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 138us/step - loss: 0.0028 - val_loss: 0.8081\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 0.0028 - val_loss: 0.8095\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0027 - val_loss: 0.8109\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 141us/step - loss: 0.0027 - val_loss: 0.8126\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 143us/step - loss: 0.0026 - val_loss: 0.8140\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.0026 - val_loss: 0.8148\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 131us/step - loss: 0.0025 - val_loss: 0.8160\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.0025 - val_loss: 0.8172\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 141us/step - loss: 0.0024 - val_loss: 0.8190\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.8205\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0024 - val_loss: 0.8214\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 138us/step - loss: 0.0023 - val_loss: 0.8227\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 0.0023 - val_loss: 0.8236\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.0022 - val_loss: 0.8249\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0022 - val_loss: 0.8268\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0022 - val_loss: 0.8277\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 141us/step - loss: 0.0021 - val_loss: 0.8294\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 416us/step - loss: 0.0021 - val_loss: 0.8305\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 354us/step - loss: 0.0021 - val_loss: 0.8316\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0020 - val_loss: 0.8323\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.002 - 0s 307us/step - loss: 0.0020 - val_loss: 0.8332\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0020 - val_loss: 0.8344\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0019 - val_loss: 0.8356\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 395us/step - loss: 0.0019 - val_loss: 0.8370\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 514us/step - loss: 0.0019 - val_loss: 0.8379\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 0.0018 - val_loss: 0.8392\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 0.0018 - val_loss: 0.8404\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 373us/step - loss: 0.0018 - val_loss: 0.8416\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 422us/step - loss: 0.0018 - val_loss: 0.8423\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 0.0017 - val_loss: 0.8434\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 181us/step - loss: 0.0017 - val_loss: 0.8442\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 258us/step - loss: 0.0017 - val_loss: 0.8455\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.0017 - val_loss: 0.8464\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 0.0016 - val_loss: 0.8478\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 0.0016 - val_loss: 0.8492\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.0016 - val_loss: 0.8505\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.0016 - val_loss: 0.8514\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0016 - val_loss: 0.8525\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 0.0015 - val_loss: 0.8530\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0015 - val_loss: 0.8543\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 180us/step - loss: 0.0015 - val_loss: 0.8554\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0015 - val_loss: 0.8559\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 171us/step - loss: 0.0014 - val_loss: 0.8569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 138us/step - loss: 0.0014 - val_loss: 0.8583\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.001 - 0s 144us/step - loss: 0.0014 - val_loss: 0.8592\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0014 - val_loss: 0.8598\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 259us/step - loss: 0.0014 - val_loss: 0.8611\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0014 - val_loss: 0.8624\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0013 - val_loss: 0.8636\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 352us/step - loss: 0.0013 - val_loss: 0.8648\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.0013 - val_loss: 0.8657\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0013 - val_loss: 0.8662\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 0.0013 - val_loss: 0.8672\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 379us/step - loss: 0.0013 - val_loss: 0.8683\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.0012 - val_loss: 0.8694\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0012 - val_loss: 0.8700\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0012 - val_loss: 0.8707\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0012 - val_loss: 0.8716\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.0012 - val_loss: 0.8728\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0012 - val_loss: 0.8738\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0012 - val_loss: 0.8747\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.0011 - val_loss: 0.8757\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 0.0011 - val_loss: 0.8770\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 759us/step - loss: 0.0011 - val_loss: 0.8777\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0011 - val_loss: 0.8785\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0011 - val_loss: 0.8794\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0011 - val_loss: 0.8804\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 0.0011 - val_loss: 0.8813\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 360us/step - loss: 0.0010 - val_loss: 0.8818\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 0.0010 - val_loss: 0.8824\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0010 - val_loss: 0.8833\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 0.0010 - val_loss: 0.8844\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 392us/step - loss: 0.0010 - val_loss: 0.8852\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 9.9045e-04 - val_loss: 0.8861\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 9.7917e-04 - val_loss: 0.8871\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 9.6882e-04 - val_loss: 0.8879\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 9.5867e-04 - val_loss: 0.8890\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 9.4831e-04 - val_loss: 0.8898\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 385us/step - loss: 9.3805e-04 - val_loss: 0.8904\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 9.2811e-04 - val_loss: 0.8915\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 9.1818e-04 - val_loss: 0.8923\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 377us/step - loss: 9.0804e-04 - val_loss: 0.8929\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 376us/step - loss: 8.9888e-04 - val_loss: 0.8936\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 8.8928e-04 - val_loss: 0.8945\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 354us/step - loss: 8.8002e-04 - val_loss: 0.8957\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 369us/step - loss: 8.7113e-04 - val_loss: 0.8966\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 8.6179e-04 - val_loss: 0.8971\n",
      "    (0, 1)   linear C\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.3297 - val_loss: 2.1686\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 557us/step - loss: 2.0492 - val_loss: 1.9482\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 561us/step - loss: 1.7620 - val_loss: 1.6840\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 539us/step - loss: 1.4514 - val_loss: 1.4413\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 568us/step - loss: 1.1554 - val_loss: 1.2265\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 529us/step - loss: 0.9167 - val_loss: 1.0558\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 540us/step - loss: 0.7330 - val_loss: 0.9251\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 912us/step - loss: 0.5937 - val_loss: 0.8600\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 844us/step - loss: 0.4729 - val_loss: 0.7799\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 821us/step - loss: 0.3884 - val_loss: 0.7340\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 832us/step - loss: 0.3221 - val_loss: 0.6992\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 865us/step - loss: 0.2698 - val_loss: 0.6772\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 958us/step - loss: 0.2280 - val_loss: 0.6485\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 679us/step - loss: 0.1831 - val_loss: 0.6660\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 878us/step - loss: 0.1601 - val_loss: 0.6301\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 685us/step - loss: 0.1334 - val_loss: 0.6290\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 704us/step - loss: 0.1176 - val_loss: 0.6331\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 668us/step - loss: 0.0988 - val_loss: 0.6167\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 722us/step - loss: 0.0880 - val_loss: 0.6296\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 781us/step - loss: 0.0749 - val_loss: 0.6217\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 831us/step - loss: 0.0674 - val_loss: 0.6257\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 829us/step - loss: 0.0575 - val_loss: 0.6386\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.6350\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0475 - val_loss: 0.6178\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.0414 - val_loss: 0.6446\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0374 - val_loss: 0.6402\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.0340 - val_loss: 0.6368\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.0313 - val_loss: 0.6491\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.0282 - val_loss: 0.6503\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.0260 - val_loss: 0.6517\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0240 - val_loss: 0.6569\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.0222 - val_loss: 0.6582\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 861us/step - loss: 0.0206 - val_loss: 0.6594\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0192 - val_loss: 0.6640\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.0180 - val_loss: 0.6693\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.6763\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.6739\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.6767\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.6790\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 974us/step - loss: 0.0132 - val_loss: 0.6855\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 818us/step - loss: 0.0125 - val_loss: 0.6855\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 0.0119 - val_loss: 0.6834\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 933us/step - loss: 0.0112 - val_loss: 0.6880\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 898us/step - loss: 0.0108 - val_loss: 0.6998\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 916us/step - loss: 0.0101 - val_loss: 0.6955\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 764us/step - loss: 0.0097 - val_loss: 0.6975\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 872us/step - loss: 0.0092 - val_loss: 0.7049\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 885us/step - loss: 0.0088 - val_loss: 0.7125\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 901us/step - loss: 0.0085 - val_loss: 0.7130\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 849us/step - loss: 0.0081 - val_loss: 0.7061\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 860us/step - loss: 0.0077 - val_loss: 0.7092\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 796us/step - loss: 0.0074 - val_loss: 0.7177\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 830us/step - loss: 0.0071 - val_loss: 0.7229\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 999us/step - loss: 0.0068 - val_loss: 0.7255\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.7230\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.7259\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 639us/step - loss: 0.0060 - val_loss: 0.7311\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 672us/step - loss: 0.0058 - val_loss: 0.7352\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 669us/step - loss: 0.0056 - val_loss: 0.7327\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 614us/step - loss: 0.0054 - val_loss: 0.7329\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 593us/step - loss: 0.0052 - val_loss: 0.7402\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 680us/step - loss: 0.0050 - val_loss: 0.7416\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 563us/step - loss: 0.0048 - val_loss: 0.7389\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 605us/step - loss: 0.0047 - val_loss: 0.7378\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 653us/step - loss: 0.0045 - val_loss: 0.7439\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 650us/step - loss: 0.0044 - val_loss: 0.7489\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 657us/step - loss: 0.0043 - val_loss: 0.7541\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 578us/step - loss: 0.0041 - val_loss: 0.7511\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 660us/step - loss: 0.0040 - val_loss: 0.7552\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 728us/step - loss: 0.0039 - val_loss: 0.7551\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 0.0037 - val_loss: 0.7611\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 663us/step - loss: 0.0036 - val_loss: 0.7618\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 558us/step - loss: 0.0035 - val_loss: 0.7634\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 593us/step - loss: 0.0034 - val_loss: 0.7644\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 647us/step - loss: 0.0033 - val_loss: 0.7615\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 0.0032 - val_loss: 0.7658\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 718us/step - loss: 0.0032 - val_loss: 0.7710\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 778us/step - loss: 0.0030 - val_loss: 0.7735\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 678us/step - loss: 0.0030 - val_loss: 0.7764\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 700us/step - loss: 0.0029 - val_loss: 0.7754\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 624us/step - loss: 0.0028 - val_loss: 0.7808\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 690us/step - loss: 0.0027 - val_loss: 0.7794\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 0.0027 - val_loss: 0.7816\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 762us/step - loss: 0.0026 - val_loss: 0.7873\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 0.0025 - val_loss: 0.7851\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.7887\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.7902\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 950us/step - loss: 0.0024 - val_loss: 0.7883\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 966us/step - loss: 0.0023 - val_loss: 0.7908\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 847us/step - loss: 0.0022 - val_loss: 0.7955\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.7959\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 957us/step - loss: 0.0021 - val_loss: 0.7955\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.7980\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.7987\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.8031\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.8026\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.8057\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 988us/step - loss: 0.0019 - val_loss: 0.8063\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 753us/step - loss: 0.0018 - val_loss: 0.8089\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.8099\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.8108\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 923us/step - loss: 0.0017 - val_loss: 0.8117\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.8120\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.8178\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 765us/step - loss: 0.0016 - val_loss: 0.8193\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 0.0016 - val_loss: 0.8198\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 778us/step - loss: 0.0015 - val_loss: 0.8202\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 668us/step - loss: 0.0015 - val_loss: 0.8208\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 0.0015 - val_loss: 0.8224\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 645us/step - loss: 0.0015 - val_loss: 0.8232\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 625us/step - loss: 0.0014 - val_loss: 0.8248\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 624us/step - loss: 0.0014 - val_loss: 0.8276\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 575us/step - loss: 0.0014 - val_loss: 0.8280\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 797us/step - loss: 0.0013 - val_loss: 0.8288\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 546us/step - loss: 0.0013 - val_loss: 0.8330\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 784us/step - loss: 0.0013 - val_loss: 0.8346\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.8363\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.8376\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.8388\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 970us/step - loss: 0.0012 - val_loss: 0.8389\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 778us/step - loss: 0.0012 - val_loss: 0.8404\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 673us/step - loss: 0.0012 - val_loss: 0.8401\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 758us/step - loss: 0.0011 - val_loss: 0.8428\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 826us/step - loss: 0.0011 - val_loss: 0.8440\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 705us/step - loss: 0.0011 - val_loss: 0.8472\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 668us/step - loss: 0.0011 - val_loss: 0.8465\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.8484\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 779us/step - loss: 0.0010 - val_loss: 0.8487\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 740us/step - loss: 0.0010 - val_loss: 0.8501\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.8528\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 839us/step - loss: 9.9339e-04 - val_loss: 0.8541\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 678us/step - loss: 9.7819e-04 - val_loss: 0.8555\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 9.6249e-04 - val_loss: 0.8577\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 9.4807e-04 - val_loss: 0.8583\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 761us/step - loss: 9.2980e-04 - val_loss: 0.8584\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 615us/step - loss: 9.1629e-04 - val_loss: 0.8583\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 640us/step - loss: 9.0122e-04 - val_loss: 0.8602\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 624us/step - loss: 8.8878e-04 - val_loss: 0.8627\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 695us/step - loss: 8.7413e-04 - val_loss: 0.8648\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 615us/step - loss: 8.5971e-04 - val_loss: 0.8641\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 653us/step - loss: 8.4629e-04 - val_loss: 0.8651\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 596us/step - loss: 8.3463e-04 - val_loss: 0.8655\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 670us/step - loss: 8.2395e-04 - val_loss: 0.8690\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 814us/step - loss: 8.1015e-04 - val_loss: 0.8706\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 920us/step - loss: 7.9970e-04 - val_loss: 0.8694\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 7.8491e-04 - val_loss: 0.8706\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 905us/step - loss: 7.7722e-04 - val_loss: 0.8742\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 7.6320e-04 - val_loss: 0.8735\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 7.5125e-04 - val_loss: 0.8736\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 787us/step - loss: 7.3968e-04 - val_loss: 0.8739\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 977us/step - loss: 7.2827e-04 - val_loss: 0.8755\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 955us/step - loss: 7.1910e-04 - val_loss: 0.8778\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 819us/step - loss: 7.0754e-04 - val_loss: 0.8794\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 733us/step - loss: 6.9706e-04 - val_loss: 0.8802\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 770us/step - loss: 6.8663e-04 - val_loss: 0.8800\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 6.7812e-04 - val_loss: 0.8821\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 6.6756e-04 - val_loss: 0.8839\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 6.5905e-04 - val_loss: 0.8852\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 966us/step - loss: 6.4870e-04 - val_loss: 0.8854\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 6.4088e-04 - val_loss: 0.8853\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 6.3175e-04 - val_loss: 0.8866\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 6.2294e-04 - val_loss: 0.8876\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 6.1381e-04 - val_loss: 0.8884\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 6.0576e-04 - val_loss: 0.8889\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 5.9787e-04 - val_loss: 0.8907\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 565us/step - loss: 5.9129e-04 - val_loss: 0.8932\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 565us/step - loss: 5.8226e-04 - val_loss: 0.8932\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 483us/step - loss: 5.7449e-04 - val_loss: 0.8939\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 5.6748e-04 - val_loss: 0.8960\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 5.6308e-04 - val_loss: 0.8943\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 5.5245e-04 - val_loss: 0.8983\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 365us/step - loss: 5.4589e-04 - val_loss: 0.9000\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 5.3918e-04 - val_loss: 0.9007\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 5.3111e-04 - val_loss: 0.8997\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 5.2483e-04 - val_loss: 0.8992\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 5.1759e-04 - val_loss: 0.8991\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 5.1089e-04 - val_loss: 0.9008\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 5.0518e-04 - val_loss: 0.9033\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 4.9846e-04 - val_loss: 0.9034\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 4.9242e-04 - val_loss: 0.9038\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 4.8630e-04 - val_loss: 0.9052\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 4.7949e-04 - val_loss: 0.9062\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 4.7484e-04 - val_loss: 0.9067\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 4.6828e-04 - val_loss: 0.9090\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 4.6251e-04 - val_loss: 0.9100\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 4.5683e-04 - val_loss: 0.9118\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 4.5279e-04 - val_loss: 0.9103\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 4.4545e-04 - val_loss: 0.9122\n",
      "Epoch 189/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 290us/step - loss: 4.3995e-04 - val_loss: 0.9122\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 4.3461e-04 - val_loss: 0.9139\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 4.2984e-04 - val_loss: 0.9151\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 4.2503e-04 - val_loss: 0.9177\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 4.1899e-04 - val_loss: 0.9185\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 378us/step - loss: 4.1354e-04 - val_loss: 0.9167\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 4.0942e-04 - val_loss: 0.9167\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 4.0505e-04 - val_loss: 0.9174\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 355us/step - loss: 3.9995e-04 - val_loss: 0.9190\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 3.9497e-04 - val_loss: 0.9204\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 366us/step - loss: 3.9023e-04 - val_loss: 0.9218\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 357us/step - loss: 3.8614e-04 - val_loss: 0.9226\n",
      "    (0, 1)     relu A\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2487 - val_loss: 2.1389\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 570us/step - loss: 2.0318 - val_loss: 1.9710\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 1.7932 - val_loss: 1.7612\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 1.5544 - val_loss: 1.5448\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 1.2976 - val_loss: 1.3504\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 1.0713 - val_loss: 1.1650\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.8529 - val_loss: 1.0123\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.6658 - val_loss: 0.8971\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 437us/step - loss: 0.5165 - val_loss: 0.8219\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.3958 - val_loss: 0.7704\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.3108 - val_loss: 0.7280\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.2483 - val_loss: 0.7007\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 352us/step - loss: 0.2001 - val_loss: 0.6786\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 0.1556 - val_loss: 0.6677\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.1265 - val_loss: 0.6734\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.1076 - val_loss: 0.6892\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0863 - val_loss: 0.6717\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 0.0733 - val_loss: 0.6805\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 352us/step - loss: 0.0627 - val_loss: 0.6857\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0520 - val_loss: 0.6763\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0440 - val_loss: 0.6911\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 349us/step - loss: 0.0386 - val_loss: 0.6917\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 0.0339 - val_loss: 0.7024\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 0.0294 - val_loss: 0.7066\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 0.0260 - val_loss: 0.7120\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0234 - val_loss: 0.7343\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 0.0208 - val_loss: 0.7179\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.0187 - val_loss: 0.7379\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.0171 - val_loss: 0.7399\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0154 - val_loss: 0.7326\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.0142 - val_loss: 0.7485\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.0130 - val_loss: 0.7409\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.0119 - val_loss: 0.7552\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 0.0111 - val_loss: 0.7579\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.0103 - val_loss: 0.7637\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 0.0095 - val_loss: 0.7598\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 0.0089 - val_loss: 0.7699\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 0.0082 - val_loss: 0.7769\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.0078 - val_loss: 0.7839\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0072 - val_loss: 0.7835\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.0068 - val_loss: 0.7878\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0065 - val_loss: 0.7919\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.0061 - val_loss: 0.7934\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 0.0058 - val_loss: 0.7999\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 0.0055 - val_loss: 0.8016\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.0052 - val_loss: 0.7995\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0049 - val_loss: 0.8068\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.003 - 0s 308us/step - loss: 0.0047 - val_loss: 0.8169\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.0045 - val_loss: 0.8098\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 0.0043 - val_loss: 0.8164\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0041 - val_loss: 0.8244\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.0039 - val_loss: 0.8183\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0037 - val_loss: 0.8251\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0036 - val_loss: 0.8275\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 0.0034 - val_loss: 0.8308\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.0033 - val_loss: 0.8310\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 0.0032 - val_loss: 0.8369\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0030 - val_loss: 0.8378\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 0.0029 - val_loss: 0.8392\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.0028 - val_loss: 0.8408\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 0.0027 - val_loss: 0.8424\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0026 - val_loss: 0.8438\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0025 - val_loss: 0.8466\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0024 - val_loss: 0.8476\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0023 - val_loss: 0.8536\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 272us/step - loss: 0.0023 - val_loss: 0.8594\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0022 - val_loss: 0.8570\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0021 - val_loss: 0.8598\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0021 - val_loss: 0.8600\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0020 - val_loss: 0.8627\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0019 - val_loss: 0.8630\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0019 - val_loss: 0.8641\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0018 - val_loss: 0.8719\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0018 - val_loss: 0.8744\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.0017 - val_loss: 0.8755\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0017 - val_loss: 0.8749\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0016 - val_loss: 0.8763\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0016 - val_loss: 0.8809\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0015 - val_loss: 0.8797\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0015 - val_loss: 0.8815\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0014 - val_loss: 0.8862\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0014 - val_loss: 0.8879\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.0014 - val_loss: 0.8890\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0013 - val_loss: 0.8876\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0013 - val_loss: 0.8932\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0013 - val_loss: 0.8959\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0012 - val_loss: 0.8979\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 520us/step - loss: 0.0012 - val_loss: 0.8985\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 613us/step - loss: 0.0012 - val_loss: 0.8959\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 504us/step - loss: 0.0011 - val_loss: 0.9013\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 648us/step - loss: 0.0011 - val_loss: 0.9058\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 578us/step - loss: 0.0011 - val_loss: 0.9015\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 717us/step - loss: 0.0011 - val_loss: 0.9032\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 451us/step - loss: 0.0010 - val_loss: 0.9112\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 427us/step - loss: 0.0010 - val_loss: 0.9112\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 9.7726e-04 - val_loss: 0.9083\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 436us/step - loss: 9.5397e-04 - val_loss: 0.9112\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 9.3230e-04 - val_loss: 0.9163\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 9.1285e-04 - val_loss: 0.9174\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 683us/step - loss: 8.8975e-04 - val_loss: 0.9156\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 419us/step - loss: 8.6957e-04 - val_loss: 0.9171\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 694us/step - loss: 8.4881e-04 - val_loss: 0.9188\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 654us/step - loss: 8.3010e-04 - val_loss: 0.9212\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 546us/step - loss: 8.1515e-04 - val_loss: 0.9222\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 7.9597e-04 - val_loss: 0.9205\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 7.7663e-04 - val_loss: 0.9230\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 394us/step - loss: 7.5917e-04 - val_loss: 0.9261\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 7.4261e-04 - val_loss: 0.9289\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 7.2705e-04 - val_loss: 0.9277\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 395us/step - loss: 7.1285e-04 - val_loss: 0.9318\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 6.9660e-04 - val_loss: 0.9329\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 6.8223e-04 - val_loss: 0.9310\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 402us/step - loss: 6.6795e-04 - val_loss: 0.9317\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 6.5348e-04 - val_loss: 0.9340\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 6.4107e-04 - val_loss: 0.9381\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 6.2771e-04 - val_loss: 0.9384\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 6.1645e-04 - val_loss: 0.9404\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 374us/step - loss: 6.0327e-04 - val_loss: 0.9418\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 428us/step - loss: 5.9397e-04 - val_loss: 0.9408\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 447us/step - loss: 5.8313e-04 - val_loss: 0.9448\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 5.7070e-04 - val_loss: 0.9457\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 5.5973e-04 - val_loss: 0.9447\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 5.4868e-04 - val_loss: 0.9469\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 390us/step - loss: 5.3997e-04 - val_loss: 0.9504\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 5.2879e-04 - val_loss: 0.9507\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 5.1842e-04 - val_loss: 0.9490\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 375us/step - loss: 5.0991e-04 - val_loss: 0.9487\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 360us/step - loss: 5.0073e-04 - val_loss: 0.9508\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 4.9055e-04 - val_loss: 0.9508\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 4.8173e-04 - val_loss: 0.9523\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 4.7181e-04 - val_loss: 0.9546\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 4.6354e-04 - val_loss: 0.9556\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 4.5502e-04 - val_loss: 0.9561\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 4.4691e-04 - val_loss: 0.9575\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 4.3921e-04 - val_loss: 0.9575\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 4.3174e-04 - val_loss: 0.9582\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 379us/step - loss: 4.2458e-04 - val_loss: 0.9614\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 366us/step - loss: 4.1732e-04 - val_loss: 0.9620\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 574us/step - loss: 4.1010e-04 - val_loss: 0.9629\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 569us/step - loss: 4.0334e-04 - val_loss: 0.9635\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 3.9683e-04 - val_loss: 0.9671\n",
      "Epoch 142/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 379us/step - loss: 3.9019e-04 - val_loss: 0.9665\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 3.8396e-04 - val_loss: 0.9686\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 3.7788e-04 - val_loss: 0.9678\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 3.7171e-04 - val_loss: 0.9682\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 3.4791e-0 - 0s 319us/step - loss: 3.6636e-04 - val_loss: 0.9723\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 556us/step - loss: 3.6012e-04 - val_loss: 0.9718\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 634us/step - loss: 3.5450e-04 - val_loss: 0.9749\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 643us/step - loss: 3.4873e-04 - val_loss: 0.9761\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 813us/step - loss: 3.4351e-04 - val_loss: 0.9782\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 717us/step - loss: 3.3831e-04 - val_loss: 0.9768\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 3.3298e-04 - val_loss: 0.9793\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 3.2821e-04 - val_loss: 0.9808\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 3.2235e-04 - val_loss: 0.9794\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 627us/step - loss: 3.1762e-04 - val_loss: 0.9819\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 365us/step - loss: 3.1285e-04 - val_loss: 0.9821\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 3.0872e-04 - val_loss: 0.9841\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 3.0383e-04 - val_loss: 0.9849\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 2.9876e-04 - val_loss: 0.9849\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 2.9484e-04 - val_loss: 0.9869\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 2.9033e-04 - val_loss: 0.9879\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 2.8636e-04 - val_loss: 0.9899\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 2.8214e-04 - val_loss: 0.9916\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 2.7806e-04 - val_loss: 0.9922\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 2.7395e-04 - val_loss: 0.9929\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 2.7014e-04 - val_loss: 0.9929\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 2.6604e-04 - val_loss: 0.9944\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 357us/step - loss: 2.6275e-04 - val_loss: 0.9944\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 586us/step - loss: 2.5885e-04 - val_loss: 0.9963\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 378us/step - loss: 2.5531e-04 - val_loss: 0.9960\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 2.5155e-04 - val_loss: 0.9982\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 2.4854e-04 - val_loss: 0.9987\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 2.4500e-04 - val_loss: 1.0013\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 2.4164e-04 - val_loss: 1.0002\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 2.3859e-04 - val_loss: 1.0026\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 2.3562e-04 - val_loss: 1.0024\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 405us/step - loss: 2.3208e-04 - val_loss: 1.0038\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 580us/step - loss: 2.2900e-04 - val_loss: 1.0055\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 378us/step - loss: 2.2595e-04 - val_loss: 1.0069\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 2.2302e-04 - val_loss: 1.0073\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 2.1985e-04 - val_loss: 1.0079\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 594us/step - loss: 2.1741e-04 - val_loss: 1.0068\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 430us/step - loss: 2.1440e-04 - val_loss: 1.0097\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 2.1147e-04 - val_loss: 1.0108\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 2.0882e-04 - val_loss: 1.0111\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 2.0628e-04 - val_loss: 1.0126\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 2.0378e-04 - val_loss: 1.0139\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 2.0105e-04 - val_loss: 1.0153\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 1.9848e-04 - val_loss: 1.0151\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 1.9598e-04 - val_loss: 1.0163\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 1.9355e-04 - val_loss: 1.0168\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 1.9133e-04 - val_loss: 1.0160\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 1.8878e-04 - val_loss: 1.0171\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 1.8654e-04 - val_loss: 1.0173\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 1.8421e-04 - val_loss: 1.0197\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 1.8206e-04 - val_loss: 1.0200\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 1.7976e-04 - val_loss: 1.0216\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 1.7768e-04 - val_loss: 1.0215\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 1.7551e-04 - val_loss: 1.0222\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 1.7370e-04 - val_loss: 1.0226\n",
      "    (0, 1)     relu B\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 2.2780 - val_loss: 2.2806\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 2.1682 - val_loss: 2.2085\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 235us/step - loss: 2.0638 - val_loss: 2.1353\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 180us/step - loss: 1.9616 - val_loss: 2.0534\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 191us/step - loss: 1.8519 - val_loss: 1.9690\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 198us/step - loss: 1.7431 - val_loss: 1.8853\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.6408 - val_loss: 1.8051\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 1.5371 - val_loss: 1.7291\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 1.4404 - val_loss: 1.6441\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 177us/step - loss: 1.3471 - val_loss: 1.5566\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 139us/step - loss: 1.2518 - val_loss: 1.4822\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 140us/step - loss: 1.1573 - val_loss: 1.4037\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 1.0646 - val_loss: 1.3201\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.9725 - val_loss: 1.2338\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.8825 - val_loss: 1.1570\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.7970 - val_loss: 1.0933\n",
      "Epoch 17/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 146us/step - loss: 0.7180 - val_loss: 1.0322\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 141us/step - loss: 0.6442 - val_loss: 0.9820\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.5766 - val_loss: 0.9486\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.5179 - val_loss: 0.9061\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 141us/step - loss: 0.4615 - val_loss: 0.8754\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 137us/step - loss: 0.4134 - val_loss: 0.8477\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.3697 - val_loss: 0.8227\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 180us/step - loss: 0.3300 - val_loss: 0.8038\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 175us/step - loss: 0.2936 - val_loss: 0.7996\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 0.2600 - val_loss: 0.7851\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 170us/step - loss: 0.2324 - val_loss: 0.7736\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 0.2067 - val_loss: 0.7584\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 171us/step - loss: 0.1858 - val_loss: 0.7525\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.1648 - val_loss: 0.7462\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 235us/step - loss: 0.1465 - val_loss: 0.7447\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 0.1305 - val_loss: 0.7486\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 184us/step - loss: 0.1180 - val_loss: 0.7397\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.1059 - val_loss: 0.7358\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.0949 - val_loss: 0.7441\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 0.0857 - val_loss: 0.7423\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 171us/step - loss: 0.0782 - val_loss: 0.7420\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 174us/step - loss: 0.0697 - val_loss: 0.7411\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 174us/step - loss: 0.0633 - val_loss: 0.7431\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 176us/step - loss: 0.0579 - val_loss: 0.7505\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 0.0526 - val_loss: 0.7508\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0483 - val_loss: 0.7597\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.0443 - val_loss: 0.7635\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0409 - val_loss: 0.7654\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 176us/step - loss: 0.0380 - val_loss: 0.7647\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 180us/step - loss: 0.0352 - val_loss: 0.7725\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 173us/step - loss: 0.0328 - val_loss: 0.7788\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 171us/step - loss: 0.0306 - val_loss: 0.7803\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 177us/step - loss: 0.0287 - val_loss: 0.7825\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0269 - val_loss: 0.7844\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0254 - val_loss: 0.7942\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 141us/step - loss: 0.0239 - val_loss: 0.7978\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.0226 - val_loss: 0.7979\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0214 - val_loss: 0.8018\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.0202 - val_loss: 0.8074\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0193 - val_loss: 0.8123\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0183 - val_loss: 0.8168\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 137us/step - loss: 0.0174 - val_loss: 0.8176\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 172us/step - loss: 0.0166 - val_loss: 0.8185\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.0158 - val_loss: 0.8215\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 0.0152 - val_loss: 0.8273\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 143us/step - loss: 0.0145 - val_loss: 0.8298\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.0139 - val_loss: 0.8306\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 0.0133 - val_loss: 0.8339\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 135us/step - loss: 0.0128 - val_loss: 0.8387\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.0123 - val_loss: 0.8411\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 137us/step - loss: 0.0118 - val_loss: 0.8440\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0114 - val_loss: 0.8468\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 0.0110 - val_loss: 0.8502\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0106 - val_loss: 0.8525\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.0102 - val_loss: 0.8548\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0098 - val_loss: 0.8587\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0095 - val_loss: 0.8592\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.0092 - val_loss: 0.8604\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 139us/step - loss: 0.0089 - val_loss: 0.8649\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0086 - val_loss: 0.8674\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0083 - val_loss: 0.8695\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 0.0081 - val_loss: 0.8714\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0078 - val_loss: 0.8745\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0076 - val_loss: 0.8786\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 0.0074 - val_loss: 0.8795\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0072 - val_loss: 0.8802\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.0070 - val_loss: 0.8835\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 136us/step - loss: 0.0068 - val_loss: 0.8868\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 137us/step - loss: 0.0066 - val_loss: 0.8900\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 138us/step - loss: 0.0064 - val_loss: 0.8903\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.0062 - val_loss: 0.8931\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0061 - val_loss: 0.8957\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0059 - val_loss: 0.8971\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0058 - val_loss: 0.9005\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.0056 - val_loss: 0.9034\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.0055 - val_loss: 0.9051\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 143us/step - loss: 0.0053 - val_loss: 0.9046\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0052 - val_loss: 0.9072\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 139us/step - loss: 0.0051 - val_loss: 0.9113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0050 - val_loss: 0.9121\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0048 - val_loss: 0.9131\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.005 - 0s 160us/step - loss: 0.0047 - val_loss: 0.9150\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0046 - val_loss: 0.9173\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0045 - val_loss: 0.9209\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 140us/step - loss: 0.0044 - val_loss: 0.9208\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0043 - val_loss: 0.9236\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 0.0042 - val_loss: 0.9252\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 0.0041 - val_loss: 0.9284\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 0.0040 - val_loss: 0.9300\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 138us/step - loss: 0.0040 - val_loss: 0.9321\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.0039 - val_loss: 0.9311\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 0.0038 - val_loss: 0.9340\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0037 - val_loss: 0.9376\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.0036 - val_loss: 0.9394\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.003 - 0s 134us/step - loss: 0.0036 - val_loss: 0.9398\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 0.0035 - val_loss: 0.9417\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0034 - val_loss: 0.9442\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 139us/step - loss: 0.0034 - val_loss: 0.9460\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 138us/step - loss: 0.0033 - val_loss: 0.9470\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0032 - val_loss: 0.9489\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 166us/step - loss: 0.0032 - val_loss: 0.9512\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0031 - val_loss: 0.9525\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0030 - val_loss: 0.9548\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0030 - val_loss: 0.9555\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 140us/step - loss: 0.0029 - val_loss: 0.9563\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.0029 - val_loss: 0.9577\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 138us/step - loss: 0.0028 - val_loss: 0.9616\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0028 - val_loss: 0.9628\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0027 - val_loss: 0.9625\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.0027 - val_loss: 0.9643\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0026 - val_loss: 0.9662\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 0.0026 - val_loss: 0.9689\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 140us/step - loss: 0.0026 - val_loss: 0.9708\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0025 - val_loss: 0.9719\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 0.0025 - val_loss: 0.9727\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0024 - val_loss: 0.9750\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.9760\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.0023 - val_loss: 0.9768\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0023 - val_loss: 0.9787\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 170us/step - loss: 0.0023 - val_loss: 0.9806\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0022 - val_loss: 0.9821\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 175us/step - loss: 0.0022 - val_loss: 0.9826\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 139us/step - loss: 0.0022 - val_loss: 0.9833\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0021 - val_loss: 0.9857\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 170us/step - loss: 0.0021 - val_loss: 0.9882\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.0021 - val_loss: 0.9892\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 0.0020 - val_loss: 0.9901\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 138us/step - loss: 0.0020 - val_loss: 0.9918\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 143us/step - loss: 0.0020 - val_loss: 0.9936\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0019 - val_loss: 0.9940\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 169us/step - loss: 0.0019 - val_loss: 0.9954\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0019 - val_loss: 0.9979\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 253us/step - loss: 0.0019 - val_loss: 0.9980\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 0.0018 - val_loss: 0.9996\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0018 - val_loss: 1.0018\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 259us/step - loss: 0.0018 - val_loss: 1.0028\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0018 - val_loss: 1.0037\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0017 - val_loss: 1.0049\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 0.0017 - val_loss: 1.0067\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0017 - val_loss: 1.0084\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 362us/step - loss: 0.0017 - val_loss: 1.0093\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 464us/step - loss: 0.0016 - val_loss: 1.0108\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 0.0016 - val_loss: 1.0114\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 0.0016 - val_loss: 1.0125\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 528us/step - loss: 0.0016 - val_loss: 1.0138\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 365us/step - loss: 0.0016 - val_loss: 1.0160\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 185us/step - loss: 0.0015 - val_loss: 1.0171\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 416us/step - loss: 0.0015 - val_loss: 1.0177\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 513us/step - loss: 0.0015 - val_loss: 1.0194\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.0015 - val_loss: 1.0206\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0015 - val_loss: 1.0225\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0014 - val_loss: 1.0234\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.0014 - val_loss: 1.0247\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 0.0014 - val_loss: 1.0255\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.0014 - val_loss: 1.0262\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 0.0014 - val_loss: 1.0278\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 1.0290\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 0.0013 - val_loss: 1.0305\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 209us/step - loss: 0.0013 - val_loss: 1.0314\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.0013 - val_loss: 1.0330\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0013 - val_loss: 1.0344\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 185us/step - loss: 0.0013 - val_loss: 1.0347\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 168us/step - loss: 0.0013 - val_loss: 1.0357\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0012 - val_loss: 1.0366\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0012 - val_loss: 1.0383\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.0012 - val_loss: 1.0399\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 170us/step - loss: 0.0012 - val_loss: 1.0408\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 180us/step - loss: 0.0012 - val_loss: 1.0416\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 252us/step - loss: 0.0012 - val_loss: 1.0432\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0012 - val_loss: 1.0446\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 0.0011 - val_loss: 1.0457\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 171us/step - loss: 0.0011 - val_loss: 1.0457\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0011 - val_loss: 1.0470\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0011 - val_loss: 1.0489\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 178us/step - loss: 0.0011 - val_loss: 1.0499\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0011 - val_loss: 1.0509\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0011 - val_loss: 1.0515\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 1.0528\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 143us/step - loss: 0.0010 - val_loss: 1.0543\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 0.0010 - val_loss: 1.0548\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.0010 - val_loss: 1.0560\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.0010 - val_loss: 1.0566\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0010 - val_loss: 1.0581\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 141us/step - loss: 9.9205e-04 - val_loss: 1.0604\n",
      "    (0, 1)     relu C\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 2.1856 - val_loss: 2.0499\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 1.8136 - val_loss: 1.7471\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 1.4684 - val_loss: 1.4604\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 1.1853 - val_loss: 1.2364\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 0.9529 - val_loss: 1.0686\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.7696 - val_loss: 0.9327\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.6259 - val_loss: 0.8360\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.5103 - val_loss: 0.7847\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.4247 - val_loss: 0.7113\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 263us/step - loss: 0.3549 - val_loss: 0.6863\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.2970 - val_loss: 0.6830\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.2502 - val_loss: 0.6394\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 0.2083 - val_loss: 0.6455\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 367us/step - loss: 0.1763 - val_loss: 0.6139\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 0.1538 - val_loss: 0.6123\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 408us/step - loss: 0.1311 - val_loss: 0.6129\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 360us/step - loss: 0.1161 - val_loss: 0.6246\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 0.1046 - val_loss: 0.6132\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0914 - val_loss: 0.5974\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0796 - val_loss: 0.6321\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0696 - val_loss: 0.6116\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0619 - val_loss: 0.6192\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0561 - val_loss: 0.6252\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0500 - val_loss: 0.6242\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 0.0453 - val_loss: 0.6252\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 0.0414 - val_loss: 0.6484\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0383 - val_loss: 0.6335\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0343 - val_loss: 0.6368\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 0.0313 - val_loss: 0.6421\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 0.0287 - val_loss: 0.6470\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.0268 - val_loss: 0.6441\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0244 - val_loss: 0.6563\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0227 - val_loss: 0.6575\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 0.0210 - val_loss: 0.6636\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0195 - val_loss: 0.6585\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 0.0182 - val_loss: 0.6611\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0171 - val_loss: 0.6667\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0160 - val_loss: 0.6737\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0150 - val_loss: 0.6806\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0141 - val_loss: 0.6811\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0133 - val_loss: 0.6862\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0125 - val_loss: 0.6862\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0119 - val_loss: 0.6879\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0112 - val_loss: 0.6969\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 0.0106 - val_loss: 0.6948\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0101 - val_loss: 0.6960\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0095 - val_loss: 0.7061\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0091 - val_loss: 0.7079\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0086 - val_loss: 0.7101\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.0082 - val_loss: 0.7201\n",
      "Epoch 51/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 272us/step - loss: 0.0078 - val_loss: 0.7201\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0074 - val_loss: 0.7162\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 0.0071 - val_loss: 0.7174\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 0.0068 - val_loss: 0.7257\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0065 - val_loss: 0.7301\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0062 - val_loss: 0.7337\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 0.0060 - val_loss: 0.7298\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0057 - val_loss: 0.7406\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 0.0055 - val_loss: 0.7403\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0053 - val_loss: 0.7396\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0051 - val_loss: 0.7402\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.0049 - val_loss: 0.7456\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0047 - val_loss: 0.7447\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 0.0046 - val_loss: 0.7510\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 0.0044 - val_loss: 0.7553\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.0042 - val_loss: 0.7576\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0041 - val_loss: 0.7601\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0040 - val_loss: 0.7672\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.0038 - val_loss: 0.7654\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0037 - val_loss: 0.7636\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 427us/step - loss: 0.0036 - val_loss: 0.7661\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 405us/step - loss: 0.0035 - val_loss: 0.7721\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 472us/step - loss: 0.0033 - val_loss: 0.7734\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 0.0032 - val_loss: 0.7729\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 0.0031 - val_loss: 0.7791\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.0030 - val_loss: 0.7811\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 0.0029 - val_loss: 0.7808\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0028 - val_loss: 0.7843\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 0.0028 - val_loss: 0.7855\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0027 - val_loss: 0.7896\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0026 - val_loss: 0.7912\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0025 - val_loss: 0.7918\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0025 - val_loss: 0.7920\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0024 - val_loss: 0.7947\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 0.0023 - val_loss: 0.7974\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0023 - val_loss: 0.8008\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.0022 - val_loss: 0.8020\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0022 - val_loss: 0.8019\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0021 - val_loss: 0.8065\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0020 - val_loss: 0.8066\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 0.0020 - val_loss: 0.8109\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0019 - val_loss: 0.8098\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0019 - val_loss: 0.8137\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.0018 - val_loss: 0.8148\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0018 - val_loss: 0.8168\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0018 - val_loss: 0.8176\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0017 - val_loss: 0.8197\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 0.0017 - val_loss: 0.8212\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0016 - val_loss: 0.8249\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0016 - val_loss: 0.8287\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 0.0016 - val_loss: 0.8264\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0015 - val_loss: 0.8277\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0015 - val_loss: 0.8312\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0015 - val_loss: 0.8334\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0014 - val_loss: 0.8331\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0014 - val_loss: 0.8356\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0014 - val_loss: 0.8378\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 263us/step - loss: 0.0013 - val_loss: 0.8383\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0013 - val_loss: 0.8402\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0013 - val_loss: 0.8398\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0013 - val_loss: 0.8399\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 390us/step - loss: 0.0012 - val_loss: 0.8432\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0012 - val_loss: 0.8447\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 258us/step - loss: 0.0012 - val_loss: 0.8478\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0012 - val_loss: 0.8491\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0011 - val_loss: 0.8512\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 261us/step - loss: 0.0011 - val_loss: 0.8545\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0011 - val_loss: 0.8559\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0011 - val_loss: 0.8573\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 0.0010 - val_loss: 0.8577\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0010 - val_loss: 0.8596\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0010 - val_loss: 0.8622\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 9.9359e-04 - val_loss: 0.8650\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 9.7446e-04 - val_loss: 0.8632\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 259us/step - loss: 9.5476e-04 - val_loss: 0.8641\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 9.3688e-04 - val_loss: 0.8676\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 9.2151e-04 - val_loss: 0.8698\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 9.0351e-04 - val_loss: 0.8705\n",
      "Epoch 129/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 270us/step - loss: 8.8873e-04 - val_loss: 0.8711\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 8.7305e-04 - val_loss: 0.8709\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 8.5666e-04 - val_loss: 0.8726\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 8.4266e-04 - val_loss: 0.8739\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 8.2850e-04 - val_loss: 0.8742\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 8.1429e-04 - val_loss: 0.8747\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 8.0110e-04 - val_loss: 0.8775\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 7.8686e-04 - val_loss: 0.8806\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 7.7485e-04 - val_loss: 0.8828\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 7.6108e-04 - val_loss: 0.8832\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 7.5000e-04 - val_loss: 0.8838\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 7.3666e-04 - val_loss: 0.8853\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 7.2574e-04 - val_loss: 0.8850\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 7.1418e-04 - val_loss: 0.8861\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 7.0284e-04 - val_loss: 0.8876\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 6.9226e-04 - val_loss: 0.8893\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 6.8311e-04 - val_loss: 0.8918\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 6.7133e-04 - val_loss: 0.8920\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 6.5981e-04 - val_loss: 0.8942\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 6.4906e-04 - val_loss: 0.8962\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 261us/step - loss: 6.4100e-04 - val_loss: 0.8981\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 6.3020e-04 - val_loss: 0.8998\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 6.1977e-04 - val_loss: 0.9014\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 6.1053e-04 - val_loss: 0.9018\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 6.0179e-04 - val_loss: 0.9020\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 5.9186e-04 - val_loss: 0.9043\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 5.8340e-04 - val_loss: 0.9059\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 5.7494e-04 - val_loss: 0.9071\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 5.6757e-04 - val_loss: 0.9089\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 5.5833e-04 - val_loss: 0.9104\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 5.5023e-04 - val_loss: 0.9098\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 5.4232e-04 - val_loss: 0.9101\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 5.3339e-04 - val_loss: 0.9117\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 5.2637e-04 - val_loss: 0.9140\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 5.1836e-04 - val_loss: 0.9142\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 5.1157e-04 - val_loss: 0.9155\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 5.0518e-04 - val_loss: 0.9144\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 4.9740e-04 - val_loss: 0.9168\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 4.9040e-04 - val_loss: 0.9178\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 4.8393e-04 - val_loss: 0.9202\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 4.7698e-04 - val_loss: 0.9212\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 4.7044e-04 - val_loss: 0.9235\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 4.6365e-04 - val_loss: 0.9246\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 4.5962e-04 - val_loss: 0.9257\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 4.5282e-04 - val_loss: 0.9258\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 4.4594e-04 - val_loss: 0.9260\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 4.3963e-04 - val_loss: 0.9284\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 4.3396e-04 - val_loss: 0.9306\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 4.2869e-04 - val_loss: 0.9315\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 4.2262e-04 - val_loss: 0.9322\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 4.1759e-04 - val_loss: 0.9331\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 4.1196e-04 - val_loss: 0.9328\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 4.0648e-04 - val_loss: 0.9346\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 4.0130e-04 - val_loss: 0.9372\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 3.9636e-04 - val_loss: 0.9375\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 486us/step - loss: 3.9061e-04 - val_loss: 0.9365\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 495us/step - loss: 3.8561e-04 - val_loss: 0.9392\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 3.8069e-04 - val_loss: 0.9398\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 3.7621e-04 - val_loss: 0.9417\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 3.7086e-04 - val_loss: 0.9419\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 3.6635e-04 - val_loss: 0.9422\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 3.6217e-04 - val_loss: 0.9433\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 3.5727e-04 - val_loss: 0.9449\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 3.5292e-04 - val_loss: 0.9462\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 3.4858e-04 - val_loss: 0.9470\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 3.4393e-04 - val_loss: 0.9478\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 3.4005e-04 - val_loss: 0.9484\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 3.3497e-04 - val_loss: 0.9496\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 3.3102e-04 - val_loss: 0.9519\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 261us/step - loss: 3.2692e-04 - val_loss: 0.9530\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 3.2273e-04 - val_loss: 0.9550\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 3.1883e-04 - val_loss: 0.9576\n",
      "    (0, 1)     tanh A\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 2.1783 - val_loss: 2.0706\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 1.8939 - val_loss: 1.8765\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 1.6662 - val_loss: 1.6820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 1.4549 - val_loss: 1.5136\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 1.2528 - val_loss: 1.3543\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 1.0786 - val_loss: 1.2180\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.9193 - val_loss: 1.0999\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.7724 - val_loss: 1.0037\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.6614 - val_loss: 0.9268\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 0.5643 - val_loss: 0.8613\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.4806 - val_loss: 0.8190\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.4186 - val_loss: 0.7814\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.3683 - val_loss: 0.7555\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.3190 - val_loss: 0.7457\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.2832 - val_loss: 0.7188\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 0.2509 - val_loss: 0.7129\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 0.2298 - val_loss: 0.6867\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 261us/step - loss: 0.2025 - val_loss: 0.6850\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.1809 - val_loss: 0.6757\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.1641 - val_loss: 0.6687\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.1499 - val_loss: 0.6564\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.1362 - val_loss: 0.6583\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 0.1236 - val_loss: 0.6471\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 0.1129 - val_loss: 0.6471\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.1034 - val_loss: 0.6483\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0953 - val_loss: 0.6499\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 259us/step - loss: 0.0879 - val_loss: 0.6396\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 0.0819 - val_loss: 0.6397\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 0.0760 - val_loss: 0.6328\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 261us/step - loss: 0.0708 - val_loss: 0.6325\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0662 - val_loss: 0.6347\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0620 - val_loss: 0.6350\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.0587 - val_loss: 0.6302\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 0.0553 - val_loss: 0.6319\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 0.0522 - val_loss: 0.6311\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0494 - val_loss: 0.6326\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 0.0467 - val_loss: 0.6301\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0445 - val_loss: 0.6292\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 0.0423 - val_loss: 0.6306\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 259us/step - loss: 0.0404 - val_loss: 0.6302\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 0.0385 - val_loss: 0.6280\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0366 - val_loss: 0.6268\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 261us/step - loss: 0.0349 - val_loss: 0.6302\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0334 - val_loss: 0.6334\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0319 - val_loss: 0.6322\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 0.0306 - val_loss: 0.6349\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0294 - val_loss: 0.6306\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0284 - val_loss: 0.6343\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0272 - val_loss: 0.6333\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0261 - val_loss: 0.6339\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0252 - val_loss: 0.6398\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 0.0243 - val_loss: 0.6346\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0235 - val_loss: 0.6375\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0227 - val_loss: 0.6354\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0220 - val_loss: 0.6365\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0213 - val_loss: 0.6390\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0207 - val_loss: 0.6399\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0200 - val_loss: 0.6398\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0194 - val_loss: 0.6382\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0189 - val_loss: 0.6410\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0183 - val_loss: 0.6405\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0178 - val_loss: 0.6437\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0173 - val_loss: 0.6426\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 0.0168 - val_loss: 0.6449\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 0.0164 - val_loss: 0.6458\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0160 - val_loss: 0.6450\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0156 - val_loss: 0.6474\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0152 - val_loss: 0.6492\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0148 - val_loss: 0.6490\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.0144 - val_loss: 0.6493\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0141 - val_loss: 0.6510\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0138 - val_loss: 0.6525\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0135 - val_loss: 0.6522\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 0.0131 - val_loss: 0.6546\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0128 - val_loss: 0.6537\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 0.0125 - val_loss: 0.6563\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0123 - val_loss: 0.6577\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0120 - val_loss: 0.6589\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 263us/step - loss: 0.0117 - val_loss: 0.6576\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0115 - val_loss: 0.6573\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0112 - val_loss: 0.6601\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0110 - val_loss: 0.6626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0108 - val_loss: 0.6625\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.0106 - val_loss: 0.6627\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0104 - val_loss: 0.6648\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0102 - val_loss: 0.6662\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0100 - val_loss: 0.6643\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0098 - val_loss: 0.6672\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0096 - val_loss: 0.6683\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 0.0094 - val_loss: 0.6696\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0092 - val_loss: 0.6695\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0090 - val_loss: 0.6704\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0089 - val_loss: 0.6716\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0087 - val_loss: 0.6730\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0086 - val_loss: 0.6736\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 0.0084 - val_loss: 0.6736\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0083 - val_loss: 0.6748\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 259us/step - loss: 0.0081 - val_loss: 0.6783\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0080 - val_loss: 0.6774\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0079 - val_loss: 0.6772\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0077 - val_loss: 0.6770\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 0.0076 - val_loss: 0.6802\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0075 - val_loss: 0.6809\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.6813\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 515us/step - loss: 0.0072 - val_loss: 0.6830\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 418us/step - loss: 0.0071 - val_loss: 0.6837\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.0070 - val_loss: 0.6844\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 716us/step - loss: 0.0069 - val_loss: 0.6865\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.0068 - val_loss: 0.6872\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 817us/step - loss: 0.0067 - val_loss: 0.6873\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 507us/step - loss: 0.0066 - val_loss: 0.6882\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 365us/step - loss: 0.0065 - val_loss: 0.6890\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 386us/step - loss: 0.0064 - val_loss: 0.6893\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 628us/step - loss: 0.0063 - val_loss: 0.6922\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 0.0062 - val_loss: 0.6921\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.0061 - val_loss: 0.6926\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 0.0060 - val_loss: 0.6915\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.0059 - val_loss: 0.6945\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.0058 - val_loss: 0.6955\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.0058 - val_loss: 0.6961\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.0057 - val_loss: 0.6967\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0056 - val_loss: 0.6973\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0055 - val_loss: 0.7001\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0054 - val_loss: 0.6983\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0054 - val_loss: 0.6991\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.0053 - val_loss: 0.7012\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0052 - val_loss: 0.7023\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0052 - val_loss: 0.7029\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0051 - val_loss: 0.7040\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0050 - val_loss: 0.7059\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 0.0050 - val_loss: 0.7047\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.0049 - val_loss: 0.7054\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 0.0048 - val_loss: 0.7080\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.0048 - val_loss: 0.7076\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.0047 - val_loss: 0.7076\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.0046 - val_loss: 0.7083\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 0.0046 - val_loss: 0.7101\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0045 - val_loss: 0.7087\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.0045 - val_loss: 0.7098\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0044 - val_loss: 0.7099\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0043 - val_loss: 0.7090\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 0.0043 - val_loss: 0.7106\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 0.0042 - val_loss: 0.7111\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0042 - val_loss: 0.7119\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0041 - val_loss: 0.7120\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0041 - val_loss: 0.7134\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0040 - val_loss: 0.7157\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 0.0039 - val_loss: 0.7156\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0039 - val_loss: 0.7164\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0039 - val_loss: 0.7167\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0038 - val_loss: 0.7193\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0038 - val_loss: 0.7204\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 0.0037 - val_loss: 0.7209\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0037 - val_loss: 0.7215\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 263us/step - loss: 0.0036 - val_loss: 0.7218\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0036 - val_loss: 0.7235\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0035 - val_loss: 0.7234\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0035 - val_loss: 0.7243\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 0.0035 - val_loss: 0.7263\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0034 - val_loss: 0.7245\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 297us/step - loss: 0.0034 - val_loss: 0.7248\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.0034 - val_loss: 0.7265\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0033 - val_loss: 0.7277\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0033 - val_loss: 0.7292\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0032 - val_loss: 0.7294\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0032 - val_loss: 0.7296\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0032 - val_loss: 0.7320\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.7325\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 503us/step - loss: 0.0031 - val_loss: 0.7326\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 496us/step - loss: 0.0031 - val_loss: 0.7341\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 865us/step - loss: 0.0030 - val_loss: 0.7346\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.7350\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 713us/step - loss: 0.0030 - val_loss: 0.7361\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 697us/step - loss: 0.0029 - val_loss: 0.7367\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 385us/step - loss: 0.0029 - val_loss: 0.7379\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 362us/step - loss: 0.0029 - val_loss: 0.7388\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 391us/step - loss: 0.0029 - val_loss: 0.7395\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.0028 - val_loss: 0.7404\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0028 - val_loss: 0.7417\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0028 - val_loss: 0.7419\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0027 - val_loss: 0.7426\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0027 - val_loss: 0.7435\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0027 - val_loss: 0.7449\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 562us/step - loss: 0.0027 - val_loss: 0.7456\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 626us/step - loss: 0.0026 - val_loss: 0.7453\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0026 - val_loss: 0.7460\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 0.0026 - val_loss: 0.7466\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 423us/step - loss: 0.0025 - val_loss: 0.7484\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 456us/step - loss: 0.0025 - val_loss: 0.7489\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 613us/step - loss: 0.0025 - val_loss: 0.7497\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 358us/step - loss: 0.0025 - val_loss: 0.7503\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 492us/step - loss: 0.0024 - val_loss: 0.7502\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 365us/step - loss: 0.0024 - val_loss: 0.7509\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 0.0024 - val_loss: 0.7515\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 366us/step - loss: 0.0024 - val_loss: 0.7521\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.0024 - val_loss: 0.7533\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 0.0023 - val_loss: 0.7547\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 0.0023 - val_loss: 0.7549\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 0.0023 - val_loss: 0.7564\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0023 - val_loss: 0.7566\n",
      "    (0, 1)     tanh B\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.4309 - val_loss: 2.3612\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 232us/step - loss: 2.2819 - val_loss: 2.2794\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 2.1702 - val_loss: 2.1990\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 2.0552 - val_loss: 2.1166\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 211us/step - loss: 1.9394 - val_loss: 2.0233\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 174us/step - loss: 1.8226 - val_loss: 1.9149\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 1.7004 - val_loss: 1.8062\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 1.5887 - val_loss: 1.7109\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 226us/step - loss: 1.4732 - val_loss: 1.6263\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 250us/step - loss: 1.3667 - val_loss: 1.5423\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 232us/step - loss: 1.2639 - val_loss: 1.4504\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 251us/step - loss: 1.1637 - val_loss: 1.3717\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 199us/step - loss: 1.0732 - val_loss: 1.2997\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.9884 - val_loss: 1.2356\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.9115 - val_loss: 1.1858\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.8423 - val_loss: 1.1364\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 353us/step - loss: 0.7783 - val_loss: 1.0834\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.7200 - val_loss: 1.0425\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 0.6661 - val_loss: 1.0097\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 0.6202 - val_loss: 0.9806\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 253us/step - loss: 0.5750 - val_loss: 0.9466\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.517 - 0s 338us/step - loss: 0.5355 - val_loss: 0.9203\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 453us/step - loss: 0.5003 - val_loss: 0.8980\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 509us/step - loss: 0.4675 - val_loss: 0.8829\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.4386 - val_loss: 0.8661\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 415us/step - loss: 0.4086 - val_loss: 0.8479\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 0.3848 - val_loss: 0.8324\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.3607 - val_loss: 0.8205\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 952us/step - loss: 0.3399 - val_loss: 0.8115\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 844us/step - loss: 0.3202 - val_loss: 0.8006\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 643us/step - loss: 0.3017 - val_loss: 0.7871\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 531us/step - loss: 0.2849 - val_loss: 0.7800\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 424us/step - loss: 0.2691 - val_loss: 0.7757\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 425us/step - loss: 0.2543 - val_loss: 0.7707\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.2416 - val_loss: 0.7626\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 0.2287 - val_loss: 0.7551\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.2172 - val_loss: 0.7504\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 0.2069 - val_loss: 0.7490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 391us/step - loss: 0.1967 - val_loss: 0.7447\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.1874 - val_loss: 0.7361\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 352us/step - loss: 0.1787 - val_loss: 0.7330\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 0.1704 - val_loss: 0.7337\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 0.1626 - val_loss: 0.7319\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 228us/step - loss: 0.1557 - val_loss: 0.7286\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 248us/step - loss: 0.1487 - val_loss: 0.7249\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.1425 - val_loss: 0.7235\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.1364 - val_loss: 0.7232\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 449us/step - loss: 0.1311 - val_loss: 0.7233\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.1260 - val_loss: 0.7212\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 238us/step - loss: 0.1210 - val_loss: 0.7182\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 398us/step - loss: 0.1165 - val_loss: 0.7163\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 240us/step - loss: 0.1123 - val_loss: 0.7148\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 0.1085 - val_loss: 0.7137\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.1046 - val_loss: 0.7144\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 459us/step - loss: 0.1011 - val_loss: 0.7123\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 226us/step - loss: 0.0977 - val_loss: 0.7110\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0946 - val_loss: 0.7111\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 252us/step - loss: 0.0916 - val_loss: 0.7098\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 408us/step - loss: 0.0887 - val_loss: 0.7095\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.0861 - val_loss: 0.7080\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 259us/step - loss: 0.0835 - val_loss: 0.7069\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 239us/step - loss: 0.0810 - val_loss: 0.7076\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 216us/step - loss: 0.0787 - val_loss: 0.7068\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 258us/step - loss: 0.0765 - val_loss: 0.7054\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 249us/step - loss: 0.0744 - val_loss: 0.7061\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0725 - val_loss: 0.7042\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0705 - val_loss: 0.7038\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 226us/step - loss: 0.0687 - val_loss: 0.7037\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.0670 - val_loss: 0.7045\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0652 - val_loss: 0.7039\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 201us/step - loss: 0.0636 - val_loss: 0.7031\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 178us/step - loss: 0.0620 - val_loss: 0.7028\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 0.0605 - val_loss: 0.7027\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 211us/step - loss: 0.0590 - val_loss: 0.7032\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 206us/step - loss: 0.0577 - val_loss: 0.7025\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 185us/step - loss: 0.0563 - val_loss: 0.7018\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.0550 - val_loss: 0.7013\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 202us/step - loss: 0.0538 - val_loss: 0.7011\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0526 - val_loss: 0.7016\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 188us/step - loss: 0.0514 - val_loss: 0.7015\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 213us/step - loss: 0.0503 - val_loss: 0.7005\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 259us/step - loss: 0.0492 - val_loss: 0.7010\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 216us/step - loss: 0.0481 - val_loss: 0.7011\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0471 - val_loss: 0.7016\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 229us/step - loss: 0.0462 - val_loss: 0.7014\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 219us/step - loss: 0.0452 - val_loss: 0.7014\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0443 - val_loss: 0.7006\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 206us/step - loss: 0.0434 - val_loss: 0.7010\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 195us/step - loss: 0.0425 - val_loss: 0.7011\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 169us/step - loss: 0.0417 - val_loss: 0.7012\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 181us/step - loss: 0.0409 - val_loss: 0.7015\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0401 - val_loss: 0.7008\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 178us/step - loss: 0.0393 - val_loss: 0.7006\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 168us/step - loss: 0.0386 - val_loss: 0.7012\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 172us/step - loss: 0.0378 - val_loss: 0.7015\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 263us/step - loss: 0.0372 - val_loss: 0.7017\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 0.0365 - val_loss: 0.7014\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 188us/step - loss: 0.0358 - val_loss: 0.7015\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 180us/step - loss: 0.0351 - val_loss: 0.7021\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0345 - val_loss: 0.7025\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 0.0339 - val_loss: 0.7025\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 247us/step - loss: 0.0333 - val_loss: 0.7028\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 483us/step - loss: 0.0328 - val_loss: 0.7029\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 445us/step - loss: 0.0322 - val_loss: 0.7034\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 212us/step - loss: 0.0316 - val_loss: 0.7030\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0311 - val_loss: 0.7036\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 206us/step - loss: 0.0306 - val_loss: 0.7042\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0301 - val_loss: 0.7045\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 0.0296 - val_loss: 0.7043\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 201us/step - loss: 0.0291 - val_loss: 0.7057\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.0286 - val_loss: 0.7054\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 194us/step - loss: 0.0282 - val_loss: 0.7049\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 238us/step - loss: 0.0277 - val_loss: 0.7052\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 232us/step - loss: 0.0273 - val_loss: 0.7064\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 362us/step - loss: 0.0269 - val_loss: 0.7078\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0265 - val_loss: 0.7080\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 271us/step - loss: 0.0261 - val_loss: 0.7077\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 211us/step - loss: 0.0257 - val_loss: 0.7072\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 0.0253 - val_loss: 0.7075\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 181us/step - loss: 0.0249 - val_loss: 0.7085\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.0245 - val_loss: 0.7095\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 0.0242 - val_loss: 0.7091\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0238 - val_loss: 0.7084\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 233us/step - loss: 0.0235 - val_loss: 0.7079\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.0231 - val_loss: 0.7092\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 206us/step - loss: 0.0228 - val_loss: 0.7108\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 220us/step - loss: 0.0225 - val_loss: 0.7115\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0222 - val_loss: 0.7113\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0219 - val_loss: 0.7111\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.0216 - val_loss: 0.7116\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 355us/step - loss: 0.0213 - val_loss: 0.7120\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 256us/step - loss: 0.0210 - val_loss: 0.7125\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 0.0207 - val_loss: 0.7131\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0204 - val_loss: 0.7139\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 199us/step - loss: 0.0202 - val_loss: 0.7149\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0199 - val_loss: 0.7152\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 205us/step - loss: 0.0196 - val_loss: 0.7152\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 0.0194 - val_loss: 0.7153\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 181us/step - loss: 0.0191 - val_loss: 0.7156\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 207us/step - loss: 0.0189 - val_loss: 0.7160\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 0.0186 - val_loss: 0.7163\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0184 - val_loss: 0.7171\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 174us/step - loss: 0.0182 - val_loss: 0.7183\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 204us/step - loss: 0.0180 - val_loss: 0.7191\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 230us/step - loss: 0.0177 - val_loss: 0.7189\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 215us/step - loss: 0.0175 - val_loss: 0.7194\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0173 - val_loss: 0.7204\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 184us/step - loss: 0.0171 - val_loss: 0.7207\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 199us/step - loss: 0.0169 - val_loss: 0.7211\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 192us/step - loss: 0.0167 - val_loss: 0.7217\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 218us/step - loss: 0.0165 - val_loss: 0.7218\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 214us/step - loss: 0.0163 - val_loss: 0.7224\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0161 - val_loss: 0.7232\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 195us/step - loss: 0.0159 - val_loss: 0.7237\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 246us/step - loss: 0.0157 - val_loss: 0.7243\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 197us/step - loss: 0.0156 - val_loss: 0.7250\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 231us/step - loss: 0.0154 - val_loss: 0.7250\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 399us/step - loss: 0.0152 - val_loss: 0.7255\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 373us/step - loss: 0.0151 - val_loss: 0.7264\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0149 - val_loss: 0.7271\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 410us/step - loss: 0.0147 - val_loss: 0.7278\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 419us/step - loss: 0.0146 - val_loss: 0.7281\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0144 - val_loss: 0.7286\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0143 - val_loss: 0.7288\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 244us/step - loss: 0.0141 - val_loss: 0.7293\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 193us/step - loss: 0.0140 - val_loss: 0.7297\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 263us/step - loss: 0.0138 - val_loss: 0.7307\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 0.0137 - val_loss: 0.7312\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 370us/step - loss: 0.0135 - val_loss: 0.7318\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.0134 - val_loss: 0.7321\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0132 - val_loss: 0.7330\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0131 - val_loss: 0.7334\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 381us/step - loss: 0.0130 - val_loss: 0.7342\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0128 - val_loss: 0.7345\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0127 - val_loss: 0.7349\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0126 - val_loss: 0.7357\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 209us/step - loss: 0.0125 - val_loss: 0.7363\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 196us/step - loss: 0.0123 - val_loss: 0.7366\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.012 - 0s 193us/step - loss: 0.0122 - val_loss: 0.7372\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 227us/step - loss: 0.0121 - val_loss: 0.7373\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 391us/step - loss: 0.0120 - val_loss: 0.7380\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 245us/step - loss: 0.0119 - val_loss: 0.7389\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 196us/step - loss: 0.0118 - val_loss: 0.7394\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0116 - val_loss: 0.7400\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 198us/step - loss: 0.0115 - val_loss: 0.7404\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.0114 - val_loss: 0.7404\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 224us/step - loss: 0.0113 - val_loss: 0.7409\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 253us/step - loss: 0.0112 - val_loss: 0.7412\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0111 - val_loss: 0.7421\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 251us/step - loss: 0.0110 - val_loss: 0.7431\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 201us/step - loss: 0.0109 - val_loss: 0.7434\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 225us/step - loss: 0.0108 - val_loss: 0.7437\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 0.0107 - val_loss: 0.7443\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.0106 - val_loss: 0.7446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 425us/step - loss: 0.0105 - val_loss: 0.7450\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 0.0104 - val_loss: 0.7454\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0103 - val_loss: 0.7459\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 357us/step - loss: 0.0102 - val_loss: 0.7465\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0102 - val_loss: 0.7469\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 256us/step - loss: 0.0101 - val_loss: 0.7472\n",
      "    (0, 1)     tanh C\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2214 - val_loss: 2.0980\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 517us/step - loss: 1.8916 - val_loss: 1.8445\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 437us/step - loss: 1.5783 - val_loss: 1.5974\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 521us/step - loss: 1.2841 - val_loss: 1.3487\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 562us/step - loss: 1.0085 - val_loss: 1.1407\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 538us/step - loss: 0.7864 - val_loss: 1.0073\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 421us/step - loss: 0.6303 - val_loss: 0.8970\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 398us/step - loss: 0.5109 - val_loss: 0.8269\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 374us/step - loss: 0.4309 - val_loss: 0.7843\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.3605 - val_loss: 0.7483\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.3064 - val_loss: 0.7108\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.2687 - val_loss: 0.7082\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 384us/step - loss: 0.2228 - val_loss: 0.6771\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 358us/step - loss: 0.1907 - val_loss: 0.6892\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 498us/step - loss: 0.1629 - val_loss: 0.6663\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.1398 - val_loss: 0.6565\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 403us/step - loss: 0.1233 - val_loss: 0.6610\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 382us/step - loss: 0.1103 - val_loss: 0.6488\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 387us/step - loss: 0.0937 - val_loss: 0.6655\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 468us/step - loss: 0.0810 - val_loss: 0.6496\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 373us/step - loss: 0.0729 - val_loss: 0.6563\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.0647 - val_loss: 0.6501\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 0.0575 - val_loss: 0.6621\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 370us/step - loss: 0.0526 - val_loss: 0.6631\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 362us/step - loss: 0.0466 - val_loss: 0.6595\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 393us/step - loss: 0.0428 - val_loss: 0.6577\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 367us/step - loss: 0.0392 - val_loss: 0.6668\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.0348 - val_loss: 0.6769\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 0.0323 - val_loss: 0.6783\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 0.0300 - val_loss: 0.6792\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 0.0271 - val_loss: 0.6834\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.0248 - val_loss: 0.6792\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 0.0229 - val_loss: 0.6929\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 393us/step - loss: 0.0213 - val_loss: 0.6885\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 402us/step - loss: 0.0196 - val_loss: 0.6961\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 0.0183 - val_loss: 0.6975\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 379us/step - loss: 0.0173 - val_loss: 0.7013\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 379us/step - loss: 0.0161 - val_loss: 0.7020\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 0.0152 - val_loss: 0.7045\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.0143 - val_loss: 0.7144\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 409us/step - loss: 0.0134 - val_loss: 0.7144\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 420us/step - loss: 0.0126 - val_loss: 0.7111\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 369us/step - loss: 0.0119 - val_loss: 0.7156\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 361us/step - loss: 0.0113 - val_loss: 0.7234\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.0107 - val_loss: 0.7217\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0102 - val_loss: 0.7240\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 358us/step - loss: 0.0097 - val_loss: 0.7278\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 0.0093 - val_loss: 0.7273\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.0088 - val_loss: 0.7361\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0084 - val_loss: 0.7424\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.0080 - val_loss: 0.7386\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 0.0077 - val_loss: 0.7440\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 370us/step - loss: 0.0073 - val_loss: 0.7467\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 425us/step - loss: 0.0070 - val_loss: 0.7473\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 355us/step - loss: 0.0067 - val_loss: 0.7507\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0065 - val_loss: 0.7526\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 660us/step - loss: 0.0062 - val_loss: 0.7548\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 464us/step - loss: 0.0060 - val_loss: 0.7552\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 0.0058 - val_loss: 0.7634\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 373us/step - loss: 0.0056 - val_loss: 0.7613\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 369us/step - loss: 0.0054 - val_loss: 0.7654\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.0052 - val_loss: 0.7675\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 353us/step - loss: 0.0050 - val_loss: 0.7691\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0048 - val_loss: 0.7696\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0047 - val_loss: 0.7735\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 370us/step - loss: 0.0045 - val_loss: 0.7712\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 365us/step - loss: 0.0044 - val_loss: 0.7781\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 0.0042 - val_loss: 0.7804\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 388us/step - loss: 0.0041 - val_loss: 0.7825\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.0040 - val_loss: 0.7828\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0038 - val_loss: 0.7834\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 373us/step - loss: 0.0037 - val_loss: 0.7862\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 356us/step - loss: 0.0036 - val_loss: 0.7885\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 377us/step - loss: 0.0035 - val_loss: 0.7899\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 370us/step - loss: 0.0034 - val_loss: 0.7932\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 0.0033 - val_loss: 0.7952\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 368us/step - loss: 0.0032 - val_loss: 0.7964\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 360us/step - loss: 0.0031 - val_loss: 0.7973\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 0.0030 - val_loss: 0.8005\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 0.0029 - val_loss: 0.8053\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 0.0029 - val_loss: 0.8064\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 374us/step - loss: 0.0028 - val_loss: 0.8050\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0027 - val_loss: 0.8057\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0027 - val_loss: 0.8084\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0026 - val_loss: 0.8101\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 0.0025 - val_loss: 0.8114\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 446us/step - loss: 0.0025 - val_loss: 0.8131\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0024 - val_loss: 0.8166\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 0.0023 - val_loss: 0.8157\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 369us/step - loss: 0.0023 - val_loss: 0.8170\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 424us/step - loss: 0.0022 - val_loss: 0.8197\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 410us/step - loss: 0.0022 - val_loss: 0.8217\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 401us/step - loss: 0.0021 - val_loss: 0.8240\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 419us/step - loss: 0.0021 - val_loss: 0.8246\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 458us/step - loss: 0.0020 - val_loss: 0.8261\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 463us/step - loss: 0.0020 - val_loss: 0.8295\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 425us/step - loss: 0.0019 - val_loss: 0.8319\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 410us/step - loss: 0.0019 - val_loss: 0.8335\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 383us/step - loss: 0.0018 - val_loss: 0.8361\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.0018 - val_loss: 0.8381\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.0018 - val_loss: 0.8368\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 0.0017 - val_loss: 0.8371\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 0.0017 - val_loss: 0.8387\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 0.0017 - val_loss: 0.8402\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 349us/step - loss: 0.0016 - val_loss: 0.8415\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 0.0016 - val_loss: 0.8460\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.0016 - val_loss: 0.8456\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 0.0015 - val_loss: 0.8467\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 0.0015 - val_loss: 0.8459\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0015 - val_loss: 0.8469\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.0014 - val_loss: 0.8496\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 364us/step - loss: 0.0014 - val_loss: 0.8516\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0014 - val_loss: 0.8516\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 353us/step - loss: 0.0014 - val_loss: 0.8537\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.0013 - val_loss: 0.8546\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 372us/step - loss: 0.0013 - val_loss: 0.8566\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 0.0013 - val_loss: 0.8586\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 353us/step - loss: 0.0013 - val_loss: 0.8590\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0012 - val_loss: 0.8602\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 0.0012 - val_loss: 0.8622\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 381us/step - loss: 0.0012 - val_loss: 0.8625\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 349us/step - loss: 0.0012 - val_loss: 0.8633\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0011 - val_loss: 0.8642\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0011 - val_loss: 0.8645\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.0011 - val_loss: 0.8659\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 353us/step - loss: 0.0011 - val_loss: 0.8679\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 361us/step - loss: 0.0011 - val_loss: 0.8699\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 0.0010 - val_loss: 0.8705\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 349us/step - loss: 0.0010 - val_loss: 0.8731\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 349us/step - loss: 0.0010 - val_loss: 0.8732\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 9.9113e-04 - val_loss: 0.8746\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 9.7736e-04 - val_loss: 0.8753\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 9.5729e-04 - val_loss: 0.8744\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 9.4391e-04 - val_loss: 0.8756\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 9.2678e-04 - val_loss: 0.8787\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 9.1211e-04 - val_loss: 0.8809\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 349us/step - loss: 8.9681e-04 - val_loss: 0.8799\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 8.8126e-04 - val_loss: 0.8828\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 397us/step - loss: 8.6792e-04 - val_loss: 0.8862\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 384us/step - loss: 8.5586e-04 - val_loss: 0.8892\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 373us/step - loss: 8.4025e-04 - val_loss: 0.8881\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 352us/step - loss: 8.2847e-04 - val_loss: 0.8896\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 8.1619e-04 - val_loss: 0.8881\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 379us/step - loss: 8.0248e-04 - val_loss: 0.8883\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 358us/step - loss: 7.9032e-04 - val_loss: 0.8898\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 364us/step - loss: 7.7835e-04 - val_loss: 0.8902\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 365us/step - loss: 7.6658e-04 - val_loss: 0.8940\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 366us/step - loss: 7.5477e-04 - val_loss: 0.8941\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 355us/step - loss: 7.4338e-04 - val_loss: 0.8947\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 384us/step - loss: 7.3255e-04 - val_loss: 0.8978\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 7.2152e-04 - val_loss: 0.8976\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 7.1020e-04 - val_loss: 0.8998\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 6.9850e-04 - val_loss: 0.9003\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 6.8990e-04 - val_loss: 0.9005\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 6.7805e-04 - val_loss: 0.9024\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 6.6973e-04 - val_loss: 0.9033\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 6.5918e-04 - val_loss: 0.9034\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 6.5229e-04 - val_loss: 0.9069\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 6.4010e-04 - val_loss: 0.9045\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 6.3162e-04 - val_loss: 0.9057\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 6.2344e-04 - val_loss: 0.9081\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 6.1300e-04 - val_loss: 0.9108\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 6.0528e-04 - val_loss: 0.9130\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 5.9696e-04 - val_loss: 0.9134\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 5.8779e-04 - val_loss: 0.9131\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 5.7972e-04 - val_loss: 0.9138\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 5.7197e-04 - val_loss: 0.9138\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 5.6427e-04 - val_loss: 0.9156\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 5.5662e-04 - val_loss: 0.9157\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 5.4937e-04 - val_loss: 0.9166\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 5.4196e-04 - val_loss: 0.9183\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 5.3506e-04 - val_loss: 0.9192\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 5.2826e-04 - val_loss: 0.9202\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 5.2131e-04 - val_loss: 0.9199\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 5.1407e-04 - val_loss: 0.9198\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 5.0790e-04 - val_loss: 0.9221\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 5.0100e-04 - val_loss: 0.9235\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 4.9440e-04 - val_loss: 0.9249\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 4.8819e-04 - val_loss: 0.9251\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 4.8192e-04 - val_loss: 0.9266\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 4.7553e-04 - val_loss: 0.9278\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 4.6938e-04 - val_loss: 0.9276\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 4.6350e-04 - val_loss: 0.9291\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 4.5778e-04 - val_loss: 0.9295\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 4.5196e-04 - val_loss: 0.9326\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 4.4605e-04 - val_loss: 0.9330\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 4.4141e-04 - val_loss: 0.9346\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 4.3543e-04 - val_loss: 0.9339\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 4.2990e-04 - val_loss: 0.9351\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 4.2448e-04 - val_loss: 0.9356\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 4.2036e-04 - val_loss: 0.9363\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 4.1497e-04 - val_loss: 0.9385\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 4.0975e-04 - val_loss: 0.9384\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 4.0474e-04 - val_loss: 0.9402\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 4.0054e-04 - val_loss: 0.9411\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 3.9500e-04 - val_loss: 0.9415\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 3.9048e-04 - val_loss: 0.9421\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 3.8582e-04 - val_loss: 0.9434\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 3.8138e-04 - val_loss: 0.9443\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 3.7698e-04 - val_loss: 0.9435\n",
      " (-0.5, 2)   linear A\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 2.2581 - val_loss: 2.1350\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 1.9458 - val_loss: 1.8579\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 1.6181 - val_loss: 1.5380\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 1.2846 - val_loss: 1.2478\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.9750 - val_loss: 1.0382\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.7561 - val_loss: 0.8782\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.5891 - val_loss: 0.8008\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.4692 - val_loss: 0.7348\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.3729 - val_loss: 0.6779\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.3029 - val_loss: 0.6672\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.2472 - val_loss: 0.6379\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 354us/step - loss: 0.2022 - val_loss: 0.6170\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.1652 - val_loss: 0.6109\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.1332 - val_loss: 0.5986\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 261us/step - loss: 0.1148 - val_loss: 0.6064\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0911 - val_loss: 0.5967\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0766 - val_loss: 0.6089\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 0.0653 - val_loss: 0.5907\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0544 - val_loss: 0.6050\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0476 - val_loss: 0.6151\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0404 - val_loss: 0.6157\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0360 - val_loss: 0.6130\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0306 - val_loss: 0.6241\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0275 - val_loss: 0.6237\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0241 - val_loss: 0.6289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0215 - val_loss: 0.6305\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0196 - val_loss: 0.6380\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0178 - val_loss: 0.6387\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0162 - val_loss: 0.6546\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.0148 - val_loss: 0.6471\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0136 - val_loss: 0.6500\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0123 - val_loss: 0.6535\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0114 - val_loss: 0.6673\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0106 - val_loss: 0.6675\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0097 - val_loss: 0.6688\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.0091 - val_loss: 0.6819\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0085 - val_loss: 0.6767\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0079 - val_loss: 0.6790\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0074 - val_loss: 0.6922\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0069 - val_loss: 0.6865\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0065 - val_loss: 0.6876\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0061 - val_loss: 0.6981\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0058 - val_loss: 0.6963\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0055 - val_loss: 0.6929\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0052 - val_loss: 0.6979\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0049 - val_loss: 0.7092\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0047 - val_loss: 0.7093\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0044 - val_loss: 0.7096\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0042 - val_loss: 0.7138\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0040 - val_loss: 0.7159\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.0038 - val_loss: 0.7209\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 0.0037 - val_loss: 0.7213\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0035 - val_loss: 0.7258\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0034 - val_loss: 0.7353\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 0.0032 - val_loss: 0.7340\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 0.0031 - val_loss: 0.7316\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.0029 - val_loss: 0.7330\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 263us/step - loss: 0.0028 - val_loss: 0.7433\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0027 - val_loss: 0.7502\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0026 - val_loss: 0.7479\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0025 - val_loss: 0.7479\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0024 - val_loss: 0.7516\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0023 - val_loss: 0.7510\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0022 - val_loss: 0.7560\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0021 - val_loss: 0.7607\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0020 - val_loss: 0.7634\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0020 - val_loss: 0.7650\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.0019 - val_loss: 0.7641\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0018 - val_loss: 0.7670\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0018 - val_loss: 0.7694\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0017 - val_loss: 0.7735\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0017 - val_loss: 0.7778\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0016 - val_loss: 0.7775\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0016 - val_loss: 0.7767\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0015 - val_loss: 0.7811\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0015 - val_loss: 0.7845\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0014 - val_loss: 0.7854\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0014 - val_loss: 0.7868\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0013 - val_loss: 0.7879\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.001 - 0s 333us/step - loss: 0.0013 - val_loss: 0.7891\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 378us/step - loss: 0.0013 - val_loss: 0.7911\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 379us/step - loss: 0.0012 - val_loss: 0.7955\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 379us/step - loss: 0.0012 - val_loss: 0.7979\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 394us/step - loss: 0.0012 - val_loss: 0.7980\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.0011 - val_loss: 0.8001\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.0011 - val_loss: 0.8006\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 366us/step - loss: 0.0011 - val_loss: 0.8052\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 361us/step - loss: 0.0010 - val_loss: 0.8075\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 414us/step - loss: 0.0010 - val_loss: 0.8096\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 386us/step - loss: 9.9173e-04 - val_loss: 0.8098\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 381us/step - loss: 9.6567e-04 - val_loss: 0.8153\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 591us/step - loss: 9.4047e-04 - val_loss: 0.8162\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 425us/step - loss: 9.1718e-04 - val_loss: 0.8180\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 421us/step - loss: 8.9495e-04 - val_loss: 0.8187\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 511us/step - loss: 8.7438e-04 - val_loss: 0.8198\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 8.5085e-04 - val_loss: 0.8228\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 8.3221e-04 - val_loss: 0.8252\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 8.1461e-04 - val_loss: 0.8263\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 403us/step - loss: 7.9455e-04 - val_loss: 0.8281\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 393us/step - loss: 7.7705e-04 - val_loss: 0.8293\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 7.6055e-04 - val_loss: 0.8299\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 547us/step - loss: 7.4111e-04 - val_loss: 0.8312\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 427us/step - loss: 7.2408e-04 - val_loss: 0.8331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 951us/step - loss: 7.0744e-04 - val_loss: 0.8350\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 6.9191e-04 - val_loss: 0.8364\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 6.7826e-04 - val_loss: 0.8386\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 6.6270e-04 - val_loss: 0.8404\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 6.4900e-04 - val_loss: 0.8425\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 6.3664e-04 - val_loss: 0.8462\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 373us/step - loss: 6.2249e-04 - val_loss: 0.8458\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 6.0961e-04 - val_loss: 0.8461\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 5.9633e-04 - val_loss: 0.8474\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 5.8481e-04 - val_loss: 0.8487\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 5.7250e-04 - val_loss: 0.8510\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 5.6132e-04 - val_loss: 0.8528\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 5.5053e-04 - val_loss: 0.8545\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 427us/step - loss: 5.3993e-04 - val_loss: 0.8551\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 631us/step - loss: 5.2888e-04 - val_loss: 0.8565\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 5.1869e-04 - val_loss: 0.8571\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 373us/step - loss: 5.0967e-04 - val_loss: 0.8596\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 590us/step - loss: 4.9917e-04 - val_loss: 0.8613\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 501us/step - loss: 4.8945e-04 - val_loss: 0.8622\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 457us/step - loss: 4.8054e-04 - val_loss: 0.8622\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 4.7176e-04 - val_loss: 0.8633\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 4.6457e-04 - val_loss: 0.8675\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 4.5422e-04 - val_loss: 0.8684\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 4.4615e-04 - val_loss: 0.8701\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 4.3787e-04 - val_loss: 0.8700\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 4.3041e-04 - val_loss: 0.8726\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 4.2398e-04 - val_loss: 0.8719\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 363us/step - loss: 4.1554e-04 - val_loss: 0.8748\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 4.0968e-04 - val_loss: 0.8766\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 4.0233e-04 - val_loss: 0.8766\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 3.9460e-04 - val_loss: 0.8792\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 3.8867e-04 - val_loss: 0.8805\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 3.8187e-04 - val_loss: 0.8822\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 352us/step - loss: 3.7523e-04 - val_loss: 0.8816\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 3.6961e-04 - val_loss: 0.8830\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 263us/step - loss: 3.6349e-04 - val_loss: 0.8839\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 3.5700e-04 - val_loss: 0.8845\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 3.5131e-04 - val_loss: 0.8866\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 3.4516e-04 - val_loss: 0.8878\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 3.4029e-04 - val_loss: 0.8864\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 379us/step - loss: 3.3429e-04 - val_loss: 0.8892\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 643us/step - loss: 3.2883e-04 - val_loss: 0.8913\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 552us/step - loss: 3.2350e-04 - val_loss: 0.8915\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 588us/step - loss: 3.1841e-04 - val_loss: 0.8923\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 451us/step - loss: 3.1382e-04 - val_loss: 0.8920\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 3.0808e-04 - val_loss: 0.8944\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 3.0357e-04 - val_loss: 0.8969\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 2.9905e-04 - val_loss: 0.8981\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 2.9375e-04 - val_loss: 0.8976\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 365us/step - loss: 2.8984e-04 - val_loss: 0.8999\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 2.8527e-04 - val_loss: 0.9026\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 2.8078e-04 - val_loss: 0.9035\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 2.7651e-04 - val_loss: 0.9054\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 2.7223e-04 - val_loss: 0.9067\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 2.6803e-04 - val_loss: 0.9062\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 2.6445e-04 - val_loss: 0.9062\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 2.6033e-04 - val_loss: 0.9092\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 2.5638e-04 - val_loss: 0.9094\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 2.5306e-04 - val_loss: 0.9111\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 2.4987e-04 - val_loss: 0.9093\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 368us/step - loss: 2.4628e-04 - val_loss: 0.9104\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 2.4239e-04 - val_loss: 0.9120\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 2.3889e-04 - val_loss: 0.9140\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 2.3496e-04 - val_loss: 0.9145\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 2.3159e-04 - val_loss: 0.9158\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 362us/step - loss: 2.2835e-04 - val_loss: 0.9171\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 384us/step - loss: 2.2516e-04 - val_loss: 0.9177\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 429us/step - loss: 2.2224e-04 - val_loss: 0.9191\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 399us/step - loss: 2.1902e-04 - val_loss: 0.9198\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 371us/step - loss: 2.1621e-04 - val_loss: 0.9220\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 2.1313e-04 - val_loss: 0.9224\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 2.1044e-04 - val_loss: 0.9241\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 2.0727e-04 - val_loss: 0.9249\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 2.0497e-04 - val_loss: 0.9257\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 2.0160e-04 - val_loss: 0.9266\n",
      "Epoch 179/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 340us/step - loss: 1.9910e-04 - val_loss: 0.9276\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 355us/step - loss: 1.9643e-04 - val_loss: 0.9284\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 1.9403e-04 - val_loss: 0.9279\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 1.9167e-04 - val_loss: 0.9308\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 1.8888e-04 - val_loss: 0.9321\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 1.8617e-04 - val_loss: 0.9325\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 1.8390e-04 - val_loss: 0.9332\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 1.8189e-04 - val_loss: 0.9339\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 1.7925e-04 - val_loss: 0.9351\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 1.7725e-04 - val_loss: 0.9362\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 1.7520e-04 - val_loss: 0.9378\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 1.7270e-04 - val_loss: 0.9378\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 1.7074e-04 - val_loss: 0.9383\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 381us/step - loss: 1.6858e-04 - val_loss: 0.9403\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 1.6648e-04 - val_loss: 0.9412\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 1.6453e-04 - val_loss: 0.9421\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 1.6259e-04 - val_loss: 0.9423\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 1.6055e-04 - val_loss: 0.9443\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 1.5846e-04 - val_loss: 0.9444\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 374us/step - loss: 1.5642e-04 - val_loss: 0.9454\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 1.5467e-04 - val_loss: 0.9461\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 1.5259e-04 - val_loss: 0.9467\n",
      " (-0.5, 2)   linear B\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.4622 - val_loss: 2.3833\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 245us/step - loss: 2.2719 - val_loss: 2.2539\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 248us/step - loss: 2.1105 - val_loss: 2.1206\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 258us/step - loss: 1.9444 - val_loss: 1.9808\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 216us/step - loss: 1.7744 - val_loss: 1.8374\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 1.6073 - val_loss: 1.6982\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 172us/step - loss: 1.4506 - val_loss: 1.5671\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 201us/step - loss: 1.3024 - val_loss: 1.4474\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 1.1599 - val_loss: 1.3319\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 1.0353 - val_loss: 1.2323\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 186us/step - loss: 0.9216 - val_loss: 1.1425\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 177us/step - loss: 0.8207 - val_loss: 1.0646\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 0.7305 - val_loss: 1.0002\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 171us/step - loss: 0.6523 - val_loss: 0.9435\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 0.5866 - val_loss: 0.8984\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.5237 - val_loss: 0.8581\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 171us/step - loss: 0.4669 - val_loss: 0.8270\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 191us/step - loss: 0.4209 - val_loss: 0.8003\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 241us/step - loss: 0.3763 - val_loss: 0.7724\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 252us/step - loss: 0.3385 - val_loss: 0.7520\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 143us/step - loss: 0.3012 - val_loss: 0.7445\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.2721 - val_loss: 0.7323\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.2450 - val_loss: 0.7175\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.2183 - val_loss: 0.7050\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.1981 - val_loss: 0.6947\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.1778 - val_loss: 0.6958\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.1598 - val_loss: 0.6941\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.1442 - val_loss: 0.6820\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.1293 - val_loss: 0.6725\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.1165 - val_loss: 0.6754\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.1053 - val_loss: 0.6806\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.0954 - val_loss: 0.6917\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 0.0873 - val_loss: 0.6820\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 186us/step - loss: 0.0792 - val_loss: 0.6748\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 0.0726 - val_loss: 0.6728\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.0661 - val_loss: 0.6791\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0604 - val_loss: 0.6909\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0557 - val_loss: 0.6937\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.0510 - val_loss: 0.6890\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.0472 - val_loss: 0.6915\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 243us/step - loss: 0.0435 - val_loss: 0.6936\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 0.0407 - val_loss: 0.6936\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0378 - val_loss: 0.7007\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0353 - val_loss: 0.7047\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0330 - val_loss: 0.7074\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 0.0310 - val_loss: 0.7096\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 252us/step - loss: 0.0289 - val_loss: 0.7092\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.0273 - val_loss: 0.7101\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 0.0257 - val_loss: 0.7137\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 174us/step - loss: 0.0242 - val_loss: 0.7182\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 0.0230 - val_loss: 0.7200\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0219 - val_loss: 0.7250\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 175us/step - loss: 0.0207 - val_loss: 0.7260\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0197 - val_loss: 0.7270\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0188 - val_loss: 0.7307\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 164us/step - loss: 0.0178 - val_loss: 0.7334\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 229us/step - loss: 0.0170 - val_loss: 0.7374\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0162 - val_loss: 0.7387\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0155 - val_loss: 0.7419\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 200us/step - loss: 0.0149 - val_loss: 0.7415\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 177us/step - loss: 0.0142 - val_loss: 0.7440\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 169us/step - loss: 0.0137 - val_loss: 0.7479\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0131 - val_loss: 0.7516\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 0.0126 - val_loss: 0.7548\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.0121 - val_loss: 0.7560\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0117 - val_loss: 0.7562\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.0113 - val_loss: 0.7581\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 177us/step - loss: 0.0108 - val_loss: 0.7606\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 251us/step - loss: 0.0105 - val_loss: 0.7642\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0101 - val_loss: 0.7650\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 249us/step - loss: 0.0098 - val_loss: 0.7673\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 168us/step - loss: 0.0094 - val_loss: 0.7697\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0091 - val_loss: 0.7718\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.0088 - val_loss: 0.7743\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 170us/step - loss: 0.0086 - val_loss: 0.7767\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 175us/step - loss: 0.0083 - val_loss: 0.7782\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.0081 - val_loss: 0.7801\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 178us/step - loss: 0.0078 - val_loss: 0.7817\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 178us/step - loss: 0.0076 - val_loss: 0.7831\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 181us/step - loss: 0.0074 - val_loss: 0.7841\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 185us/step - loss: 0.0072 - val_loss: 0.7857\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 174us/step - loss: 0.0069 - val_loss: 0.7891\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 171us/step - loss: 0.0067 - val_loss: 0.7907\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 174us/step - loss: 0.0066 - val_loss: 0.7915\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 169us/step - loss: 0.0064 - val_loss: 0.7945\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.0062 - val_loss: 0.7969\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 0.0061 - val_loss: 0.7991\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 196us/step - loss: 0.0059 - val_loss: 0.8007\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 199us/step - loss: 0.0058 - val_loss: 0.8013\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 0.0056 - val_loss: 0.8025\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 257us/step - loss: 0.0055 - val_loss: 0.8048\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 226us/step - loss: 0.0053 - val_loss: 0.8065\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 217us/step - loss: 0.0052 - val_loss: 0.8084\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.0051 - val_loss: 0.8103\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0050 - val_loss: 0.8111\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0049 - val_loss: 0.8136\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 263us/step - loss: 0.0047 - val_loss: 0.8145\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 0.0046 - val_loss: 0.8160\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0045 - val_loss: 0.8172\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 226us/step - loss: 0.0044 - val_loss: 0.8190\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0043 - val_loss: 0.8209\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 210us/step - loss: 0.0043 - val_loss: 0.8232\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0042 - val_loss: 0.8241\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 234us/step - loss: 0.0041 - val_loss: 0.8253\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 0.0040 - val_loss: 0.8264\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0039 - val_loss: 0.8279\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 168us/step - loss: 0.0038 - val_loss: 0.8294\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 0.0038 - val_loss: 0.8317\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.0037 - val_loss: 0.8322\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 171us/step - loss: 0.0036 - val_loss: 0.8339\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 168us/step - loss: 0.0035 - val_loss: 0.8351\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 171us/step - loss: 0.0035 - val_loss: 0.8363\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 168us/step - loss: 0.0034 - val_loss: 0.8380\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 178us/step - loss: 0.0033 - val_loss: 0.8395\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 179us/step - loss: 0.0033 - val_loss: 0.8414\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 0.0032 - val_loss: 0.8431\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 169us/step - loss: 0.0032 - val_loss: 0.8441\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 186us/step - loss: 0.0031 - val_loss: 0.8453\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 177us/step - loss: 0.0030 - val_loss: 0.8457\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 168us/step - loss: 0.0030 - val_loss: 0.8475\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 166us/step - loss: 0.0029 - val_loss: 0.8485\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 179us/step - loss: 0.0029 - val_loss: 0.8502\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 189us/step - loss: 0.0028 - val_loss: 0.8523\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 172us/step - loss: 0.0028 - val_loss: 0.8533\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 181us/step - loss: 0.0027 - val_loss: 0.8539\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0027 - val_loss: 0.8551\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 177us/step - loss: 0.0026 - val_loss: 0.8561\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 170us/step - loss: 0.0026 - val_loss: 0.8578\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0026 - val_loss: 0.8583\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.0025 - val_loss: 0.8603\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0025 - val_loss: 0.8617\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.0024 - val_loss: 0.8624\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0024 - val_loss: 0.8631\n",
      "Epoch 134/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 146us/step - loss: 0.0024 - val_loss: 0.8644\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0023 - val_loss: 0.8658\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0023 - val_loss: 0.8673\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.8691\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 0.0022 - val_loss: 0.8698\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.0022 - val_loss: 0.8710\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.0022 - val_loss: 0.8714\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.0021 - val_loss: 0.8727\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0021 - val_loss: 0.8736\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0021 - val_loss: 0.8746\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.0020 - val_loss: 0.8754\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 139us/step - loss: 0.0020 - val_loss: 0.8773\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.0020 - val_loss: 0.8782\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0019 - val_loss: 0.8793\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.8804\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0019 - val_loss: 0.8817\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.0019 - val_loss: 0.8825\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.8833\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 0.0018 - val_loss: 0.8847\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 138us/step - loss: 0.0018 - val_loss: 0.8856\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0018 - val_loss: 0.8868\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0017 - val_loss: 0.8871\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 141us/step - loss: 0.0017 - val_loss: 0.8884\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 166us/step - loss: 0.0017 - val_loss: 0.8899\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0017 - val_loss: 0.8914\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 0.0016 - val_loss: 0.8918\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.0016 - val_loss: 0.8931\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0016 - val_loss: 0.8938\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 0.0016 - val_loss: 0.8947\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.0016 - val_loss: 0.8953\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.8966\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 143us/step - loss: 0.0015 - val_loss: 0.8978\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0015 - val_loss: 0.8989\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0015 - val_loss: 0.8994\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 143us/step - loss: 0.0015 - val_loss: 0.9000\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0014 - val_loss: 0.9016\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.0014 - val_loss: 0.9031\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.0014 - val_loss: 0.9037\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0014 - val_loss: 0.9044\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.0014 - val_loss: 0.9053\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.9064\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.0013 - val_loss: 0.9075\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 143us/step - loss: 0.0013 - val_loss: 0.9088\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 0.0013 - val_loss: 0.9094\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 138us/step - loss: 0.0013 - val_loss: 0.9103\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0013 - val_loss: 0.9111\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.9123\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0013 - val_loss: 0.9132\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 0.0012 - val_loss: 0.9137\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 140us/step - loss: 0.0012 - val_loss: 0.9145\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.9155\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 143us/step - loss: 0.0012 - val_loss: 0.9167\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.0012 - val_loss: 0.9175\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 0.0012 - val_loss: 0.9182\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.9190\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.0011 - val_loss: 0.9200\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.0011 - val_loss: 0.9209\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.0011 - val_loss: 0.9221\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0011 - val_loss: 0.9230\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 140us/step - loss: 0.0011 - val_loss: 0.9240\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0011 - val_loss: 0.9249\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 0.0011 - val_loss: 0.9256\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0011 - val_loss: 0.9260\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 141us/step - loss: 0.0011 - val_loss: 0.9269\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0010 - val_loss: 0.9279\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 173us/step - loss: 0.0010 - val_loss: 0.9289\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0010 - val_loss: 0.9296\n",
      " (-0.5, 2)   linear C\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 2.2281 - val_loss: 2.1428\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 474us/step - loss: 1.9514 - val_loss: 1.9270\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 371us/step - loss: 1.6676 - val_loss: 1.6939\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 1.3780 - val_loss: 1.4462\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 1.1000 - val_loss: 1.2306\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 0.8628 - val_loss: 1.0701\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.6919 - val_loss: 0.9555\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.5678 - val_loss: 0.8791\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.4680 - val_loss: 0.8316\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.3878 - val_loss: 0.7815\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 316us/step - loss: 0.3228 - val_loss: 0.7400\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 597us/step - loss: 0.2725 - val_loss: 0.7168\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 689us/step - loss: 0.2326 - val_loss: 0.7089\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 617us/step - loss: 0.2071 - val_loss: 0.7022\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 858us/step - loss: 0.1691 - val_loss: 0.6611\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 473us/step - loss: 0.1448 - val_loss: 0.6885\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 442us/step - loss: 0.1224 - val_loss: 0.6610\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.1053 - val_loss: 0.6692\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.0931 - val_loss: 0.6788\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 566us/step - loss: 0.0785 - val_loss: 0.6674\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 575us/step - loss: 0.0688 - val_loss: 0.6751\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 478us/step - loss: 0.0598 - val_loss: 0.6749\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 522us/step - loss: 0.0527 - val_loss: 0.6735\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.0467 - val_loss: 0.6752\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 384us/step - loss: 0.0418 - val_loss: 0.6792\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 562us/step - loss: 0.0377 - val_loss: 0.6815\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 388us/step - loss: 0.0342 - val_loss: 0.6881\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 349us/step - loss: 0.0308 - val_loss: 0.6952\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0281 - val_loss: 0.6887\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 370us/step - loss: 0.0257 - val_loss: 0.6936\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 503us/step - loss: 0.0237 - val_loss: 0.6942\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.0217 - val_loss: 0.6964\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0201 - val_loss: 0.7078\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0184 - val_loss: 0.7092\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0171 - val_loss: 0.7126\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0159 - val_loss: 0.7060\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0150 - val_loss: 0.7118\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0140 - val_loss: 0.7168\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 0.0131 - val_loss: 0.7281\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 0.0122 - val_loss: 0.7253\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.0115 - val_loss: 0.7256\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 343us/step - loss: 0.0108 - val_loss: 0.7311\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 0.0103 - val_loss: 0.7410\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0097 - val_loss: 0.7382\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 369us/step - loss: 0.0092 - val_loss: 0.7461\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 357us/step - loss: 0.0087 - val_loss: 0.7434\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.0083 - val_loss: 0.7459\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.0079 - val_loss: 0.7500\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 0.0075 - val_loss: 0.7588\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 0.0071 - val_loss: 0.7608\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 0.0068 - val_loss: 0.7649\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0065 - val_loss: 0.7654\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.0062 - val_loss: 0.7649\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 366us/step - loss: 0.0059 - val_loss: 0.7736\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.0057 - val_loss: 0.7818\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 358us/step - loss: 0.0054 - val_loss: 0.7790\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 0.0052 - val_loss: 0.7759\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 0.0050 - val_loss: 0.7842\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 0.0048 - val_loss: 0.7899\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0046 - val_loss: 0.7889\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 373us/step - loss: 0.0044 - val_loss: 0.7880\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 557us/step - loss: 0.0043 - val_loss: 0.7972\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 382us/step - loss: 0.0041 - val_loss: 0.7955\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0039 - val_loss: 0.7990\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0038 - val_loss: 0.8009\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.0037 - val_loss: 0.8013\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.0035 - val_loss: 0.8039\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0034 - val_loss: 0.8110\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.0033 - val_loss: 0.8109\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 475us/step - loss: 0.0032 - val_loss: 0.8086\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 451us/step - loss: 0.0031 - val_loss: 0.8125\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 0.0030 - val_loss: 0.8162\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0029 - val_loss: 0.8174\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0028 - val_loss: 0.8187\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 354us/step - loss: 0.0027 - val_loss: 0.8218\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.0026 - val_loss: 0.8253\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 358us/step - loss: 0.0026 - val_loss: 0.8245\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 353us/step - loss: 0.0025 - val_loss: 0.8256\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.0024 - val_loss: 0.8290\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 0.0024 - val_loss: 0.8315\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 0.0023 - val_loss: 0.8327\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.0022 - val_loss: 0.8355\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0022 - val_loss: 0.8355\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0021 - val_loss: 0.8373\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 0.0021 - val_loss: 0.8405\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 361us/step - loss: 0.0020 - val_loss: 0.8434\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 385us/step - loss: 0.0019 - val_loss: 0.8433\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0019 - val_loss: 0.8462\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0019 - val_loss: 0.8507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0018 - val_loss: 0.8522\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0018 - val_loss: 0.8523\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0017 - val_loss: 0.8540\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0017 - val_loss: 0.8588\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0016 - val_loss: 0.8600\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0016 - val_loss: 0.8602\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0016 - val_loss: 0.8605\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0015 - val_loss: 0.8648\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0015 - val_loss: 0.8660\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0015 - val_loss: 0.8646\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0014 - val_loss: 0.8672\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 499us/step - loss: 0.0014 - val_loss: 0.8711\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 376us/step - loss: 0.0014 - val_loss: 0.8716\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0013 - val_loss: 0.8702\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0013 - val_loss: 0.8740\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0013 - val_loss: 0.8733\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0012 - val_loss: 0.8748\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0012 - val_loss: 0.8787\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0012 - val_loss: 0.8809\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0012 - val_loss: 0.8819\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0011 - val_loss: 0.8833\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.0011 - val_loss: 0.8848\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0011 - val_loss: 0.8869\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 0.0011 - val_loss: 0.8881\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 544us/step - loss: 0.0011 - val_loss: 0.8901\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 509us/step - loss: 0.0010 - val_loss: 0.8920\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 563us/step - loss: 0.0010 - val_loss: 0.8914\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 447us/step - loss: 9.9555e-04 - val_loss: 0.8926\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 9.7744e-04 - val_loss: 0.8952\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 9.5753e-04 - val_loss: 0.8954\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 9.4029e-04 - val_loss: 0.8968\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 9.2318e-04 - val_loss: 0.8989\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 9.0411e-04 - val_loss: 0.9008\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 8.8982e-04 - val_loss: 0.8999\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 8.7150e-04 - val_loss: 0.9012\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 8.5811e-04 - val_loss: 0.9048\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 8.4143e-04 - val_loss: 0.9055\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 369us/step - loss: 8.2589e-04 - val_loss: 0.9067\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 601us/step - loss: 8.1217e-04 - val_loss: 0.9079\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 527us/step - loss: 7.9767e-04 - val_loss: 0.9092\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 7.8215e-04 - val_loss: 0.9108\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 515us/step - loss: 7.7122e-04 - val_loss: 0.9126\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 484us/step - loss: 7.5720e-04 - val_loss: 0.9132\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 7.4413e-04 - val_loss: 0.9131\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 7.3050e-04 - val_loss: 0.9142\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 358us/step - loss: 7.1830e-04 - val_loss: 0.9160\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 352us/step - loss: 7.0636e-04 - val_loss: 0.9159\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 343us/step - loss: 6.9515e-04 - val_loss: 0.9168\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 6.8242e-04 - val_loss: 0.9187\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 6.7170e-04 - val_loss: 0.9190\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 6.6093e-04 - val_loss: 0.9223\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 6.4965e-04 - val_loss: 0.9241\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 6.3980e-04 - val_loss: 0.9233\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 6.2790e-04 - val_loss: 0.9271\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 6.1822e-04 - val_loss: 0.9284\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 6.0845e-04 - val_loss: 0.9286\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 492us/step - loss: 5.9897e-04 - val_loss: 0.9270\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 439us/step - loss: 5.8998e-04 - val_loss: 0.9286\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 600us/step - loss: 5.7998e-04 - val_loss: 0.9299\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 564us/step - loss: 5.7128e-04 - val_loss: 0.9305\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 5.6535e-04 - val_loss: 0.9341\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 5.5348e-04 - val_loss: 0.9330\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 5.4588e-04 - val_loss: 0.9336\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 5.3764e-04 - val_loss: 0.9355\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 5.2896e-04 - val_loss: 0.9379\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 5.2169e-04 - val_loss: 0.9397\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 5.1451e-04 - val_loss: 0.9403\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 5.0643e-04 - val_loss: 0.9409\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 4.9845e-04 - val_loss: 0.9421\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 4.9197e-04 - val_loss: 0.9426\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 4.8626e-04 - val_loss: 0.9429\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 4.7813e-04 - val_loss: 0.9448\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 4.7119e-04 - val_loss: 0.9472\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 4.6525e-04 - val_loss: 0.9478\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 4.6020e-04 - val_loss: 0.9467\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 4.5207e-04 - val_loss: 0.9488\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 274us/step - loss: 4.4585e-04 - val_loss: 0.9498\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 4.4012e-04 - val_loss: 0.9509\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 4.3385e-04 - val_loss: 0.9521\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 4.2737e-04 - val_loss: 0.9527\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 4.2119e-04 - val_loss: 0.9550\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 4.1594e-04 - val_loss: 0.9568\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 4.1047e-04 - val_loss: 0.9582\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 4.0595e-04 - val_loss: 0.9590\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 4.0021e-04 - val_loss: 0.9589\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 3.9373e-04 - val_loss: 0.9604\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 3.8865e-04 - val_loss: 0.9627\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 3.8359e-04 - val_loss: 0.9620\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 3.7828e-04 - val_loss: 0.9626\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 3.7387e-04 - val_loss: 0.9649\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 3.6865e-04 - val_loss: 0.9658\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 3.6362e-04 - val_loss: 0.9660\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 3.5887e-04 - val_loss: 0.9664\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 3.5434e-04 - val_loss: 0.9667\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 3.5102e-04 - val_loss: 0.9689\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 3.4581e-04 - val_loss: 0.9678\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 3.4094e-04 - val_loss: 0.9704\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 3.3727e-04 - val_loss: 0.9722\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 3.3229e-04 - val_loss: 0.9718\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 3.2856e-04 - val_loss: 0.9720\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 3.2383e-04 - val_loss: 0.9744\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 3.1992e-04 - val_loss: 0.9760\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 3.1640e-04 - val_loss: 0.9766\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 3.1230e-04 - val_loss: 0.9767\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 3.0829e-04 - val_loss: 0.9785\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 3.0453e-04 - val_loss: 0.9790\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 3.0092e-04 - val_loss: 0.9803\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 2.9692e-04 - val_loss: 0.9800\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 2.9303e-04 - val_loss: 0.9801\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 2.8966e-04 - val_loss: 0.9807\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 2.8618e-04 - val_loss: 0.9803\n",
      " (-0.5, 2)     relu A\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 2.2484 - val_loss: 2.1998\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 376us/step - loss: 2.0500 - val_loss: 2.0598\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 1.8511 - val_loss: 1.9132\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 1.6417 - val_loss: 1.7479\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 1.4212 - val_loss: 1.5396\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 1.1985 - val_loss: 1.3600\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 0.9947 - val_loss: 1.2124\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.7979 - val_loss: 1.0299\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 0.6246 - val_loss: 0.9439\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.5065 - val_loss: 0.8455\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 0.4114 - val_loss: 0.8150\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.3273 - val_loss: 0.7867\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 0.2870 - val_loss: 0.7577\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.2203 - val_loss: 0.7686\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.1861 - val_loss: 0.7259\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.1505 - val_loss: 0.7383\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 0.1227 - val_loss: 0.7350\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 0.1037 - val_loss: 0.7197\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.0860 - val_loss: 0.7180\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 380us/step - loss: 0.0733 - val_loss: 0.7156\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 0.0621 - val_loss: 0.7343\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 0.0532 - val_loss: 0.7144\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 0.0459 - val_loss: 0.7250\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0405 - val_loss: 0.7309\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0352 - val_loss: 0.7297\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 0.0317 - val_loss: 0.7375\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 363us/step - loss: 0.0281 - val_loss: 0.7406\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 362us/step - loss: 0.0261 - val_loss: 0.7431\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0235 - val_loss: 0.7508\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 370us/step - loss: 0.0215 - val_loss: 0.7499\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 0.0198 - val_loss: 0.7644\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 384us/step - loss: 0.0179 - val_loss: 0.7591\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 0.0163 - val_loss: 0.7646\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 0.0152 - val_loss: 0.7663\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 368us/step - loss: 0.0140 - val_loss: 0.7731\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.0129 - val_loss: 0.7720\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.0121 - val_loss: 0.7748\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 369us/step - loss: 0.0113 - val_loss: 0.7814\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 356us/step - loss: 0.0105 - val_loss: 0.7924\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.0099 - val_loss: 0.7952\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 370us/step - loss: 0.0093 - val_loss: 0.7873\n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 338us/step - loss: 0.0087 - val_loss: 0.7946\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 357us/step - loss: 0.0082 - val_loss: 0.8028\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 0.0078 - val_loss: 0.8016\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.0074 - val_loss: 0.8059\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.0070 - val_loss: 0.8071\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.0066 - val_loss: 0.8115\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.0064 - val_loss: 0.8193\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.0060 - val_loss: 0.8175\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 363us/step - loss: 0.0057 - val_loss: 0.8225\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.0055 - val_loss: 0.8264\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 0.0052 - val_loss: 0.8264\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 368us/step - loss: 0.0050 - val_loss: 0.8281\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.0048 - val_loss: 0.8299\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 366us/step - loss: 0.0046 - val_loss: 0.8347\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 0.0044 - val_loss: 0.8318\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 365us/step - loss: 0.0042 - val_loss: 0.8377\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 365us/step - loss: 0.0041 - val_loss: 0.8382\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 0.0039 - val_loss: 0.8399\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 0.0038 - val_loss: 0.8457\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 352us/step - loss: 0.0036 - val_loss: 0.8468\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.0035 - val_loss: 0.8500\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.0034 - val_loss: 0.8508\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.0032 - val_loss: 0.8556\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 356us/step - loss: 0.0032 - val_loss: 0.8590\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 0.0031 - val_loss: 0.8573\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.0029 - val_loss: 0.8593\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 358us/step - loss: 0.0028 - val_loss: 0.8623\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.0028 - val_loss: 0.8657\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0027 - val_loss: 0.8673\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 0.0026 - val_loss: 0.8715\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 354us/step - loss: 0.0025 - val_loss: 0.8730\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 364us/step - loss: 0.0024 - val_loss: 0.8757\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 0.0023 - val_loss: 0.8790\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 355us/step - loss: 0.0023 - val_loss: 0.8783\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 363us/step - loss: 0.0022 - val_loss: 0.8779\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.0022 - val_loss: 0.8836\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0021 - val_loss: 0.8860\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0020 - val_loss: 0.8864\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.0020 - val_loss: 0.8888\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.0019 - val_loss: 0.8905\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0019 - val_loss: 0.8925\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.0018 - val_loss: 0.8932\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 0.0018 - val_loss: 0.8968\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.002 - 0s 306us/step - loss: 0.0017 - val_loss: 0.8968\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 388us/step - loss: 0.0017 - val_loss: 0.8976\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 379us/step - loss: 0.0016 - val_loss: 0.8993\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 372us/step - loss: 0.0016 - val_loss: 0.9034\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 0.0016 - val_loss: 0.9046\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 358us/step - loss: 0.0015 - val_loss: 0.9045\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 375us/step - loss: 0.0015 - val_loss: 0.9064\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 360us/step - loss: 0.0015 - val_loss: 0.9084\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 357us/step - loss: 0.0014 - val_loss: 0.9108\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 358us/step - loss: 0.0014 - val_loss: 0.9122\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.0014 - val_loss: 0.9131\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 0.0013 - val_loss: 0.9141\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 0.0013 - val_loss: 0.9146\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 0.0013 - val_loss: 0.9174\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 377us/step - loss: 0.0012 - val_loss: 0.9197\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 486us/step - loss: 0.0012 - val_loss: 0.9211\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 482us/step - loss: 0.0012 - val_loss: 0.9229\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 436us/step - loss: 0.0012 - val_loss: 0.9241\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 395us/step - loss: 0.0011 - val_loss: 0.9250\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 430us/step - loss: 0.0011 - val_loss: 0.9286\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 450us/step - loss: 0.0011 - val_loss: 0.9298\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 492us/step - loss: 0.0011 - val_loss: 0.9281\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 457us/step - loss: 0.0010 - val_loss: 0.9305\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 371us/step - loss: 0.0010 - val_loss: 0.9326\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 9.9538e-04 - val_loss: 0.9339\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 9.7634e-04 - val_loss: 0.9358\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.001 - 0s 314us/step - loss: 9.5941e-04 - val_loss: 0.9371\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 352us/step - loss: 9.4033e-04 - val_loss: 0.9372\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 9.1973e-04 - val_loss: 0.9395\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 9.0336e-04 - val_loss: 0.9405\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 8.8652e-04 - val_loss: 0.9435\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 8.7067e-04 - val_loss: 0.9429\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 8.5373e-04 - val_loss: 0.9467\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 8.3826e-04 - val_loss: 0.9479\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 8.2358e-04 - val_loss: 0.9501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 8.0576e-04 - val_loss: 0.9506\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 7.9098e-04 - val_loss: 0.9516\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 7.7650e-04 - val_loss: 0.9513\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 7.6374e-04 - val_loss: 0.9528\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 7.5109e-04 - val_loss: 0.9560\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 7.3489e-04 - val_loss: 0.9563\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 7.2337e-04 - val_loss: 0.9583\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 7.1029e-04 - val_loss: 0.9598\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 6.9850e-04 - val_loss: 0.9616\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 6.8698e-04 - val_loss: 0.9617\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 6.7530e-04 - val_loss: 0.9618\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 6.6447e-04 - val_loss: 0.9636\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 6.5260e-04 - val_loss: 0.9651\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 6.4161e-04 - val_loss: 0.9667\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 6.3087e-04 - val_loss: 0.9675\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 6.2007e-04 - val_loss: 0.9688\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 6.1028e-04 - val_loss: 0.9707\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 6.0029e-04 - val_loss: 0.9710\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 5.9070e-04 - val_loss: 0.9732\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 5.8079e-04 - val_loss: 0.9747\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 343us/step - loss: 5.7159e-04 - val_loss: 0.9759\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 368us/step - loss: 5.6301e-04 - val_loss: 0.9763\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 372us/step - loss: 5.5382e-04 - val_loss: 0.9780\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 5.4569e-04 - val_loss: 0.9784\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 354us/step - loss: 5.3712e-04 - val_loss: 0.9800\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 5.2867e-04 - val_loss: 0.9811\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 5.2054e-04 - val_loss: 0.9824\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 5.1270e-04 - val_loss: 0.9843\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 5.0550e-04 - val_loss: 0.9846\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 4.9842e-04 - val_loss: 0.9868\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 4.9047e-04 - val_loss: 0.9870\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 4.8178e-04 - val_loss: 0.9877\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 4.7435e-04 - val_loss: 0.9891\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 4.6804e-04 - val_loss: 0.9907\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 4.6116e-04 - val_loss: 0.9920\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 4.5368e-04 - val_loss: 0.9923\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 356us/step - loss: 4.4746e-04 - val_loss: 0.9933\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 4.4142e-04 - val_loss: 0.9933\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 4.3430e-04 - val_loss: 0.9956\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 343us/step - loss: 4.2899e-04 - val_loss: 0.9972\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 4.2233e-04 - val_loss: 0.9974\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 368us/step - loss: 4.1676e-04 - val_loss: 0.9979\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 4.1075e-04 - val_loss: 0.9991\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 4.0470e-04 - val_loss: 1.0004\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 3.9946e-04 - val_loss: 1.0021\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 3.9369e-04 - val_loss: 1.0021\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 3.8794e-04 - val_loss: 1.0038\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 3.8242e-04 - val_loss: 1.0043\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 3.7783e-04 - val_loss: 1.0047\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 3.7229e-04 - val_loss: 1.0062\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 375us/step - loss: 3.6692e-04 - val_loss: 1.0078\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 3.6217e-04 - val_loss: 1.0090\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 3.5677e-04 - val_loss: 1.0098\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 3.5256e-04 - val_loss: 1.0110\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 3.4853e-04 - val_loss: 1.0121\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 3.4306e-04 - val_loss: 1.0125\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 3.3897e-04 - val_loss: 1.0125\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 3.3454e-04 - val_loss: 1.0140\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 3.2980e-04 - val_loss: 1.0151\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 3.2630e-04 - val_loss: 1.0164\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 3.2148e-04 - val_loss: 1.0177\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 3.1766e-04 - val_loss: 1.0191\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 3.1378e-04 - val_loss: 1.0195\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 3.0999e-04 - val_loss: 1.0206\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 3.0587e-04 - val_loss: 1.0202\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 3.0194e-04 - val_loss: 1.0215\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 2.9802e-04 - val_loss: 1.0229\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 2.9430e-04 - val_loss: 1.0239\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 2.9086e-04 - val_loss: 1.0254\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 2.8710e-04 - val_loss: 1.0262\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 2.8363e-04 - val_loss: 1.0272\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 2.8029e-04 - val_loss: 1.0285\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 2.7684e-04 - val_loss: 1.0282\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 2.6635e-0 - 0s 313us/step - loss: 2.7317e-04 - val_loss: 1.0297\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 2.6991e-04 - val_loss: 1.0305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 2.6662e-04 - val_loss: 1.0317\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 2.6341e-04 - val_loss: 1.0326\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 2.6039e-04 - val_loss: 1.0321\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 2.5737e-04 - val_loss: 1.0324\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 2.5398e-04 - val_loss: 1.0337\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 343us/step - loss: 2.5103e-04 - val_loss: 1.0347\n",
      " (-0.5, 2)     relu B\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 2.4019 - val_loss: 2.3456\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 2.2769 - val_loss: 2.2738\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 2.1690 - val_loss: 2.1868\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 2.0582 - val_loss: 2.0981\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 1.9472 - val_loss: 2.0125\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 1.8434 - val_loss: 1.9346\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 1.7456 - val_loss: 1.8550\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 1.6531 - val_loss: 1.7786\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 1.5655 - val_loss: 1.7066\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 143us/step - loss: 1.4790 - val_loss: 1.6345\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 172us/step - loss: 1.3903 - val_loss: 1.5610\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 1.3044 - val_loss: 1.4864\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 1.2189 - val_loss: 1.4112\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 1.1343 - val_loss: 1.3348\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 1.0495 - val_loss: 1.2641\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.9678 - val_loss: 1.1971\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 139us/step - loss: 0.8872 - val_loss: 1.1339\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.8078 - val_loss: 1.0718\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.7321 - val_loss: 1.0133\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 141us/step - loss: 0.6592 - val_loss: 0.9576\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 140us/step - loss: 0.5906 - val_loss: 0.9090\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 0.5300 - val_loss: 0.8621\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 166us/step - loss: 0.4706 - val_loss: 0.8211\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 185us/step - loss: 0.4218 - val_loss: 0.7853\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 175us/step - loss: 0.3770 - val_loss: 0.7612\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 173us/step - loss: 0.3392 - val_loss: 0.7417\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 174us/step - loss: 0.3014 - val_loss: 0.7236\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.2687 - val_loss: 0.7106\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.2408 - val_loss: 0.7010\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.2172 - val_loss: 0.6876\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 181us/step - loss: 0.1948 - val_loss: 0.6762\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 186us/step - loss: 0.1756 - val_loss: 0.6699\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 171us/step - loss: 0.1589 - val_loss: 0.6652\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 176us/step - loss: 0.1436 - val_loss: 0.6663\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 178us/step - loss: 0.1302 - val_loss: 0.6636\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 173us/step - loss: 0.1179 - val_loss: 0.6648\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 177us/step - loss: 0.1067 - val_loss: 0.6614\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.0980 - val_loss: 0.6615\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0894 - val_loss: 0.6616\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.0820 - val_loss: 0.6660\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0750 - val_loss: 0.6672\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 0.0691 - val_loss: 0.6679\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 0.0631 - val_loss: 0.6673\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.0582 - val_loss: 0.6682\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 177us/step - loss: 0.0541 - val_loss: 0.6681\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 166us/step - loss: 0.0501 - val_loss: 0.6689\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 175us/step - loss: 0.0465 - val_loss: 0.6703\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 171us/step - loss: 0.0434 - val_loss: 0.6762\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 0.0406 - val_loss: 0.6812\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0378 - val_loss: 0.6812\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0353 - val_loss: 0.6798\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 171us/step - loss: 0.0333 - val_loss: 0.6798\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 173us/step - loss: 0.0312 - val_loss: 0.6823\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 174us/step - loss: 0.0292 - val_loss: 0.6832\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 189us/step - loss: 0.0276 - val_loss: 0.6868\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 184us/step - loss: 0.0261 - val_loss: 0.6890\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 177us/step - loss: 0.0247 - val_loss: 0.6917\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 194us/step - loss: 0.0234 - val_loss: 0.6929\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 0.0222 - val_loss: 0.6945\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 0.0210 - val_loss: 0.6950\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0201 - val_loss: 0.6985\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 0.0192 - val_loss: 0.7022\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 0.0182 - val_loss: 0.7040\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 179us/step - loss: 0.0174 - val_loss: 0.7030\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 173us/step - loss: 0.0166 - val_loss: 0.7026\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 179us/step - loss: 0.0159 - val_loss: 0.7065\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 176us/step - loss: 0.0152 - val_loss: 0.7089\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.0146 - val_loss: 0.7108\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 172us/step - loss: 0.0140 - val_loss: 0.7122\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 169us/step - loss: 0.0134 - val_loss: 0.7137\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0129 - val_loss: 0.7155\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0124 - val_loss: 0.7179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 0.0119 - val_loss: 0.7202\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 182us/step - loss: 0.0115 - val_loss: 0.7201\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 166us/step - loss: 0.0111 - val_loss: 0.7218\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 172us/step - loss: 0.0107 - val_loss: 0.7230\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 171us/step - loss: 0.0103 - val_loss: 0.7243\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 0.0100 - val_loss: 0.7261\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 172us/step - loss: 0.0096 - val_loss: 0.7279\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 182us/step - loss: 0.0093 - val_loss: 0.7294\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 178us/step - loss: 0.0090 - val_loss: 0.7314\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 176us/step - loss: 0.0087 - val_loss: 0.7323\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 185us/step - loss: 0.0084 - val_loss: 0.7339\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 187us/step - loss: 0.0082 - val_loss: 0.7354\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 176us/step - loss: 0.0080 - val_loss: 0.7366\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.0077 - val_loss: 0.7391\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 175us/step - loss: 0.0075 - val_loss: 0.7397\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0073 - val_loss: 0.7413\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 0.0071 - val_loss: 0.7426\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 138us/step - loss: 0.0069 - val_loss: 0.7447\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 0.0067 - val_loss: 0.7466\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0065 - val_loss: 0.7477\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0063 - val_loss: 0.7482\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 171us/step - loss: 0.0062 - val_loss: 0.7498\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0060 - val_loss: 0.7516\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 139us/step - loss: 0.0058 - val_loss: 0.7531\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 177us/step - loss: 0.0057 - val_loss: 0.7550\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 139us/step - loss: 0.0056 - val_loss: 0.7559\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.0054 - val_loss: 0.7554\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0053 - val_loss: 0.7563\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.0052 - val_loss: 0.7585\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0050 - val_loss: 0.7602\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.0049 - val_loss: 0.7614\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0048 - val_loss: 0.7634\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 140us/step - loss: 0.0047 - val_loss: 0.7649\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0046 - val_loss: 0.7663\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.0045 - val_loss: 0.7665\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.0044 - val_loss: 0.7677\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0043 - val_loss: 0.7684\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0042 - val_loss: 0.7701\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 143us/step - loss: 0.0041 - val_loss: 0.7714\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0040 - val_loss: 0.7730\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 172us/step - loss: 0.0039 - val_loss: 0.7739\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.0038 - val_loss: 0.7748\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0038 - val_loss: 0.7757\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.7769\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0036 - val_loss: 0.7779\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.0035 - val_loss: 0.7794\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.0035 - val_loss: 0.7809\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0034 - val_loss: 0.7817\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.0033 - val_loss: 0.7830\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0033 - val_loss: 0.7839\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0032 - val_loss: 0.7849\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0031 - val_loss: 0.7860\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0031 - val_loss: 0.7869\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0030 - val_loss: 0.7880\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.0030 - val_loss: 0.7892\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 140us/step - loss: 0.0029 - val_loss: 0.7905\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.0029 - val_loss: 0.7915\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.0028 - val_loss: 0.7922\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0028 - val_loss: 0.7935\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0027 - val_loss: 0.7943\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0027 - val_loss: 0.7951\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0026 - val_loss: 0.7956\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.0026 - val_loss: 0.7964\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0025 - val_loss: 0.7974\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 140us/step - loss: 0.0025 - val_loss: 0.7985\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.7993\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.8005\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.002 - 0s 154us/step - loss: 0.0024 - val_loss: 0.8016\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.0023 - val_loss: 0.8030\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0023 - val_loss: 0.8036\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 173us/step - loss: 0.0023 - val_loss: 0.8046\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0022 - val_loss: 0.8053\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0022 - val_loss: 0.8054\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0022 - val_loss: 0.8061\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0021 - val_loss: 0.8070\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0021 - val_loss: 0.8080\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0021 - val_loss: 0.8090\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 141us/step - loss: 0.0020 - val_loss: 0.8106\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 151us/step - loss: 0.0020 - val_loss: 0.8117\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0020 - val_loss: 0.8125\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0019 - val_loss: 0.8133\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.8138\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.0019 - val_loss: 0.8149\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0019 - val_loss: 0.8154\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 0.0018 - val_loss: 0.8160\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 0.0018 - val_loss: 0.8174\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0018 - val_loss: 0.8180\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.0017 - val_loss: 0.8189\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0017 - val_loss: 0.8199\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 169us/step - loss: 0.0017 - val_loss: 0.8211\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.0017 - val_loss: 0.8216\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.001 - 0s 140us/step - loss: 0.0017 - val_loss: 0.8222\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 141us/step - loss: 0.0016 - val_loss: 0.8229\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 0.0016 - val_loss: 0.8235\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.0016 - val_loss: 0.8246\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0016 - val_loss: 0.8256\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 0.0015 - val_loss: 0.8266\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 0.0015 - val_loss: 0.8277\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 143us/step - loss: 0.0015 - val_loss: 0.8283\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0015 - val_loss: 0.8291\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.0015 - val_loss: 0.8298\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0014 - val_loss: 0.8307\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 191us/step - loss: 0.0014 - val_loss: 0.8317\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0014 - val_loss: 0.8326\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.0014 - val_loss: 0.8334\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0014 - val_loss: 0.8340\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 138us/step - loss: 0.0014 - val_loss: 0.8345\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.0013 - val_loss: 0.8354\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 175us/step - loss: 0.0013 - val_loss: 0.8361\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0013 - val_loss: 0.8372\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.8380\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0013 - val_loss: 0.8385\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.0013 - val_loss: 0.8393\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.0013 - val_loss: 0.8397\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0012 - val_loss: 0.8404\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.0012 - val_loss: 0.8412\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0012 - val_loss: 0.8422\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 0.0012 - val_loss: 0.8431\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 169us/step - loss: 0.0012 - val_loss: 0.8437\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0012 - val_loss: 0.8445\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0012 - val_loss: 0.8450\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0011 - val_loss: 0.8459\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0011 - val_loss: 0.8465\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0011 - val_loss: 0.8468\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 175us/step - loss: 0.0011 - val_loss: 0.8474\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0011 - val_loss: 0.8484\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 0.8495\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 173us/step - loss: 0.0011 - val_loss: 0.8503\n",
      " (-0.5, 2)     relu C\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.4533 - val_loss: 2.3075\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 2.1317 - val_loss: 2.0233\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 1.7700 - val_loss: 1.7357\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 1.4176 - val_loss: 1.4546\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 1.1029 - val_loss: 1.2401\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 385us/step - loss: 0.8508 - val_loss: 1.0447\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 370us/step - loss: 0.6689 - val_loss: 0.9266\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 381us/step - loss: 0.5267 - val_loss: 0.8620\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 343us/step - loss: 0.4240 - val_loss: 0.7951\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 357us/step - loss: 0.3490 - val_loss: 0.7664\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 0.2964 - val_loss: 0.7389\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 364us/step - loss: 0.2591 - val_loss: 0.7130\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 0.2048 - val_loss: 0.7017\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 370us/step - loss: 0.1695 - val_loss: 0.7062\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.1454 - val_loss: 0.6752\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 353us/step - loss: 0.1264 - val_loss: 0.6813\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.1093 - val_loss: 0.6885\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0934 - val_loss: 0.6708\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0819 - val_loss: 0.6757\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0726 - val_loss: 0.7027\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0653 - val_loss: 0.6724\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.0562 - val_loss: 0.6961\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0502 - val_loss: 0.6920\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 0.0450 - val_loss: 0.6911\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.0406 - val_loss: 0.7026\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0374 - val_loss: 0.7003\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0348 - val_loss: 0.7043\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 278us/step - loss: 0.0314 - val_loss: 0.7220\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 0.0285 - val_loss: 0.7112\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0264 - val_loss: 0.7163\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0245 - val_loss: 0.7216\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0229 - val_loss: 0.7300\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0212 - val_loss: 0.7255\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0196 - val_loss: 0.7362\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0183 - val_loss: 0.7417\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0171 - val_loss: 0.7365\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0160 - val_loss: 0.7419\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.0151 - val_loss: 0.7417\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0142 - val_loss: 0.7439\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0134 - val_loss: 0.7531\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0127 - val_loss: 0.7555\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0121 - val_loss: 0.7600\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0116 - val_loss: 0.7557\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0108 - val_loss: 0.7713\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0104 - val_loss: 0.7620\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 0.0098 - val_loss: 0.7732\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0093 - val_loss: 0.7718\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0088 - val_loss: 0.7741\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0084 - val_loss: 0.7789\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.0082 - val_loss: 0.7879\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0077 - val_loss: 0.7884\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0074 - val_loss: 0.7876\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0072 - val_loss: 0.7939\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0068 - val_loss: 0.7880\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0066 - val_loss: 0.7938\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0063 - val_loss: 0.7988\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0061 - val_loss: 0.7989\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0058 - val_loss: 0.8008\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0057 - val_loss: 0.8045\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0054 - val_loss: 0.8048\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0053 - val_loss: 0.8090\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0050 - val_loss: 0.8129\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0049 - val_loss: 0.8144\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0048 - val_loss: 0.8173\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0046 - val_loss: 0.8213\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0044 - val_loss: 0.8212\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0043 - val_loss: 0.8198\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0042 - val_loss: 0.8215\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0040 - val_loss: 0.8237\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0039 - val_loss: 0.8287\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0038 - val_loss: 0.8294\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0037 - val_loss: 0.8319\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 517us/step - loss: 0.0036 - val_loss: 0.8294\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 514us/step - loss: 0.0035 - val_loss: 0.8348\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0034 - val_loss: 0.8357\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0033 - val_loss: 0.8405\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 0.0032 - val_loss: 0.8422\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0031 - val_loss: 0.8484\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0030 - val_loss: 0.8456\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0029 - val_loss: 0.8448\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0029 - val_loss: 0.8493\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0028 - val_loss: 0.8497\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0027 - val_loss: 0.8551\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0026 - val_loss: 0.8582\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.0026 - val_loss: 0.8572\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0025 - val_loss: 0.8580\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0025 - val_loss: 0.8617\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0024 - val_loss: 0.8629\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0023 - val_loss: 0.8635\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.0023 - val_loss: 0.8666\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 0.0022 - val_loss: 0.8690\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0022 - val_loss: 0.8702\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.0021 - val_loss: 0.8717\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0021 - val_loss: 0.8750\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0020 - val_loss: 0.8774\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0020 - val_loss: 0.8787\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0020 - val_loss: 0.8803\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0019 - val_loss: 0.8803\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0019 - val_loss: 0.8817\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0018 - val_loss: 0.8859\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0018 - val_loss: 0.8866\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0018 - val_loss: 0.8875\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0017 - val_loss: 0.8883\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0017 - val_loss: 0.8900\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0017 - val_loss: 0.8913\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.0016 - val_loss: 0.8949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0016 - val_loss: 0.8950\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0016 - val_loss: 0.8951\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 0.0015 - val_loss: 0.8992\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.0015 - val_loss: 0.8988\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0015 - val_loss: 0.8992\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 0.0014 - val_loss: 0.9025\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 370us/step - loss: 0.0014 - val_loss: 0.9013\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.0014 - val_loss: 0.9029\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0014 - val_loss: 0.9052\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 391us/step - loss: 0.0013 - val_loss: 0.9055\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 0.0013 - val_loss: 0.9073\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 357us/step - loss: 0.0013 - val_loss: 0.9090\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 361us/step - loss: 0.0013 - val_loss: 0.9089\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.0012 - val_loss: 0.9110\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 0.0012 - val_loss: 0.9109\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0012 - val_loss: 0.9117\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.0012 - val_loss: 0.9155\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 0.0012 - val_loss: 0.9156\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0011 - val_loss: 0.9183\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0011 - val_loss: 0.9190\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0011 - val_loss: 0.9196\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0011 - val_loss: 0.9200\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0011 - val_loss: 0.9225\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 0.0010 - val_loss: 0.9242\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 366us/step - loss: 0.0010 - val_loss: 0.9206\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.0010 - val_loss: 0.9234\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 9.9720e-04 - val_loss: 0.9267\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 9.8081e-04 - val_loss: 0.9267\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 9.6595e-04 - val_loss: 0.9278\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 9.4949e-04 - val_loss: 0.9301\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 9.3516e-04 - val_loss: 0.9317\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 9.2055e-04 - val_loss: 0.9336\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 9.0509e-04 - val_loss: 0.9345\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 8.9171e-04 - val_loss: 0.9369\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 8.7953e-04 - val_loss: 0.9351\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 8.6544e-04 - val_loss: 0.9372\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 8.5126e-04 - val_loss: 0.9386\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 8.3835e-04 - val_loss: 0.9399\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 8.2831e-04 - val_loss: 0.9423\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 8.1571e-04 - val_loss: 0.9414\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 8.0278e-04 - val_loss: 0.9416\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 7.9097e-04 - val_loss: 0.9425\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 7.7934e-04 - val_loss: 0.9448\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 7.6959e-04 - val_loss: 0.9464\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 7.5698e-04 - val_loss: 0.9462\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 7.4727e-04 - val_loss: 0.9450\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 7.3531e-04 - val_loss: 0.9469\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 7.2476e-04 - val_loss: 0.9478\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 7.1634e-04 - val_loss: 0.9515\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 7.0461e-04 - val_loss: 0.9502\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 6.9668e-04 - val_loss: 0.9496\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 6.8559e-04 - val_loss: 0.9519\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 6.7661e-04 - val_loss: 0.9538\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 6.6700e-04 - val_loss: 0.9544\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 6.5704e-04 - val_loss: 0.9541\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 6.4896e-04 - val_loss: 0.9551\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 6.4005e-04 - val_loss: 0.9578\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 6.3097e-04 - val_loss: 0.9582\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 6.2321e-04 - val_loss: 0.9589\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 6.1474e-04 - val_loss: 0.9598\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 6.0729e-04 - val_loss: 0.9618\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 5.9902e-04 - val_loss: 0.9618\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 5.9067e-04 - val_loss: 0.9634\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 5.8306e-04 - val_loss: 0.9647\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 5.7533e-04 - val_loss: 0.9646\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 5.6770e-04 - val_loss: 0.9654\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 5.6056e-04 - val_loss: 0.9673\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 5.5312e-04 - val_loss: 0.9685\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 5.4613e-04 - val_loss: 0.9688\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 5.3896e-04 - val_loss: 0.9698\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 5.3269e-04 - val_loss: 0.9699\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 5.2598e-04 - val_loss: 0.9712\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 5.1986e-04 - val_loss: 0.9740\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 5.1339e-04 - val_loss: 0.9756\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 5.0669e-04 - val_loss: 0.9754\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 5.0149e-04 - val_loss: 0.9753\n",
      "Epoch 183/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 288us/step - loss: 4.9432e-04 - val_loss: 0.9753\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 4.8836e-04 - val_loss: 0.9769\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 4.8313e-04 - val_loss: 0.9779\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 4.7655e-04 - val_loss: 0.9797\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 4.7090e-04 - val_loss: 0.9809\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 4.6559e-04 - val_loss: 0.9825\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 4.6009e-04 - val_loss: 0.9830\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 4.5531e-04 - val_loss: 0.9827\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 4.4979e-04 - val_loss: 0.9842\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 4.4397e-04 - val_loss: 0.9848\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 4.3843e-04 - val_loss: 0.9863\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 4.3333e-04 - val_loss: 0.9873\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 4.2837e-04 - val_loss: 0.9881\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 4.2379e-04 - val_loss: 0.9890\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 4.4695e-0 - 0s 330us/step - loss: 4.1865e-04 - val_loss: 0.9897\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 4.1374e-04 - val_loss: 0.9900\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 4.0906e-04 - val_loss: 0.9901\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 4.0407e-04 - val_loss: 0.9914\n",
      " (-0.5, 2)     tanh A\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 2.2191 - val_loss: 2.0865\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 392us/step - loss: 1.9068 - val_loss: 1.8534\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 379us/step - loss: 1.6472 - val_loss: 1.6389\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 1.4109 - val_loss: 1.4628\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 360us/step - loss: 1.2182 - val_loss: 1.3164\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 370us/step - loss: 1.0454 - val_loss: 1.1935\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 0.9105 - val_loss: 1.0987\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 356us/step - loss: 0.7969 - val_loss: 1.0231\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 378us/step - loss: 0.6940 - val_loss: 0.9754\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.6095 - val_loss: 0.9183\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.5380 - val_loss: 0.8858\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 361us/step - loss: 0.4717 - val_loss: 0.8596\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.4073 - val_loss: 0.8180\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 0.3700 - val_loss: 0.8102\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.3259 - val_loss: 0.7890\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.2843 - val_loss: 0.7786\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.2534 - val_loss: 0.7528\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.2230 - val_loss: 0.7483\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 0.2026 - val_loss: 0.7408\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.1854 - val_loss: 0.7317\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 0.1664 - val_loss: 0.7312\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 0.1463 - val_loss: 0.7195\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.1323 - val_loss: 0.7302\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.1198 - val_loss: 0.7131\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.1095 - val_loss: 0.7114\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.1000 - val_loss: 0.7163\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.0915 - val_loss: 0.7186\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.0845 - val_loss: 0.7087\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0787 - val_loss: 0.7255\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.0727 - val_loss: 0.7064\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0679 - val_loss: 0.7113\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0636 - val_loss: 0.7082\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.0598 - val_loss: 0.7132\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0564 - val_loss: 0.7136\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0534 - val_loss: 0.7105\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 0.0506 - val_loss: 0.7144\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0480 - val_loss: 0.7224\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.0456 - val_loss: 0.7144\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.0433 - val_loss: 0.7212\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0412 - val_loss: 0.7122\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0393 - val_loss: 0.7225\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 0.0377 - val_loss: 0.7215\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0360 - val_loss: 0.7205\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.0345 - val_loss: 0.7272\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0331 - val_loss: 0.7218\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.0317 - val_loss: 0.7258\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.0306 - val_loss: 0.7259\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0295 - val_loss: 0.7252\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0283 - val_loss: 0.7297\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.0274 - val_loss: 0.7281\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0264 - val_loss: 0.7270\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0254 - val_loss: 0.7299\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.0246 - val_loss: 0.7298\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0237 - val_loss: 0.7323\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0229 - val_loss: 0.7371\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0222 - val_loss: 0.7348\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.0216 - val_loss: 0.7340\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0209 - val_loss: 0.7375\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0203 - val_loss: 0.7397\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 299us/step - loss: 0.0197 - val_loss: 0.7422\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0191 - val_loss: 0.7437\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0186 - val_loss: 0.7408\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0181 - val_loss: 0.7466\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0176 - val_loss: 0.7432\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0171 - val_loss: 0.7441\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0167 - val_loss: 0.7480\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0162 - val_loss: 0.7490\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.0158 - val_loss: 0.7503\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0154 - val_loss: 0.7475\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0150 - val_loss: 0.7496\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.0147 - val_loss: 0.7538\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0143 - val_loss: 0.7508\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.0140 - val_loss: 0.7576\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0136 - val_loss: 0.7547\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0133 - val_loss: 0.7538\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0130 - val_loss: 0.7582\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0127 - val_loss: 0.7593\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.0124 - val_loss: 0.7551\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 0.0121 - val_loss: 0.7645\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0119 - val_loss: 0.7617\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0116 - val_loss: 0.7630\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.0114 - val_loss: 0.7617\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0111 - val_loss: 0.7635\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0109 - val_loss: 0.7676\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0107 - val_loss: 0.7688\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0105 - val_loss: 0.7686\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0102 - val_loss: 0.7700\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 0.0100 - val_loss: 0.7728\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 0.0099 - val_loss: 0.7700\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0097 - val_loss: 0.7719\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0095 - val_loss: 0.7733\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0093 - val_loss: 0.7735\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 0.0091 - val_loss: 0.7746\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0090 - val_loss: 0.7784\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 0.0088 - val_loss: 0.7782\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0086 - val_loss: 0.7771\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0085 - val_loss: 0.7774\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0083 - val_loss: 0.7779\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0082 - val_loss: 0.7795\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.0080 - val_loss: 0.7808\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0079 - val_loss: 0.7836\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.0078 - val_loss: 0.7824\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0076 - val_loss: 0.7845\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0075 - val_loss: 0.7887\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0074 - val_loss: 0.7889\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0072 - val_loss: 0.7871\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0071 - val_loss: 0.7884\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.0070 - val_loss: 0.7907\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0069 - val_loss: 0.7919\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0068 - val_loss: 0.7935\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0067 - val_loss: 0.7944\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0066 - val_loss: 0.7930\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0065 - val_loss: 0.7944\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0064 - val_loss: 0.7970\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0063 - val_loss: 0.7961\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0062 - val_loss: 0.8016\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0061 - val_loss: 0.7997\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0060 - val_loss: 0.8012\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0059 - val_loss: 0.8013\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0058 - val_loss: 0.8035\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0057 - val_loss: 0.8031\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 0.0057 - val_loss: 0.8057\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0056 - val_loss: 0.8053\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.0055 - val_loss: 0.8069\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0054 - val_loss: 0.8070\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0053 - val_loss: 0.8083\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0053 - val_loss: 0.8061\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0052 - val_loss: 0.8070\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0051 - val_loss: 0.8091\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.0050 - val_loss: 0.8106\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0050 - val_loss: 0.8120\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0049 - val_loss: 0.8129\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.0048 - val_loss: 0.8145\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0048 - val_loss: 0.8153\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.0047 - val_loss: 0.8150\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 0.0047 - val_loss: 0.8184\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.0046 - val_loss: 0.8164\n",
      "Epoch 138/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 313us/step - loss: 0.0045 - val_loss: 0.8167\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0045 - val_loss: 0.8186\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0044 - val_loss: 0.8193\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 0.0044 - val_loss: 0.8208\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 0.0043 - val_loss: 0.8203\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0042 - val_loss: 0.8234\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.0042 - val_loss: 0.8229\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 0.0041 - val_loss: 0.8234\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 360us/step - loss: 0.0041 - val_loss: 0.8238\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 0.0040 - val_loss: 0.8252\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0040 - val_loss: 0.8273\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0039 - val_loss: 0.8276\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0039 - val_loss: 0.8284\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.0038 - val_loss: 0.8287\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0038 - val_loss: 0.8289\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 0.0038 - val_loss: 0.8300\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.0037 - val_loss: 0.8313\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 0.0037 - val_loss: 0.8325\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0036 - val_loss: 0.8327\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0036 - val_loss: 0.8336\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0035 - val_loss: 0.8342\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0035 - val_loss: 0.8348\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0035 - val_loss: 0.8365\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0034 - val_loss: 0.8372\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0034 - val_loss: 0.8384\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0033 - val_loss: 0.8397\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0033 - val_loss: 0.8404\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0033 - val_loss: 0.8415\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 0.0032 - val_loss: 0.8404\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0032 - val_loss: 0.8410\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0032 - val_loss: 0.8438\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0031 - val_loss: 0.8437\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 0.0031 - val_loss: 0.8446\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 0.0031 - val_loss: 0.8461\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 0.0030 - val_loss: 0.8456\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0030 - val_loss: 0.8464\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.0030 - val_loss: 0.8463\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 0.0029 - val_loss: 0.8482\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.0029 - val_loss: 0.8501\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.0029 - val_loss: 0.8501\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 0.0028 - val_loss: 0.8504\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 0.0028 - val_loss: 0.8513\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0028 - val_loss: 0.8527\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.0027 - val_loss: 0.8531\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0027 - val_loss: 0.8532\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 0.0027 - val_loss: 0.8529\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.0027 - val_loss: 0.8540\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0026 - val_loss: 0.8555\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0026 - val_loss: 0.8570\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 0.0026 - val_loss: 0.8578\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0026 - val_loss: 0.8589\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0025 - val_loss: 0.8588\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0025 - val_loss: 0.8587\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0025 - val_loss: 0.8579\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0025 - val_loss: 0.8598\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.0024 - val_loss: 0.8610\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0024 - val_loss: 0.8610\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0024 - val_loss: 0.8622\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.0024 - val_loss: 0.8636\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0023 - val_loss: 0.8644\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.0023 - val_loss: 0.8654\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 0.0023 - val_loss: 0.8657\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.0023 - val_loss: 0.8643\n",
      " (-0.5, 2)     tanh B\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 2.3826 - val_loss: 2.3035\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 2.2381 - val_loss: 2.2049\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 2.1159 - val_loss: 2.1034\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 1.9889 - val_loss: 2.0076\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 1.8717 - val_loss: 1.9137\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 1.7523 - val_loss: 1.8215\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 1.6510 - val_loss: 1.7377\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 1.5477 - val_loss: 1.6601\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 1.4526 - val_loss: 1.5917\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 1.442 - 0s 144us/step - loss: 1.3654 - val_loss: 1.5181\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 1.2802 - val_loss: 1.4493\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 1.1993 - val_loss: 1.3841\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 1.1216 - val_loss: 1.3191\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 1.0483 - val_loss: 1.2640\n",
      "Epoch 15/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 142us/step - loss: 0.9800 - val_loss: 1.2125\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.9137 - val_loss: 1.1664\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.8555 - val_loss: 1.1201\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.8001 - val_loss: 1.0795\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 143us/step - loss: 0.7476 - val_loss: 1.0440\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.6998 - val_loss: 1.0121\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.6564 - val_loss: 0.9815\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 0.6143 - val_loss: 0.9549\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.5765 - val_loss: 0.9269\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.5414 - val_loss: 0.9043\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.5083 - val_loss: 0.8872\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.4807 - val_loss: 0.8690\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 168us/step - loss: 0.4514 - val_loss: 0.8544\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.4251 - val_loss: 0.8374\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 0.4014 - val_loss: 0.8207\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 0.3786 - val_loss: 0.8051\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.3584 - val_loss: 0.7955\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.3392 - val_loss: 0.7879\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 171us/step - loss: 0.3209 - val_loss: 0.7810\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 0.3035 - val_loss: 0.7679\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.2878 - val_loss: 0.7574\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.2731 - val_loss: 0.7484\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.2596 - val_loss: 0.7460\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 141us/step - loss: 0.2464 - val_loss: 0.7395\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 0.2344 - val_loss: 0.7331\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 172us/step - loss: 0.2230 - val_loss: 0.7288\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 135us/step - loss: 0.2120 - val_loss: 0.7263\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.2028 - val_loss: 0.7248\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 143us/step - loss: 0.1935 - val_loss: 0.7167\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 140us/step - loss: 0.1843 - val_loss: 0.7147\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.1755 - val_loss: 0.7114\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.1677 - val_loss: 0.7071\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 138us/step - loss: 0.1602 - val_loss: 0.7065\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1532 - val_loss: 0.7057\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 140us/step - loss: 0.1468 - val_loss: 0.7041\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.1403 - val_loss: 0.7010\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.1349 - val_loss: 0.6974\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.1293 - val_loss: 0.6932\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.1239 - val_loss: 0.6916\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 0.1192 - val_loss: 0.6949\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.1145 - val_loss: 0.6936\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.1102 - val_loss: 0.6906\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.1062 - val_loss: 0.6861\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.1024 - val_loss: 0.6835\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 166us/step - loss: 0.0988 - val_loss: 0.6846\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0952 - val_loss: 0.6844\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0921 - val_loss: 0.6819\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.0891 - val_loss: 0.6801\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0861 - val_loss: 0.6792\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0833 - val_loss: 0.6781\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0807 - val_loss: 0.6783\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.0782 - val_loss: 0.6776\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0758 - val_loss: 0.6752\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.0735 - val_loss: 0.6748\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0714 - val_loss: 0.6750\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0694 - val_loss: 0.6749\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0674 - val_loss: 0.6734\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0656 - val_loss: 0.6711\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0638 - val_loss: 0.6700\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 166us/step - loss: 0.0621 - val_loss: 0.6722\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.0606 - val_loss: 0.6729\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0590 - val_loss: 0.6709\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 0.0575 - val_loss: 0.6699\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 0.0561 - val_loss: 0.6696\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0548 - val_loss: 0.6698\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 166us/step - loss: 0.0534 - val_loss: 0.6702\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 178us/step - loss: 0.0522 - val_loss: 0.6709\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.0510 - val_loss: 0.6697\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.0499 - val_loss: 0.6704\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0488 - val_loss: 0.6709\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0477 - val_loss: 0.6699\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0467 - val_loss: 0.6686\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0457 - val_loss: 0.6685\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 134us/step - loss: 0.0447 - val_loss: 0.6692\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0438 - val_loss: 0.6693\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 0.0429 - val_loss: 0.6689\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0420 - val_loss: 0.6690\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 0.0412 - val_loss: 0.6692\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0404 - val_loss: 0.6689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.0396 - val_loss: 0.6693\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 140us/step - loss: 0.0388 - val_loss: 0.6689\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0381 - val_loss: 0.6695\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.0374 - val_loss: 0.6700\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.0367 - val_loss: 0.6691\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 166us/step - loss: 0.0360 - val_loss: 0.6691\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0354 - val_loss: 0.6694\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.0347 - val_loss: 0.6704\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0341 - val_loss: 0.6708\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.0335 - val_loss: 0.6702\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.0330 - val_loss: 0.6698\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.0324 - val_loss: 0.6703\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0319 - val_loss: 0.6712\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 0.0313 - val_loss: 0.6716\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0308 - val_loss: 0.6711\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0303 - val_loss: 0.6714\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0298 - val_loss: 0.6725\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.0294 - val_loss: 0.6724\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0289 - val_loss: 0.6720\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 0.0284 - val_loss: 0.6715\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.0280 - val_loss: 0.6721\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.0276 - val_loss: 0.6729\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0272 - val_loss: 0.6738\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 0.0268 - val_loss: 0.6746\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.0264 - val_loss: 0.6744\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.0260 - val_loss: 0.6732\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0256 - val_loss: 0.6733\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.0253 - val_loss: 0.6744\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.0249 - val_loss: 0.6751\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 0.0246 - val_loss: 0.6759\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0242 - val_loss: 0.6759\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.0239 - val_loss: 0.6759\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 143us/step - loss: 0.0236 - val_loss: 0.6772\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.022 - 0s 161us/step - loss: 0.0232 - val_loss: 0.6771\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.0229 - val_loss: 0.6769\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.0226 - val_loss: 0.6778\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0223 - val_loss: 0.6783\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0220 - val_loss: 0.6785\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0218 - val_loss: 0.6790\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.0215 - val_loss: 0.6796\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0212 - val_loss: 0.6798\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0210 - val_loss: 0.6796\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.0207 - val_loss: 0.6807\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.0204 - val_loss: 0.6811\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 143us/step - loss: 0.0202 - val_loss: 0.6813\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0199 - val_loss: 0.6818\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.0197 - val_loss: 0.6818\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0195 - val_loss: 0.6822\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.0192 - val_loss: 0.6829\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.0190 - val_loss: 0.6837\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.0188 - val_loss: 0.6840\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0186 - val_loss: 0.6850\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0184 - val_loss: 0.6852\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.0181 - val_loss: 0.6852\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.0179 - val_loss: 0.6859\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0177 - val_loss: 0.6863\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0175 - val_loss: 0.6871\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0173 - val_loss: 0.6877\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 0.0172 - val_loss: 0.6874\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.0170 - val_loss: 0.6883\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.0168 - val_loss: 0.6892\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 168us/step - loss: 0.0166 - val_loss: 0.6893\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0164 - val_loss: 0.6896\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 175us/step - loss: 0.0162 - val_loss: 0.6901\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0161 - val_loss: 0.6910\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0159 - val_loss: 0.6915\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.0157 - val_loss: 0.6918\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0156 - val_loss: 0.6922\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 181us/step - loss: 0.0154 - val_loss: 0.6925\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0152 - val_loss: 0.6933\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 0.0151 - val_loss: 0.6938\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0149 - val_loss: 0.6944\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.0148 - val_loss: 0.6943\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0146 - val_loss: 0.6953\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.0145 - val_loss: 0.6957\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 166us/step - loss: 0.0143 - val_loss: 0.6961\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0142 - val_loss: 0.6969\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0140 - val_loss: 0.6972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 143us/step - loss: 0.0139 - val_loss: 0.6979\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0138 - val_loss: 0.6984\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0136 - val_loss: 0.6987\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.0135 - val_loss: 0.6990\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 139us/step - loss: 0.0134 - val_loss: 0.6995\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 138us/step - loss: 0.0133 - val_loss: 0.7000\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.0131 - val_loss: 0.7009\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0130 - val_loss: 0.7011\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0129 - val_loss: 0.7012\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.0128 - val_loss: 0.7024\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 175us/step - loss: 0.0126 - val_loss: 0.7024\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0125 - val_loss: 0.7029\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0124 - val_loss: 0.7033\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0123 - val_loss: 0.7038\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 175us/step - loss: 0.0122 - val_loss: 0.7042\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0121 - val_loss: 0.7046\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 0.0120 - val_loss: 0.7050\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 0.0119 - val_loss: 0.7056\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.0118 - val_loss: 0.7062\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 169us/step - loss: 0.0117 - val_loss: 0.7067\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.0116 - val_loss: 0.7067\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0115 - val_loss: 0.7067\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 0.0114 - val_loss: 0.7073\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.0113 - val_loss: 0.7075\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0112 - val_loss: 0.7083\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0111 - val_loss: 0.7086\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.0110 - val_loss: 0.7090\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 0.0109 - val_loss: 0.7093\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0108 - val_loss: 0.7099\n",
      " (-0.5, 2)     tanh C\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 2.3430 - val_loss: 2.1877\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 2.0188 - val_loss: 1.9292\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 1.6975 - val_loss: 1.6578\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 1.3851 - val_loss: 1.3901\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 1.0896 - val_loss: 1.1503\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.8419 - val_loss: 0.9901\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.6620 - val_loss: 0.8728\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 0.5456 - val_loss: 0.7996\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.4453 - val_loss: 0.7540\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 0.3704 - val_loss: 0.7268\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.3120 - val_loss: 0.6792\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.2622 - val_loss: 0.6729\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 0.2227 - val_loss: 0.6590\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.1943 - val_loss: 0.6345\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.1639 - val_loss: 0.6295\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.1451 - val_loss: 0.6309\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.1237 - val_loss: 0.5970\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.1071 - val_loss: 0.6093\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0927 - val_loss: 0.6150\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 0.0819 - val_loss: 0.5981\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0725 - val_loss: 0.5976\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0648 - val_loss: 0.6062\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0581 - val_loss: 0.5909\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.0516 - val_loss: 0.6095\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0476 - val_loss: 0.6134\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.052 - 0s 309us/step - loss: 0.0431 - val_loss: 0.6058\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 0.0390 - val_loss: 0.6033\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 368us/step - loss: 0.0357 - val_loss: 0.6083\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 400us/step - loss: 0.0328 - val_loss: 0.6048\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 429us/step - loss: 0.0302 - val_loss: 0.6096\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 452us/step - loss: 0.0277 - val_loss: 0.6151\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 392us/step - loss: 0.0257 - val_loss: 0.6116\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 360us/step - loss: 0.0240 - val_loss: 0.6227\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 447us/step - loss: 0.0221 - val_loss: 0.6151\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 409us/step - loss: 0.0207 - val_loss: 0.6309\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 460us/step - loss: 0.0193 - val_loss: 0.6304\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 389us/step - loss: 0.0180 - val_loss: 0.6298\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.0170 - val_loss: 0.6341\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 0.0158 - val_loss: 0.6320\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 0.0151 - val_loss: 0.6363\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 403us/step - loss: 0.0141 - val_loss: 0.6450\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0133 - val_loss: 0.6405\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 378us/step - loss: 0.0125 - val_loss: 0.6428\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0119 - val_loss: 0.6467\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.0113 - val_loss: 0.6536\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0107 - val_loss: 0.6533\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0102 - val_loss: 0.6600\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 0.0097 - val_loss: 0.6623\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 294us/step - loss: 0.0093 - val_loss: 0.6626\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.0088 - val_loss: 0.6603\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 0.0085 - val_loss: 0.6659\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.0081 - val_loss: 0.6702\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0077 - val_loss: 0.6709\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0074 - val_loss: 0.6697\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0071 - val_loss: 0.6746\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0068 - val_loss: 0.6776\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0065 - val_loss: 0.6789\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 0.0062 - val_loss: 0.6789\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.0060 - val_loss: 0.6835\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0058 - val_loss: 0.6878\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.0056 - val_loss: 0.6891\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.0054 - val_loss: 0.6893\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.0052 - val_loss: 0.6958\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0050 - val_loss: 0.6999\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0048 - val_loss: 0.6987\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 352us/step - loss: 0.0047 - val_loss: 0.7002\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.005 - 0s 307us/step - loss: 0.0045 - val_loss: 0.7024\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0043 - val_loss: 0.7048\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0042 - val_loss: 0.7069\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.0041 - val_loss: 0.7097\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0040 - val_loss: 0.7121\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 0.0038 - val_loss: 0.7120\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0037 - val_loss: 0.7137\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0036 - val_loss: 0.7135\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.0035 - val_loss: 0.7189\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 0.0034 - val_loss: 0.7193\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0033 - val_loss: 0.7213\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.001 - 0s 322us/step - loss: 0.0032 - val_loss: 0.7213\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.0031 - val_loss: 0.7237\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0030 - val_loss: 0.7275\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0029 - val_loss: 0.7302\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0028 - val_loss: 0.7330\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.0027 - val_loss: 0.7348\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0027 - val_loss: 0.7341\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.0026 - val_loss: 0.7353\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.0025 - val_loss: 0.7399\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0025 - val_loss: 0.7405\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 0.0024 - val_loss: 0.7426\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 0.0023 - val_loss: 0.7430\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0023 - val_loss: 0.7443\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.0022 - val_loss: 0.7474\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 0.0021 - val_loss: 0.7475\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0021 - val_loss: 0.7478\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 0.0021 - val_loss: 0.7508\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.0020 - val_loss: 0.7550\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 0.0020 - val_loss: 0.7568\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.0019 - val_loss: 0.7593\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 0.0019 - val_loss: 0.7604\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.0018 - val_loss: 0.7612\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 0.0018 - val_loss: 0.7633\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0017 - val_loss: 0.7658\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0017 - val_loss: 0.7661\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0017 - val_loss: 0.7684\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0016 - val_loss: 0.7689\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 373us/step - loss: 0.0016 - val_loss: 0.7712\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0015 - val_loss: 0.7716\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 0.0015 - val_loss: 0.7730\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0015 - val_loss: 0.7754\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.0014 - val_loss: 0.7759\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 0.0014 - val_loss: 0.7770\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0014 - val_loss: 0.7790\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0014 - val_loss: 0.7798\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.0013 - val_loss: 0.7816\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.0013 - val_loss: 0.7838\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0013 - val_loss: 0.7846\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.0013 - val_loss: 0.7861\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0012 - val_loss: 0.7883\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0012 - val_loss: 0.7899\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 0.0012 - val_loss: 0.7917\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.0012 - val_loss: 0.7933\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0011 - val_loss: 0.7925\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.0011 - val_loss: 0.7938\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0011 - val_loss: 0.7973\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0011 - val_loss: 0.7990\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0011 - val_loss: 0.7994\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0010 - val_loss: 0.8000\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 304us/step - loss: 0.0010 - val_loss: 0.7997\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0010 - val_loss: 0.7996\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 9.8452e-04 - val_loss: 0.8015\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 9.6888e-04 - val_loss: 0.8053\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 349us/step - loss: 9.5188e-04 - val_loss: 0.8053\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 9.3454e-04 - val_loss: 0.8061\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 9.2046e-04 - val_loss: 0.8068\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 9.0340e-04 - val_loss: 0.8075\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 8.8920e-04 - val_loss: 0.8075\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 8.7361e-04 - val_loss: 0.8089\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 6.3901e-0 - 0s 299us/step - loss: 8.5827e-04 - val_loss: 0.8114\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 8.4360e-04 - val_loss: 0.8123\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 8.3033e-04 - val_loss: 0.8127\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 8.1715e-04 - val_loss: 0.8141\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 8.0353e-04 - val_loss: 0.8150\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 7.9042e-04 - val_loss: 0.8167\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 7.7761e-04 - val_loss: 0.8165\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 7.6551e-04 - val_loss: 0.8182\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 7.5390e-04 - val_loss: 0.8206\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 7.4219e-04 - val_loss: 0.8222\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 7.3147e-04 - val_loss: 0.8221\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 7.2019e-04 - val_loss: 0.8248\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 7.0895e-04 - val_loss: 0.8244\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 6.9742e-04 - val_loss: 0.8258\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 6.8616e-04 - val_loss: 0.8266\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 6.7631e-04 - val_loss: 0.8286\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 6.6576e-04 - val_loss: 0.8289\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 6.5692e-04 - val_loss: 0.8298\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 6.4560e-04 - val_loss: 0.8315\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 6.3536e-04 - val_loss: 0.8333\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 6.2700e-04 - val_loss: 0.8343\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 6.1718e-04 - val_loss: 0.8351\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 6.0955e-04 - val_loss: 0.8340\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 5.9963e-04 - val_loss: 0.8355\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 5.9130e-04 - val_loss: 0.8369\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 5.8375e-04 - val_loss: 0.8384\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 5.7496e-04 - val_loss: 0.8391\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 5.6649e-04 - val_loss: 0.8401\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 5.5862e-04 - val_loss: 0.8410\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 5.5132e-04 - val_loss: 0.8419\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 365us/step - loss: 5.4382e-04 - val_loss: 0.8405\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 5.3601e-04 - val_loss: 0.8422\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 5.2808e-04 - val_loss: 0.8436\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 5.2180e-04 - val_loss: 0.8457\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 5.1387e-04 - val_loss: 0.8476\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 5.0710e-04 - val_loss: 0.8482\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 5.0041e-04 - val_loss: 0.8489\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 4.9370e-04 - val_loss: 0.8488\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 4.8706e-04 - val_loss: 0.8512\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 4.8134e-04 - val_loss: 0.8522\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 4.7383e-04 - val_loss: 0.8522\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 4.6732e-04 - val_loss: 0.8523\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 4.6095e-04 - val_loss: 0.8529\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 4.5514e-04 - val_loss: 0.8544\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 4.4959e-04 - val_loss: 0.8548\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 4.4342e-04 - val_loss: 0.8561\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 4.3756e-04 - val_loss: 0.8573\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 4.3221e-04 - val_loss: 0.8576\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 4.2650e-04 - val_loss: 0.8584\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 4.2075e-04 - val_loss: 0.8588\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 4.1546e-04 - val_loss: 0.8597\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 4.1013e-04 - val_loss: 0.8607\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 4.0496e-04 - val_loss: 0.8623\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 4.0030e-04 - val_loss: 0.8642\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 3.9499e-04 - val_loss: 0.8642\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 3.9017e-04 - val_loss: 0.8654\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 3.8425e-04 - val_loss: 0.8649\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 377us/step - loss: 3.8048e-04 - val_loss: 0.8660\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 3.7555e-04 - val_loss: 0.8661\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 3.7044e-04 - val_loss: 0.8673\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 3.6618e-04 - val_loss: 0.8687\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 3.6173e-04 - val_loss: 0.8702\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 3.5794e-04 - val_loss: 0.8709\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 3.5332e-04 - val_loss: 0.8713\n",
      "(-0.5, 30)   linear A\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 1s 2ms/step - loss: 2.2394 - val_loss: 2.0604\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 1.9402 - val_loss: 1.8508\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 1.6606 - val_loss: 1.6243\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 1.3789 - val_loss: 1.4031\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 1.0876 - val_loss: 1.1791\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 0.8487 - val_loss: 1.0427\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 0.6722 - val_loss: 0.9035\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.5171 - val_loss: 0.8594\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.4102 - val_loss: 0.8026\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.3348 - val_loss: 0.7860\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 0.2778 - val_loss: 0.7447\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.2145 - val_loss: 0.7629\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.1736 - val_loss: 0.7360\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.1453 - val_loss: 0.7292\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 0.1163 - val_loss: 0.7358\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0953 - val_loss: 0.7252\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0815 - val_loss: 0.7315\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.0697 - val_loss: 0.7319\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0588 - val_loss: 0.7446\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0502 - val_loss: 0.7397\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0424 - val_loss: 0.7550\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0361 - val_loss: 0.7735\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0324 - val_loss: 0.7693\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0284 - val_loss: 0.7714\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0252 - val_loss: 0.7719\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0228 - val_loss: 0.7809\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0205 - val_loss: 0.7914\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.0185 - val_loss: 0.7885\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0168 - val_loss: 0.7940\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0152 - val_loss: 0.8073\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0141 - val_loss: 0.8099\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0129 - val_loss: 0.8197\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0119 - val_loss: 0.8200\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0110 - val_loss: 0.8259\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0102 - val_loss: 0.8296\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0095 - val_loss: 0.8331\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0089 - val_loss: 0.8365\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0084 - val_loss: 0.8427\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0078 - val_loss: 0.8488\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0074 - val_loss: 0.8545\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0069 - val_loss: 0.8575\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0066 - val_loss: 0.8605\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0062 - val_loss: 0.8604\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0059 - val_loss: 0.8655\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0056 - val_loss: 0.8722\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0053 - val_loss: 0.8748\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0050 - val_loss: 0.8783\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 0.0048 - val_loss: 0.8797\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0047 - val_loss: 0.8782\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0044 - val_loss: 0.8864\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0042 - val_loss: 0.8925\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0040 - val_loss: 0.8980\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0038 - val_loss: 0.8992\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0037 - val_loss: 0.9035\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0035 - val_loss: 0.9024\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0034 - val_loss: 0.9053\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0032 - val_loss: 0.9069\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0031 - val_loss: 0.9138\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0030 - val_loss: 0.9163\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0029 - val_loss: 0.9178\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0028 - val_loss: 0.9215\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0027 - val_loss: 0.9207\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.0026 - val_loss: 0.9213\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0025 - val_loss: 0.9253\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0024 - val_loss: 0.9291\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0023 - val_loss: 0.9314\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0023 - val_loss: 0.9337\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0022 - val_loss: 0.9345\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0021 - val_loss: 0.9376\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0021 - val_loss: 0.9415\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0020 - val_loss: 0.9440\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0019 - val_loss: 0.9474\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0019 - val_loss: 0.9509\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0018 - val_loss: 0.9501\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0018 - val_loss: 0.9533\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0017 - val_loss: 0.9548\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0017 - val_loss: 0.9587\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0016 - val_loss: 0.9620\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0016 - val_loss: 0.9618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0015 - val_loss: 0.9635\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0015 - val_loss: 0.9659\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0015 - val_loss: 0.9676\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.0014 - val_loss: 0.9689\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0014 - val_loss: 0.9704\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0013 - val_loss: 0.9735\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.0013 - val_loss: 0.9763\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0013 - val_loss: 0.9782\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0013 - val_loss: 0.9821\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0012 - val_loss: 0.9833\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0012 - val_loss: 0.9834\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.0012 - val_loss: 0.9850\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0011 - val_loss: 0.9872\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0011 - val_loss: 0.9889\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.0011 - val_loss: 0.9916\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0011 - val_loss: 0.9946\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0010 - val_loss: 0.9957\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0010 - val_loss: 0.9972\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 9.8762e-04 - val_loss: 0.9960\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 9.6613e-04 - val_loss: 0.9984\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 9.4230e-04 - val_loss: 1.0008\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 9.2300e-04 - val_loss: 1.0028\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 9.0205e-04 - val_loss: 1.0047\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 8.8217e-04 - val_loss: 1.0054\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 8.6658e-04 - val_loss: 1.0066\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 8.4728e-04 - val_loss: 1.0093\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 8.2902e-04 - val_loss: 1.0115\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 8.1465e-04 - val_loss: 1.0126\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 7.9513e-04 - val_loss: 1.0143\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 7.7930e-04 - val_loss: 1.0165\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 7.6372e-04 - val_loss: 1.0167\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 7.4872e-04 - val_loss: 1.0182\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 7.3331e-04 - val_loss: 1.0200\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 7.1908e-04 - val_loss: 1.0235\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 7.0579e-04 - val_loss: 1.0252\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 6.9281e-04 - val_loss: 1.0267\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 6.7866e-04 - val_loss: 1.0274\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 6.6678e-04 - val_loss: 1.0273\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 6.5456e-04 - val_loss: 1.0301\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 6.4273e-04 - val_loss: 1.0304\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 6.3075e-04 - val_loss: 1.0315\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 6.1969e-04 - val_loss: 1.0326\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 6.0824e-04 - val_loss: 1.0332\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 5.9781e-04 - val_loss: 1.0350\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 5.8679e-04 - val_loss: 1.0367\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 5.7642e-04 - val_loss: 1.0385\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 5.6671e-04 - val_loss: 1.0384\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 5.5644e-04 - val_loss: 1.0394\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 5.4774e-04 - val_loss: 1.0412\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 5.3813e-04 - val_loss: 1.0424\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 5.3077e-04 - val_loss: 1.0447\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 5.2018e-04 - val_loss: 1.0469\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 5.1172e-04 - val_loss: 1.0486\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 5.0344e-04 - val_loss: 1.0494\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 4.9425e-04 - val_loss: 1.0501\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 4.8713e-04 - val_loss: 1.0507\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 4.7901e-04 - val_loss: 1.0517\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 4.7128e-04 - val_loss: 1.0538\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 4.6413e-04 - val_loss: 1.0547\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 4.5682e-04 - val_loss: 1.0543\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 4.4908e-04 - val_loss: 1.0566\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 4.4220e-04 - val_loss: 1.0576\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 4.3529e-04 - val_loss: 1.0589\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 4.2793e-04 - val_loss: 1.0594\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 4.2166e-04 - val_loss: 1.0604\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 4.1612e-04 - val_loss: 1.0595\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 4.0913e-04 - val_loss: 1.0614\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 4.0301e-04 - val_loss: 1.0643\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 3.9707e-04 - val_loss: 1.0648\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 3.9070e-04 - val_loss: 1.0651\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 3.8552e-04 - val_loss: 1.0658\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 3.7948e-04 - val_loss: 1.0677\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 3.7371e-04 - val_loss: 1.0697\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 3.6944e-04 - val_loss: 1.0711\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 3.6348e-04 - val_loss: 1.0729\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 3.5831e-04 - val_loss: 1.0731\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 292us/step - loss: 3.5336e-04 - val_loss: 1.0745\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 3.4888e-04 - val_loss: 1.0779\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 3.4350e-04 - val_loss: 1.0782\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 3.3793e-04 - val_loss: 1.0781\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 3.3358e-04 - val_loss: 1.0788\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 3.2854e-04 - val_loss: 1.0798\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 3.2423e-04 - val_loss: 1.0809\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 3.1974e-04 - val_loss: 1.0827\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 3.1521e-04 - val_loss: 1.0835\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 3.1094e-04 - val_loss: 1.0853\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 3.0717e-04 - val_loss: 1.0855\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 3.0282e-04 - val_loss: 1.0867\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 2.9838e-04 - val_loss: 1.0867\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 2.9500e-04 - val_loss: 1.0879\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 2.9077e-04 - val_loss: 1.0894\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 2.8712e-04 - val_loss: 1.0915\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 2.8317e-04 - val_loss: 1.0918\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 2.7989e-04 - val_loss: 1.0939\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 2.7615e-04 - val_loss: 1.0934\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 2.7233e-04 - val_loss: 1.0946\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 2.6894e-04 - val_loss: 1.0963\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 2.6514e-04 - val_loss: 1.0970\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 2.6179e-04 - val_loss: 1.0975\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 2.5836e-04 - val_loss: 1.0977\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 2.5518e-04 - val_loss: 1.0989\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 2.5211e-04 - val_loss: 1.1000\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 2.4877e-04 - val_loss: 1.1002\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 2.4591e-04 - val_loss: 1.1009\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 2.4294e-04 - val_loss: 1.1017\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 2.3986e-04 - val_loss: 1.1036\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 2.3686e-04 - val_loss: 1.1046\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 2.3418e-04 - val_loss: 1.1056\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 2.3098e-04 - val_loss: 1.1072\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 2.2852e-04 - val_loss: 1.1082\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 2.2574e-04 - val_loss: 1.1086\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 2.2334e-04 - val_loss: 1.1111\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 2.2073e-04 - val_loss: 1.1107\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 2.1752e-04 - val_loss: 1.1115\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 2.1509e-04 - val_loss: 1.1112\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 2.1231e-04 - val_loss: 1.1127\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 2.0960e-04 - val_loss: 1.1143\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 2.0717e-04 - val_loss: 1.1151\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 2.0481e-04 - val_loss: 1.1160\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 2.0255e-04 - val_loss: 1.1170\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 2.0020e-04 - val_loss: 1.1174\n",
      "(-0.5, 30)   linear B\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 7.9318 - val_loss: 7.1568\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 7.4706 - val_loss: 6.8823\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 7.2108 - val_loss: 6.6376\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 6.9324 - val_loss: 6.2893\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 6.5793 - val_loss: 5.8764\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 6.1889 - val_loss: 5.4287\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 5.7494 - val_loss: 4.9940\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 5.3632 - val_loss: 4.6552\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 5.0927 - val_loss: 4.4813\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 4.8895 - val_loss: 4.3521\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 4.7312 - val_loss: 4.1632\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.5255 - val_loss: 3.9489\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 4.3082 - val_loss: 3.7427\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 4.1104 - val_loss: 3.5530\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 3.9064 - val_loss: 3.3664\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 3.6961 - val_loss: 3.1717\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 3.4930 - val_loss: 2.9846\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 3.3029 - val_loss: 2.8348\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 3.1431 - val_loss: 2.7168\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 3.0210 - val_loss: 2.6124\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 143us/step - loss: 2.9006 - val_loss: 2.5199\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 2.8013 - val_loss: 2.4366\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.7223 - val_loss: 2.3670\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 2.6556 - val_loss: 2.3158\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 2.6049 - val_loss: 2.2723\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 2.5606 - val_loss: 2.2385\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 2.5274 - val_loss: 2.2122\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 2.4933 - val_loss: 2.1809\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 2.4652 - val_loss: 2.1642\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 2.4391 - val_loss: 2.1481\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 2.4131 - val_loss: 2.1305\n",
      "Epoch 32/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 144us/step - loss: 2.3955 - val_loss: 2.1099\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 190us/step - loss: 2.3751 - val_loss: 2.0954\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 2.3580 - val_loss: 2.0851\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 2.3440 - val_loss: 2.0748\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 2.3291 - val_loss: 2.0661\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 2.3159 - val_loss: 2.0594\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.3067 - val_loss: 2.0563\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 2.2973 - val_loss: 2.0503\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 2.2873 - val_loss: 2.0445\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 2.2800 - val_loss: 2.0373\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 2.2725 - val_loss: 2.0295\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 2.2665 - val_loss: 2.0257\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 2.2614 - val_loss: 2.0219\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 2.2563 - val_loss: 2.0183\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 2.2522 - val_loss: 2.0153\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 2.2486 - val_loss: 2.0124\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 2.2450 - val_loss: 2.0079\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 2.2423 - val_loss: 2.0051\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 2.2392 - val_loss: 2.0033\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 2.2369 - val_loss: 2.0020\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 2.2348 - val_loss: 2.0008\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 2.2329 - val_loss: 1.9984\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 2.2312 - val_loss: 1.9969\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 2.2295 - val_loss: 1.9966\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 175us/step - loss: 2.2279 - val_loss: 1.9946\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 2.2266 - val_loss: 1.9937\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 2.2253 - val_loss: 1.9929\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 2.2241 - val_loss: 1.9919\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 180us/step - loss: 2.2231 - val_loss: 1.9911\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 2.2221 - val_loss: 1.9901\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 2.2212 - val_loss: 1.9900\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 2.2204 - val_loss: 1.9889\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 139us/step - loss: 2.2196 - val_loss: 1.9889\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 172us/step - loss: 2.2189 - val_loss: 1.9884\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 2.2181 - val_loss: 1.9880\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 2.2176 - val_loss: 1.9875\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 2.2170 - val_loss: 1.9865\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 182us/step - loss: 2.2164 - val_loss: 1.9859\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 166us/step - loss: 2.2159 - val_loss: 1.9856\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 2.2154 - val_loss: 1.9854\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 2.2149 - val_loss: 1.9854\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 2.2145 - val_loss: 1.9855\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 2.2141 - val_loss: 1.9854\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 2.2137 - val_loss: 1.9853\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 171us/step - loss: 2.2133 - val_loss: 1.9848\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 2.2130 - val_loss: 1.9847\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 2.2127 - val_loss: 1.9842\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 2.2124 - val_loss: 1.9844\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 2.2121 - val_loss: 1.9842\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.2117 - val_loss: 1.9843\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.2115 - val_loss: 1.9846\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 2.2112 - val_loss: 1.9848\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 2.2110 - val_loss: 1.9846\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 2.2107 - val_loss: 1.9845\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 2.2105 - val_loss: 1.9843\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 2.2103 - val_loss: 1.9844\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 171us/step - loss: 2.2101 - val_loss: 1.9843\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 2.2099 - val_loss: 1.9847\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 2.2097 - val_loss: 1.9845\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 2.2095 - val_loss: 1.9847\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 2.2094 - val_loss: 1.9849\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 2.2092 - val_loss: 1.9848\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 2.2090 - val_loss: 1.9849\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 2.2089 - val_loss: 1.9850\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 2.2087 - val_loss: 1.9850\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 2.2086 - val_loss: 1.9851\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 2.2084 - val_loss: 1.9853\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 2.2083 - val_loss: 1.9853\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 2.2082 - val_loss: 1.9853\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 2.2080 - val_loss: 1.9855\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 191us/step - loss: 2.2079 - val_loss: 1.9858\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 2.2078 - val_loss: 1.9859\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 2.2077 - val_loss: 1.9860\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 2.2076 - val_loss: 1.9860\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 2.2075 - val_loss: 1.9861\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 2.2074 - val_loss: 1.9861\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 2.2073 - val_loss: 1.9861\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 2.2072 - val_loss: 1.9861\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 2.2071 - val_loss: 1.9863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 166us/step - loss: 2.2070 - val_loss: 1.9866\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 2.2069 - val_loss: 1.9867\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 2.2069 - val_loss: 1.9868\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 2.2068 - val_loss: 1.9871\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 2.2067 - val_loss: 1.9872\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 2.2066 - val_loss: 1.9871\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 2.2065 - val_loss: 1.9871\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 2.2065 - val_loss: 1.9874\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 2.2064 - val_loss: 1.9874\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 2.2063 - val_loss: 1.9875\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 2.2063 - val_loss: 1.9875\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.2062 - val_loss: 1.9876\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.2062 - val_loss: 1.9879\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 2.2061 - val_loss: 1.9881\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 2.2060 - val_loss: 1.9882\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 2.2060 - val_loss: 1.9884\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 2.2059 - val_loss: 1.9885\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.2059 - val_loss: 1.9888\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 2.2058 - val_loss: 1.9891\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 2.2058 - val_loss: 1.9893\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 2.2057 - val_loss: 1.9895\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 2.2057 - val_loss: 1.9896\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 2.2056 - val_loss: 1.9897\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 2.2056 - val_loss: 1.9899\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 2.2055 - val_loss: 1.9901\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 2.2055 - val_loss: 1.9904\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 2.2055 - val_loss: 1.9906\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 2.2054 - val_loss: 1.9908\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 2.581 - 0s 162us/step - loss: 2.2054 - val_loss: 1.9908\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 172us/step - loss: 2.2053 - val_loss: 1.9910\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 2.2053 - val_loss: 1.9911\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 2.2053 - val_loss: 1.9914\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 2.2052 - val_loss: 1.9916\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 186us/step - loss: 2.2052 - val_loss: 1.9918\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 2.2052 - val_loss: 1.9918\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 2.2051 - val_loss: 1.9920\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 199us/step - loss: 2.2051 - val_loss: 1.9921\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 261us/step - loss: 2.2051 - val_loss: 1.9924\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 2.2050 - val_loss: 1.9927\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 174us/step - loss: 2.2050 - val_loss: 1.9929\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 2.2050 - val_loss: 1.9931\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 2.2049 - val_loss: 1.9932\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 171us/step - loss: 2.2049 - val_loss: 1.9932\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 2.2049 - val_loss: 1.9934\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 2.2048 - val_loss: 1.9936\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 170us/step - loss: 2.2048 - val_loss: 1.9938\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 2.2048 - val_loss: 1.9940\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 169us/step - loss: 2.2048 - val_loss: 1.9943\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 2.2047 - val_loss: 1.9945\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 2.2047 - val_loss: 1.9947\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 2.2047 - val_loss: 1.9948\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 2.2047 - val_loss: 1.9950\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 2.2046 - val_loss: 1.9951\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.2046 - val_loss: 1.9953\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 2.2046 - val_loss: 1.9955\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 2.2046 - val_loss: 1.9956\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 2.2046 - val_loss: 1.9957\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 2.2045 - val_loss: 1.9960\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 2.2045 - val_loss: 1.9962\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 2.2045 - val_loss: 1.9965\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 2.2045 - val_loss: 1.9967\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 2.2044 - val_loss: 1.9969\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 2.2044 - val_loss: 1.9970\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 2.2044 - val_loss: 1.9971\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 2.2044 - val_loss: 1.9973\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 143us/step - loss: 2.2044 - val_loss: 1.9975\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 2.2044 - val_loss: 1.9978\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 2.2043 - val_loss: 1.9980\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 2.2043 - val_loss: 1.9982\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 2.2043 - val_loss: 1.9984\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 2.2043 - val_loss: 1.9985\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 166us/step - loss: 2.2043 - val_loss: 1.9987\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.2043 - val_loss: 1.9990\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 2.2042 - val_loss: 1.9990\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 2.2042 - val_loss: 1.9992\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 2.2042 - val_loss: 1.9994\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 2.2042 - val_loss: 1.9997\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 2.2042 - val_loss: 1.9999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 2.2042 - val_loss: 2.0000\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 2.2041 - val_loss: 2.0002\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 2.2041 - val_loss: 2.0003\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 2.2041 - val_loss: 2.0005\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 2.2041 - val_loss: 2.0007\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 2.2041 - val_loss: 2.0009\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 2.2041 - val_loss: 2.0011\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 2.2041 - val_loss: 2.0012\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 2.2041 - val_loss: 2.0014\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 2.2040 - val_loss: 2.0016\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 2.2040 - val_loss: 2.0018\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 2.2040 - val_loss: 2.0020\n",
      "(-0.5, 30)   linear C\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 5.9986 - val_loss: 5.1486\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 4.6118 - val_loss: 3.5765\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 2.9877 - val_loss: 2.9161\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 2.4557 - val_loss: 2.3801\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 1.9223 - val_loss: 1.8639\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 1.4787 - val_loss: 1.4284\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 1.0738 - val_loss: 1.0551\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.7488 - val_loss: 0.8247\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 0.5750 - val_loss: 0.7163\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 0.4551 - val_loss: 0.6535\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.3717 - val_loss: 0.6129\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.3120 - val_loss: 0.5752\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.2668 - val_loss: 0.5371\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.2253 - val_loss: 0.5161\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.2030 - val_loss: 0.5089\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.1752 - val_loss: 0.5000\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.1500 - val_loss: 0.4695\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.1334 - val_loss: 0.4622\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.1205 - val_loss: 0.4633\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.1035 - val_loss: 0.4485\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0937 - val_loss: 0.4427\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 0.0826 - val_loss: 0.4422\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0741 - val_loss: 0.4360\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 0.0668 - val_loss: 0.4298\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0597 - val_loss: 0.4262\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0543 - val_loss: 0.4250\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0495 - val_loss: 0.4248\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 0.0447 - val_loss: 0.4219\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0406 - val_loss: 0.4216\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0375 - val_loss: 0.4246\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0346 - val_loss: 0.4192\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 0.0318 - val_loss: 0.4195\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0297 - val_loss: 0.4178\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 0.0275 - val_loss: 0.4220\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0258 - val_loss: 0.4187\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.0240 - val_loss: 0.4151\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0227 - val_loss: 0.4172\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0210 - val_loss: 0.4181\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0201 - val_loss: 0.4214\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0187 - val_loss: 0.4217\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0178 - val_loss: 0.4207\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0169 - val_loss: 0.4224\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 0.0159 - val_loss: 0.4217\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0150 - val_loss: 0.4226\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0144 - val_loss: 0.4206\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0137 - val_loss: 0.4222\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 0.0130 - val_loss: 0.4262\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0124 - val_loss: 0.4260\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0118 - val_loss: 0.4237\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0112 - val_loss: 0.4250\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 263us/step - loss: 0.0108 - val_loss: 0.4270\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0103 - val_loss: 0.4253\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0099 - val_loss: 0.4247\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0095 - val_loss: 0.4272\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0091 - val_loss: 0.4296\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0087 - val_loss: 0.4319\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0084 - val_loss: 0.4314\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0081 - val_loss: 0.4318\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0078 - val_loss: 0.4308\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0075 - val_loss: 0.4305\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0072 - val_loss: 0.4325\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0070 - val_loss: 0.4350\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0067 - val_loss: 0.4353\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.0065 - val_loss: 0.4355\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0063 - val_loss: 0.4370\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0061 - val_loss: 0.4387\n",
      "Epoch 67/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 275us/step - loss: 0.0059 - val_loss: 0.4386\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0057 - val_loss: 0.4392\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0055 - val_loss: 0.4410\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.003 - 0s 345us/step - loss: 0.0054 - val_loss: 0.4425\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0052 - val_loss: 0.4411\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 0.0050 - val_loss: 0.4412\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0049 - val_loss: 0.4426\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0048 - val_loss: 0.4424\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0046 - val_loss: 0.4437\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0045 - val_loss: 0.4452\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0044 - val_loss: 0.4465\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0042 - val_loss: 0.4469\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 0.0041 - val_loss: 0.4483\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.0040 - val_loss: 0.4488\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0039 - val_loss: 0.4506\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 0.0038 - val_loss: 0.4504\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 0.0037 - val_loss: 0.4509\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0036 - val_loss: 0.4518\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.0035 - val_loss: 0.4533\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 0.0035 - val_loss: 0.4528\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0034 - val_loss: 0.4536\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.002 - 0s 338us/step - loss: 0.0033 - val_loss: 0.4536\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0032 - val_loss: 0.4546\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0031 - val_loss: 0.4559\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0031 - val_loss: 0.4578\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 0.0030 - val_loss: 0.4575\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 0.0029 - val_loss: 0.4580\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.0028 - val_loss: 0.4595\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0028 - val_loss: 0.4591\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0027 - val_loss: 0.4598\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 0.0027 - val_loss: 0.4613\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0026 - val_loss: 0.4605\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0025 - val_loss: 0.4615\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0025 - val_loss: 0.4624\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0024 - val_loss: 0.4638\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0024 - val_loss: 0.4651\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0023 - val_loss: 0.4653\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0023 - val_loss: 0.4659\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0022 - val_loss: 0.4668\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0022 - val_loss: 0.4675\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0022 - val_loss: 0.4680\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0021 - val_loss: 0.4688\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.0021 - val_loss: 0.4691\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 0.0020 - val_loss: 0.4698\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0020 - val_loss: 0.4713\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0020 - val_loss: 0.4713\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0019 - val_loss: 0.4717\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0019 - val_loss: 0.4723\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0018 - val_loss: 0.4720\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0018 - val_loss: 0.4725\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0018 - val_loss: 0.4746\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0017 - val_loss: 0.4760\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0017 - val_loss: 0.4765\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0017 - val_loss: 0.4772\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0017 - val_loss: 0.4781\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0016 - val_loss: 0.4783\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 0.0016 - val_loss: 0.4788\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0016 - val_loss: 0.4795\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0015 - val_loss: 0.4796\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0015 - val_loss: 0.4801\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0015 - val_loss: 0.4819\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0015 - val_loss: 0.4830\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0014 - val_loss: 0.4828\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0014 - val_loss: 0.4820\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.0014 - val_loss: 0.4830\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0014 - val_loss: 0.4831\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0013 - val_loss: 0.4839\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0013 - val_loss: 0.4852\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0013 - val_loss: 0.4863\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 0.0013 - val_loss: 0.4865\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0013 - val_loss: 0.4874\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0012 - val_loss: 0.4874\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0012 - val_loss: 0.4872\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0012 - val_loss: 0.4881\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 0.0012 - val_loss: 0.4890\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 0.0012 - val_loss: 0.4893\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 261us/step - loss: 0.0011 - val_loss: 0.4906\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0011 - val_loss: 0.4906\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 277us/step - loss: 0.0011 - val_loss: 0.4917\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0011 - val_loss: 0.4920\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0011 - val_loss: 0.4917\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0011 - val_loss: 0.4920\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0010 - val_loss: 0.4920\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0010 - val_loss: 0.4926\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.0010 - val_loss: 0.4943\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0010 - val_loss: 0.4945\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 9.8375e-04 - val_loss: 0.4955\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 9.7063e-04 - val_loss: 0.4961\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 9.5646e-04 - val_loss: 0.4969\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 9.4320e-04 - val_loss: 0.4976\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 9.2880e-04 - val_loss: 0.4989\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 9.1567e-04 - val_loss: 0.4994\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 9.0297e-04 - val_loss: 0.4994\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 8.9015e-04 - val_loss: 0.4999\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 8.7738e-04 - val_loss: 0.5003\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 8.6549e-04 - val_loss: 0.5009\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 8.5325e-04 - val_loss: 0.5020\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 8.4159e-04 - val_loss: 0.5025\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 8.3012e-04 - val_loss: 0.5030\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 8.1864e-04 - val_loss: 0.5035\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 8.0962e-04 - val_loss: 0.5038\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 7.9683e-04 - val_loss: 0.5043\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 7.8753e-04 - val_loss: 0.5040\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 7.7731e-04 - val_loss: 0.5047\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 7.6679e-04 - val_loss: 0.5058\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 7.5638e-04 - val_loss: 0.5063\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 7.4703e-04 - val_loss: 0.5062\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 7.3716e-04 - val_loss: 0.5072\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 7.2874e-04 - val_loss: 0.5076\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 7.1840e-04 - val_loss: 0.5075\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 7.0940e-04 - val_loss: 0.5088\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 7.0054e-04 - val_loss: 0.5095\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 6.9077e-04 - val_loss: 0.5103\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 6.8231e-04 - val_loss: 0.5109\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 6.7286e-04 - val_loss: 0.5110\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 6.6481e-04 - val_loss: 0.5110\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 6.5610e-04 - val_loss: 0.5121\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 6.4933e-04 - val_loss: 0.5125\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 6.4114e-04 - val_loss: 0.5128\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 6.3296e-04 - val_loss: 0.5137\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 6.2543e-04 - val_loss: 0.5138\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 6.1698e-04 - val_loss: 0.5143\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 6.1025e-04 - val_loss: 0.5151\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 6.0240e-04 - val_loss: 0.5163\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 5.9577e-04 - val_loss: 0.5170\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 5.8805e-04 - val_loss: 0.5167\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 5.8096e-04 - val_loss: 0.5165\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 5.7436e-04 - val_loss: 0.5169\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 5.6651e-04 - val_loss: 0.5182\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 5.6077e-04 - val_loss: 0.5189\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 5.5444e-04 - val_loss: 0.5193\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 5.4817e-04 - val_loss: 0.5197\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 5.4135e-04 - val_loss: 0.5203\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 373us/step - loss: 5.3558e-04 - val_loss: 0.5206\n",
      "(-0.5, 30)     relu A\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 2.2692 - val_loss: 2.2172\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 2.1192 - val_loss: 2.0895\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 1.9365 - val_loss: 1.9299\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 573us/step - loss: 1.7178 - val_loss: 1.7403\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 603us/step - loss: 1.4772 - val_loss: 1.5482\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 379us/step - loss: 1.2399 - val_loss: 1.3336\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 1.0094 - val_loss: 1.1795\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.8182 - val_loss: 1.0510\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.6741 - val_loss: 0.9692\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 0.5596 - val_loss: 0.9407\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.4678 - val_loss: 0.8609\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 0.3963 - val_loss: 0.8621\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.3257 - val_loss: 0.8450\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.2775 - val_loss: 0.8210\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 0.2353 - val_loss: 0.8067\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.2007 - val_loss: 0.8327\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.1706 - val_loss: 0.8183\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 0.1420 - val_loss: 0.8160\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 0.1190 - val_loss: 0.8199\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 0.1010 - val_loss: 0.7917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0894 - val_loss: 0.8408\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 0.0746 - val_loss: 0.8102\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0651 - val_loss: 0.8529\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 0.0561 - val_loss: 0.8375\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.0489 - val_loss: 0.8391\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0427 - val_loss: 0.8544\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 0.0392 - val_loss: 0.8463\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0341 - val_loss: 0.8662\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.0301 - val_loss: 0.8820\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.0269 - val_loss: 0.8656\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.0239 - val_loss: 0.8800\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 0.0221 - val_loss: 0.8906\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 0.0198 - val_loss: 0.8851\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 0.0182 - val_loss: 0.9018\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 0.0168 - val_loss: 0.9049\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 0.0153 - val_loss: 0.9104\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 0.0145 - val_loss: 0.9101\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 373us/step - loss: 0.0133 - val_loss: 0.9161\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.0125 - val_loss: 0.9319\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 0.0116 - val_loss: 0.9313\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0111 - val_loss: 0.9286\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 0.0103 - val_loss: 0.9355\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.0097 - val_loss: 0.9471\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0091 - val_loss: 0.9533\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.0086 - val_loss: 0.9549\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.0082 - val_loss: 0.9595\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.0077 - val_loss: 0.9669\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0073 - val_loss: 0.9667\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.0069 - val_loss: 0.9650\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.0065 - val_loss: 0.9733\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.0062 - val_loss: 0.9813\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.0060 - val_loss: 0.9917\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.0057 - val_loss: 0.9865\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0054 - val_loss: 0.9856\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 0.0052 - val_loss: 0.9997\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.0049 - val_loss: 0.9973\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.0047 - val_loss: 1.0044\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 0.0045 - val_loss: 1.0048\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 0.0043 - val_loss: 1.0078\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 0.0042 - val_loss: 1.0116\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.0040 - val_loss: 1.0190\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 0.0039 - val_loss: 1.0209\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0037 - val_loss: 1.0236\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 0.0036 - val_loss: 1.0276\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0035 - val_loss: 1.0306\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0033 - val_loss: 1.0322\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.0032 - val_loss: 1.0363\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.0031 - val_loss: 1.0358\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 0.0030 - val_loss: 1.0441\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 0.0029 - val_loss: 1.0425\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 0.0028 - val_loss: 1.0509\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 0.0027 - val_loss: 1.0542\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.0026 - val_loss: 1.0529\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.0025 - val_loss: 1.0524\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0025 - val_loss: 1.0617\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 0.0024 - val_loss: 1.0670\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0023 - val_loss: 1.0685\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.0023 - val_loss: 1.0701\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 354us/step - loss: 0.0022 - val_loss: 1.0724\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 0.0021 - val_loss: 1.0716\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.0021 - val_loss: 1.0761\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 0.0020 - val_loss: 1.0815\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 0.0020 - val_loss: 1.0807\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.0019 - val_loss: 1.0816\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.0019 - val_loss: 1.0846\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.0018 - val_loss: 1.0904\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0018 - val_loss: 1.0916\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0017 - val_loss: 1.0912\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0017 - val_loss: 1.0945\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0016 - val_loss: 1.0987\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0016 - val_loss: 1.1036\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0015 - val_loss: 1.1044\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 343us/step - loss: 0.0015 - val_loss: 1.1070\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.0015 - val_loss: 1.1100\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 0.0014 - val_loss: 1.1106\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.0014 - val_loss: 1.1143\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 0.0014 - val_loss: 1.1160\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0013 - val_loss: 1.1211\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.0013 - val_loss: 1.1214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 0.0013 - val_loss: 1.1231\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.0013 - val_loss: 1.1254\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0012 - val_loss: 1.1267\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0012 - val_loss: 1.1281\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0012 - val_loss: 1.1307\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.0011 - val_loss: 1.1339\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.0011 - val_loss: 1.1344\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0011 - val_loss: 1.1359\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 0.0011 - val_loss: 1.1396\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.0011 - val_loss: 1.1433\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0010 - val_loss: 1.1440\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.0010 - val_loss: 1.1448\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 9.9327e-04 - val_loss: 1.1470\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 9.7673e-04 - val_loss: 1.1483\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 9.5557e-04 - val_loss: 1.1520\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 9.3894e-04 - val_loss: 1.1544\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 9.1939e-04 - val_loss: 1.1521\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 9.0193e-04 - val_loss: 1.1552\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 8.8626e-04 - val_loss: 1.1604\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 8.6867e-04 - val_loss: 1.1577\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 8.5006e-04 - val_loss: 1.1587\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 8.3398e-04 - val_loss: 1.1618\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 8.1902e-04 - val_loss: 1.1617\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 8.0285e-04 - val_loss: 1.1651\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 7.8833e-04 - val_loss: 1.1676\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 7.7326e-04 - val_loss: 1.1685\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 7.5963e-04 - val_loss: 1.1702\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 7.4728e-04 - val_loss: 1.1713\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 7.3326e-04 - val_loss: 1.1745\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 7.2212e-04 - val_loss: 1.1762\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 7.0892e-04 - val_loss: 1.1781\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 6.9682e-04 - val_loss: 1.1785\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 6.8377e-04 - val_loss: 1.1807\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 6.7351e-04 - val_loss: 1.1827\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 6.6127e-04 - val_loss: 1.1838\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 6.5110e-04 - val_loss: 1.1873\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 6.3911e-04 - val_loss: 1.1861\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 6.2949e-04 - val_loss: 1.1881\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 6.1878e-04 - val_loss: 1.1890\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 6.0843e-04 - val_loss: 1.1915\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 5.9905e-04 - val_loss: 1.1942\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 5.9051e-04 - val_loss: 1.1968\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 5.7937e-04 - val_loss: 1.1968\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 5.6966e-04 - val_loss: 1.1974\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 5.6237e-04 - val_loss: 1.1987\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 5.5405e-04 - val_loss: 1.2013\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 5.4421e-04 - val_loss: 1.2020\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 5.3644e-04 - val_loss: 1.2014\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 5.2736e-04 - val_loss: 1.2047\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 5.1958e-04 - val_loss: 1.2068\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 5.1187e-04 - val_loss: 1.2080\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 5.0475e-04 - val_loss: 1.2108\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 4.9680e-04 - val_loss: 1.2090\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 4.8878e-04 - val_loss: 1.2107\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 4.8174e-04 - val_loss: 1.2137\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 4.7438e-04 - val_loss: 1.2149\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 4.6756e-04 - val_loss: 1.2149\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 4.6161e-04 - val_loss: 1.2146\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 4.5475e-04 - val_loss: 1.2196\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 4.4814e-04 - val_loss: 1.2189\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 3.5808e-0 - 0s 319us/step - loss: 4.4077e-04 - val_loss: 1.2212\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 4.3471e-04 - val_loss: 1.2225\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 4.2824e-04 - val_loss: 1.2248\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 4.2194e-04 - val_loss: 1.2242\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 353us/step - loss: 4.1612e-04 - val_loss: 1.2251\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 4.0990e-04 - val_loss: 1.2272\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 4.0426e-04 - val_loss: 1.2291\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 3.9837e-04 - val_loss: 1.2300\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 3.9253e-04 - val_loss: 1.2315\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 3.8686e-04 - val_loss: 1.2321\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 3.8128e-04 - val_loss: 1.2334\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 3.7587e-04 - val_loss: 1.2344\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 3.7043e-04 - val_loss: 1.2358\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 3.6529e-04 - val_loss: 1.2374\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 3.5994e-04 - val_loss: 1.2402\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 322us/step - loss: 3.5546e-04 - val_loss: 1.2415\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 3.5067e-04 - val_loss: 1.2418\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 3.4605e-04 - val_loss: 1.2415\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 3.4105e-04 - val_loss: 1.2442\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 3.3684e-04 - val_loss: 1.2458\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 3.3236e-04 - val_loss: 1.2462\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 3.2820e-04 - val_loss: 1.2458\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 3.2441e-04 - val_loss: 1.2482\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 3.1970e-04 - val_loss: 1.2485\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 3.1564e-04 - val_loss: 1.2495\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 3.1163e-04 - val_loss: 1.2499\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 3.0742e-04 - val_loss: 1.2521\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 3.0344e-04 - val_loss: 1.2542\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 2.9963e-04 - val_loss: 1.2549\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 2.9594e-04 - val_loss: 1.2558\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 2.9213e-04 - val_loss: 1.2563\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 2.8827e-04 - val_loss: 1.2584\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 395us/step - loss: 2.8482e-04 - val_loss: 1.2597\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 2.8158e-04 - val_loss: 1.2605\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 2.7819e-04 - val_loss: 1.2616\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 2.7454e-04 - val_loss: 1.2637\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 2.7105e-04 - val_loss: 1.2641\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 2.6775e-04 - val_loss: 1.2644\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 2.6466e-04 - val_loss: 1.2652\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 2.6112e-04 - val_loss: 1.2664\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 2.5815e-04 - val_loss: 1.2674\n",
      "(-0.5, 30)     relu B\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 5.5557 - val_loss: 5.3425\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 5.2484 - val_loss: 5.1028\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 4.9828 - val_loss: 4.8658\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 4.7062 - val_loss: 4.6821\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 196us/step - loss: 4.5052 - val_loss: 4.5131\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 4.2964 - val_loss: 4.2870\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 179us/step - loss: 4.0294 - val_loss: 4.0425\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 173us/step - loss: 3.7704 - val_loss: 3.8128\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 3.4877 - val_loss: 3.5768\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 3.1959 - val_loss: 3.3631\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 2.9350 - val_loss: 3.1757\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 2.7082 - val_loss: 2.9730\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 2.4855 - val_loss: 2.7699\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 169us/step - loss: 2.2892 - val_loss: 2.5730\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 2.1095 - val_loss: 2.3992\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 1.9615 - val_loss: 2.2495\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 1.8246 - val_loss: 2.1053\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 1.6796 - val_loss: 1.9636\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 1.5618 - val_loss: 1.8195\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 1.4183 - val_loss: 1.6698\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 1.2975 - val_loss: 1.5242\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 176us/step - loss: 1.1666 - val_loss: 1.3918\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 1.0500 - val_loss: 1.2806\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.9328 - val_loss: 1.1787\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 170us/step - loss: 0.8264 - val_loss: 1.0792\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 166us/step - loss: 0.7390 - val_loss: 0.9971\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.6588 - val_loss: 0.9551\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 169us/step - loss: 0.5890 - val_loss: 0.8946\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 179us/step - loss: 0.5185 - val_loss: 0.8397\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.4641 - val_loss: 0.7987\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.4139 - val_loss: 0.7658\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.3684 - val_loss: 0.7276\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.3285 - val_loss: 0.7028\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.2912 - val_loss: 0.6848\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.2578 - val_loss: 0.6605\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.2315 - val_loss: 0.6390\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.2082 - val_loss: 0.6322\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.1866 - val_loss: 0.6208\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 0.1659 - val_loss: 0.6107\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.1496 - val_loss: 0.6035\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.1354 - val_loss: 0.6030\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.1206 - val_loss: 0.5925\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.1101 - val_loss: 0.5875\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0994 - val_loss: 0.5850\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.0910 - val_loss: 0.5838\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 0.0833 - val_loss: 0.5817\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0769 - val_loss: 0.5848\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0698 - val_loss: 0.5777\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 0.0643 - val_loss: 0.5748\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0597 - val_loss: 0.5707\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.0551 - val_loss: 0.5698\n",
      "Epoch 52/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 160us/step - loss: 0.0514 - val_loss: 0.5691\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0480 - val_loss: 0.5699\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0448 - val_loss: 0.5688\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0420 - val_loss: 0.5711\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.0395 - val_loss: 0.5709\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 170us/step - loss: 0.0372 - val_loss: 0.5673\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 0.0350 - val_loss: 0.5654\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0329 - val_loss: 0.5657\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 148us/step - loss: 0.0311 - val_loss: 0.5671\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0294 - val_loss: 0.5693\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 173us/step - loss: 0.0279 - val_loss: 0.5674\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0264 - val_loss: 0.5674\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 0.0250 - val_loss: 0.5676\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0238 - val_loss: 0.5683\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.0227 - val_loss: 0.5687\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 170us/step - loss: 0.0216 - val_loss: 0.5696\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.0206 - val_loss: 0.5695\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0196 - val_loss: 0.5704\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 166us/step - loss: 0.0187 - val_loss: 0.5717\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0180 - val_loss: 0.5713\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 0.0172 - val_loss: 0.5727\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0165 - val_loss: 0.5743\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 144us/step - loss: 0.0158 - val_loss: 0.5754\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0152 - val_loss: 0.5746\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0145 - val_loss: 0.5750\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 0.0140 - val_loss: 0.5758\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0135 - val_loss: 0.5779\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0130 - val_loss: 0.5780\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.0125 - val_loss: 0.5776\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0121 - val_loss: 0.5784\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.0117 - val_loss: 0.5795\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0113 - val_loss: 0.5798\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 0.0109 - val_loss: 0.5804\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.0106 - val_loss: 0.5816\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 166us/step - loss: 0.0102 - val_loss: 0.5820\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0099 - val_loss: 0.5827\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.0096 - val_loss: 0.5836\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0093 - val_loss: 0.5839\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0090 - val_loss: 0.5851\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.0088 - val_loss: 0.5857\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0085 - val_loss: 0.5863\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0082 - val_loss: 0.5871\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0080 - val_loss: 0.5879\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0078 - val_loss: 0.5889\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 0.0076 - val_loss: 0.5894\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.0074 - val_loss: 0.5906\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 0.0072 - val_loss: 0.5914\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0070 - val_loss: 0.5910\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0068 - val_loss: 0.5922\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0066 - val_loss: 0.5935\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0065 - val_loss: 0.5938\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 168us/step - loss: 0.0063 - val_loss: 0.5943\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.0062 - val_loss: 0.5948\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0060 - val_loss: 0.5956\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.0059 - val_loss: 0.5962\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0057 - val_loss: 0.5970\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0056 - val_loss: 0.5986\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 178us/step - loss: 0.0055 - val_loss: 0.5987\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0054 - val_loss: 0.5988\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0052 - val_loss: 0.5996\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0051 - val_loss: 0.6003\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0050 - val_loss: 0.6012\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0049 - val_loss: 0.6024\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 0.0048 - val_loss: 0.6029\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0047 - val_loss: 0.6031\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 180us/step - loss: 0.0046 - val_loss: 0.6032\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0045 - val_loss: 0.6044\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.0044 - val_loss: 0.6050\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.0043 - val_loss: 0.6059\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0042 - val_loss: 0.6063\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.0042 - val_loss: 0.6070\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0041 - val_loss: 0.6076\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.0040 - val_loss: 0.6082\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 0.0039 - val_loss: 0.6085\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 173us/step - loss: 0.0039 - val_loss: 0.6091\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0038 - val_loss: 0.6098\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 143us/step - loss: 0.0037 - val_loss: 0.6107\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 0.0036 - val_loss: 0.6112\n",
      "Epoch 130/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 161us/step - loss: 0.0036 - val_loss: 0.6117\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 171us/step - loss: 0.0035 - val_loss: 0.6126\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.6136\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.6139\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0033 - val_loss: 0.6144\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.0033 - val_loss: 0.6153\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0032 - val_loss: 0.6158\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 168us/step - loss: 0.0032 - val_loss: 0.6160\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0031 - val_loss: 0.6167\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 176us/step - loss: 0.0031 - val_loss: 0.6175\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.0030 - val_loss: 0.6181\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 166us/step - loss: 0.0030 - val_loss: 0.6188\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0029 - val_loss: 0.6194\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0029 - val_loss: 0.6200\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.0028 - val_loss: 0.6205\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0028 - val_loss: 0.6213\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0027 - val_loss: 0.6218\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0027 - val_loss: 0.6226\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 147us/step - loss: 0.0027 - val_loss: 0.6233\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.0026 - val_loss: 0.6234\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0026 - val_loss: 0.6237\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 167us/step - loss: 0.0025 - val_loss: 0.6246\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 0.6252\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0025 - val_loss: 0.6257\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 163us/step - loss: 0.0024 - val_loss: 0.6263\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0024 - val_loss: 0.6273\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0024 - val_loss: 0.6275\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.6277\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.0023 - val_loss: 0.6286\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.0023 - val_loss: 0.6293\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0022 - val_loss: 0.6296\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 0.6301\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0022 - val_loss: 0.6306\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0021 - val_loss: 0.6312\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 0.0021 - val_loss: 0.6319\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0021 - val_loss: 0.6321\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0021 - val_loss: 0.6326\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 162us/step - loss: 0.0020 - val_loss: 0.6332\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0020 - val_loss: 0.6337\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.0020 - val_loss: 0.6345\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 157us/step - loss: 0.0020 - val_loss: 0.6351\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 150us/step - loss: 0.0019 - val_loss: 0.6357\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0019 - val_loss: 0.6364\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0019 - val_loss: 0.6366\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 145us/step - loss: 0.0019 - val_loss: 0.6368\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0018 - val_loss: 0.6372\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0018 - val_loss: 0.6378\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 159us/step - loss: 0.0018 - val_loss: 0.6381\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 166us/step - loss: 0.0018 - val_loss: 0.6387\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.0018 - val_loss: 0.6395\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 164us/step - loss: 0.0017 - val_loss: 0.6400\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 169us/step - loss: 0.0017 - val_loss: 0.6405\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 153us/step - loss: 0.0017 - val_loss: 0.6410\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 161us/step - loss: 0.0017 - val_loss: 0.6413\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.6417\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 142us/step - loss: 0.0016 - val_loss: 0.6423\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 156us/step - loss: 0.0016 - val_loss: 0.6429\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 158us/step - loss: 0.0016 - val_loss: 0.6432\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 166us/step - loss: 0.0016 - val_loss: 0.6436\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 160us/step - loss: 0.0016 - val_loss: 0.6443\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 173us/step - loss: 0.0015 - val_loss: 0.6447\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0015 - val_loss: 0.6450\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0015 - val_loss: 0.6458\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0015 - val_loss: 0.6462\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 165us/step - loss: 0.0015 - val_loss: 0.6464\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 151us/step - loss: 0.0015 - val_loss: 0.6469\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 149us/step - loss: 0.0014 - val_loss: 0.6475\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 168us/step - loss: 0.0014 - val_loss: 0.6479\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 154us/step - loss: 0.0014 - val_loss: 0.6484\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 146us/step - loss: 0.0014 - val_loss: 0.6489\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 152us/step - loss: 0.0014 - val_loss: 0.6494\n",
      "(-0.5, 30)     relu C\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 6.7067 - val_loss: 5.8967\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 5.7843 - val_loss: 5.0308\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 4.7161 - val_loss: 3.9634\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 3.4675 - val_loss: 2.9527\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 2.4875 - val_loss: 2.2755\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 1.9119 - val_loss: 1.8167\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 274us/step - loss: 1.4207 - val_loss: 1.4798\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 1.1057 - val_loss: 1.2753\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.8671 - val_loss: 1.0997\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.6939 - val_loss: 0.9932\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.5545 - val_loss: 0.9009\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.4635 - val_loss: 0.8418\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.3822 - val_loss: 0.7813\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.3222 - val_loss: 0.7547\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.2648 - val_loss: 0.7265\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 0.2246 - val_loss: 0.6977\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.1893 - val_loss: 0.6649\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.1594 - val_loss: 0.6518\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.1365 - val_loss: 0.6433\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.1186 - val_loss: 0.6258\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.1022 - val_loss: 0.6179\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 0.0878 - val_loss: 0.6150\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0768 - val_loss: 0.6026\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 0.0669 - val_loss: 0.6038\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0594 - val_loss: 0.5931\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0524 - val_loss: 0.5834\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0471 - val_loss: 0.5830\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0420 - val_loss: 0.5803\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 0.0380 - val_loss: 0.5742\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0345 - val_loss: 0.5718\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.0316 - val_loss: 0.5702\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0284 - val_loss: 0.5672\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0262 - val_loss: 0.5699\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0241 - val_loss: 0.5643\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0222 - val_loss: 0.5625\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0210 - val_loss: 0.5604\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0191 - val_loss: 0.5675\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0180 - val_loss: 0.5625\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0165 - val_loss: 0.5575\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0154 - val_loss: 0.5597\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0145 - val_loss: 0.5572\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0138 - val_loss: 0.5582\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0129 - val_loss: 0.5632\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0122 - val_loss: 0.5607\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0115 - val_loss: 0.5577\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0111 - val_loss: 0.5657\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0103 - val_loss: 0.5594\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0099 - val_loss: 0.5586\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0093 - val_loss: 0.5614\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 0.0089 - val_loss: 0.5655\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0085 - val_loss: 0.5634\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0081 - val_loss: 0.5638\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0078 - val_loss: 0.5650\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0075 - val_loss: 0.5643\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 0.0071 - val_loss: 0.5659\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0069 - val_loss: 0.5665\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0066 - val_loss: 0.5645\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0063 - val_loss: 0.5661\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 0.0061 - val_loss: 0.5686\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 0.0059 - val_loss: 0.5687\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0056 - val_loss: 0.5698\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0054 - val_loss: 0.5711\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0052 - val_loss: 0.5704\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0050 - val_loss: 0.5704\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0049 - val_loss: 0.5721\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0047 - val_loss: 0.5716\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0046 - val_loss: 0.5700\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0044 - val_loss: 0.5718\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0043 - val_loss: 0.5731\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0041 - val_loss: 0.5754\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0040 - val_loss: 0.5760\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0039 - val_loss: 0.5762\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0038 - val_loss: 0.5750\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0037 - val_loss: 0.5751\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0035 - val_loss: 0.5798\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0034 - val_loss: 0.5811\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0033 - val_loss: 0.5806\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0032 - val_loss: 0.5765\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0032 - val_loss: 0.5776\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0031 - val_loss: 0.5793\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0030 - val_loss: 0.5821\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0029 - val_loss: 0.5823\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0028 - val_loss: 0.5821\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0028 - val_loss: 0.5818\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0027 - val_loss: 0.5843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 0.0026 - val_loss: 0.5847\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0025 - val_loss: 0.5854\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 0.0025 - val_loss: 0.5859\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0024 - val_loss: 0.5858\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 0.0024 - val_loss: 0.5858\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0023 - val_loss: 0.5876\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0023 - val_loss: 0.5893\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0022 - val_loss: 0.5909\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0021 - val_loss: 0.5898\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0021 - val_loss: 0.5898\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0021 - val_loss: 0.5911\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0020 - val_loss: 0.5912\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0020 - val_loss: 0.5927\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0019 - val_loss: 0.5927\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.0019 - val_loss: 0.5941\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0018 - val_loss: 0.5937\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0018 - val_loss: 0.5940\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 0.0018 - val_loss: 0.5954\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0017 - val_loss: 0.5955\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.0017 - val_loss: 0.5972\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0017 - val_loss: 0.5972\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0016 - val_loss: 0.5982\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0016 - val_loss: 0.5988\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0016 - val_loss: 0.5991\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0015 - val_loss: 0.6003\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0015 - val_loss: 0.6006\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0015 - val_loss: 0.6014\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 0.0014 - val_loss: 0.6015\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0014 - val_loss: 0.6042\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 0.0014 - val_loss: 0.6039\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 0.0014 - val_loss: 0.6037\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0013 - val_loss: 0.6037\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0013 - val_loss: 0.6068\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.0013 - val_loss: 0.6070\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0013 - val_loss: 0.6055\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0012 - val_loss: 0.6071\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0012 - val_loss: 0.6091\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0012 - val_loss: 0.6093\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.0012 - val_loss: 0.6095\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0012 - val_loss: 0.6096\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0011 - val_loss: 0.6104\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.0011 - val_loss: 0.6113\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0011 - val_loss: 0.6107\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0011 - val_loss: 0.6105\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0011 - val_loss: 0.6128\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0010 - val_loss: 0.6135\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0010 - val_loss: 0.6131\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0010 - val_loss: 0.6139\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 9.9027e-04 - val_loss: 0.6158\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 9.7314e-04 - val_loss: 0.6155\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 9.5802e-04 - val_loss: 0.6161\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 9.4460e-04 - val_loss: 0.6163\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 9.2680e-04 - val_loss: 0.6168\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 9.1348e-04 - val_loss: 0.6184\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 8.9738e-04 - val_loss: 0.6178\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 8.8503e-04 - val_loss: 0.6191\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 8.6823e-04 - val_loss: 0.6210\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 8.5609e-04 - val_loss: 0.6206\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 8.4298e-04 - val_loss: 0.6216\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 8.2858e-04 - val_loss: 0.6225\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 8.1598e-04 - val_loss: 0.6237\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 8.0555e-04 - val_loss: 0.6238\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 7.9264e-04 - val_loss: 0.6238\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 7.8165e-04 - val_loss: 0.6235\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 7.6885e-04 - val_loss: 0.6245\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 7.5813e-04 - val_loss: 0.6253\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 7.4662e-04 - val_loss: 0.6257\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 7.3578e-04 - val_loss: 0.6272\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 7.2509e-04 - val_loss: 0.6274\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 7.1478e-04 - val_loss: 0.6287\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 7.0389e-04 - val_loss: 0.6290\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 6.9465e-04 - val_loss: 0.6293\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 6.8440e-04 - val_loss: 0.6299\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 6.7537e-04 - val_loss: 0.6306\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 6.6594e-04 - val_loss: 0.6317\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 6.5596e-04 - val_loss: 0.6318\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 6.4745e-04 - val_loss: 0.6320\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 283us/step - loss: 6.3914e-04 - val_loss: 0.6322\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 6.2935e-04 - val_loss: 0.6329\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 6.2152e-04 - val_loss: 0.6326\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 6.1201e-04 - val_loss: 0.6338\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 6.0410e-04 - val_loss: 0.6341\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 5.9593e-04 - val_loss: 0.6345\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 5.9052e-04 - val_loss: 0.6368\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 5.8019e-04 - val_loss: 0.6366\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 5.7193e-04 - val_loss: 0.6366\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 5.6476e-04 - val_loss: 0.6364\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 5.5730e-04 - val_loss: 0.6366\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 5.5005e-04 - val_loss: 0.6375\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 5.4217e-04 - val_loss: 0.6371\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 5.3533e-04 - val_loss: 0.6381\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 5.2863e-04 - val_loss: 0.6400\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 5.2102e-04 - val_loss: 0.6401\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 5.1448e-04 - val_loss: 0.6405\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 5.0800e-04 - val_loss: 0.6412\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 5.0140e-04 - val_loss: 0.6405\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 4.9540e-04 - val_loss: 0.6407\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 4.8862e-04 - val_loss: 0.6413\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 4.8313e-04 - val_loss: 0.6429\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 4.7717e-04 - val_loss: 0.6440\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 4.7084e-04 - val_loss: 0.6445\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 4.6519e-04 - val_loss: 0.6455\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 4.6054e-04 - val_loss: 0.6458\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 4.5371e-04 - val_loss: 0.6477\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 4.4817e-04 - val_loss: 0.6474\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 4.4318e-04 - val_loss: 0.6471\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 4.3770e-04 - val_loss: 0.6480\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 4.3230e-04 - val_loss: 0.6482\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 4.2705e-04 - val_loss: 0.6495\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 4.2182e-04 - val_loss: 0.6502\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 4.1711e-04 - val_loss: 0.6501\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 4.1224e-04 - val_loss: 0.6502\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 4.0762e-04 - val_loss: 0.6513\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 4.0261e-04 - val_loss: 0.6516\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 3.9781e-04 - val_loss: 0.6522\n",
      "(-0.5, 30)     tanh A\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 2.2021 - val_loss: 2.0591\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 1.8945 - val_loss: 1.8135\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 1.6206 - val_loss: 1.5825\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 1.3848 - val_loss: 1.3807\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 1.1754 - val_loss: 1.2333\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 349us/step - loss: 0.9950 - val_loss: 1.1120\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 0.8496 - val_loss: 1.0102\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.7199 - val_loss: 0.9465\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.6143 - val_loss: 0.8849\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 0.5294 - val_loss: 0.8338\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 0.4592 - val_loss: 0.8022\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.3931 - val_loss: 0.7665\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.3447 - val_loss: 0.7476\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.3030 - val_loss: 0.7304\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.2666 - val_loss: 0.6999\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.2301 - val_loss: 0.6986\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.2070 - val_loss: 0.6848\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.1840 - val_loss: 0.6764\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.1625 - val_loss: 0.6677\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.1466 - val_loss: 0.6581\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.1338 - val_loss: 0.6644\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.1218 - val_loss: 0.6636\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 0.1098 - val_loss: 0.6594\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 0.1002 - val_loss: 0.6525\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.0922 - val_loss: 0.6617\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 0.0844 - val_loss: 0.6575\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 0.0782 - val_loss: 0.6613\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.0720 - val_loss: 0.6597\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.075 - 0s 321us/step - loss: 0.0673 - val_loss: 0.6555\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0623 - val_loss: 0.6598\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0582 - val_loss: 0.6620\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0546 - val_loss: 0.6628\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0511 - val_loss: 0.6621\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 0.0482 - val_loss: 0.6650\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.0455 - val_loss: 0.6619\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 366us/step - loss: 0.0428 - val_loss: 0.6676\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 423us/step - loss: 0.0405 - val_loss: 0.6710\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 481us/step - loss: 0.0385 - val_loss: 0.6706\n",
      "Epoch 39/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 813us/step - loss: 0.0364 - val_loss: 0.6736\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 494us/step - loss: 0.0345 - val_loss: 0.6738\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 398us/step - loss: 0.0330 - val_loss: 0.6751\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 389us/step - loss: 0.0314 - val_loss: 0.6719\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 0.0300 - val_loss: 0.6750\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 0.0287 - val_loss: 0.6778\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 358us/step - loss: 0.0276 - val_loss: 0.6835\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 598us/step - loss: 0.0265 - val_loss: 0.6820\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 407us/step - loss: 0.0255 - val_loss: 0.6784\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.0245 - val_loss: 0.6856\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 745us/step - loss: 0.0235 - val_loss: 0.6868\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 481us/step - loss: 0.0227 - val_loss: 0.6870\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 515us/step - loss: 0.0218 - val_loss: 0.6870\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 677us/step - loss: 0.0211 - val_loss: 0.6892\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 0.0204 - val_loss: 0.6896\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 427us/step - loss: 0.0197 - val_loss: 0.6897\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0191 - val_loss: 0.6958\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 465us/step - loss: 0.0185 - val_loss: 0.6928\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 382us/step - loss: 0.0179 - val_loss: 0.6969\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 363us/step - loss: 0.0174 - val_loss: 0.6997\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.0168 - val_loss: 0.6992\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 0.0163 - val_loss: 0.6965\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 425us/step - loss: 0.0159 - val_loss: 0.7034\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0154 - val_loss: 0.7029\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 399us/step - loss: 0.0149 - val_loss: 0.7022\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 452us/step - loss: 0.0145 - val_loss: 0.7009\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 0.0142 - val_loss: 0.7059\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 378us/step - loss: 0.0138 - val_loss: 0.7078\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 471us/step - loss: 0.0134 - val_loss: 0.7065\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0131 - val_loss: 0.7082\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 357us/step - loss: 0.0128 - val_loss: 0.7113\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 382us/step - loss: 0.0124 - val_loss: 0.7108\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 381us/step - loss: 0.0121 - val_loss: 0.7138\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 0.0118 - val_loss: 0.7145\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0115 - val_loss: 0.7136\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 0.0113 - val_loss: 0.7132\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.0110 - val_loss: 0.7155\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 0.0107 - val_loss: 0.7172\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 406us/step - loss: 0.0105 - val_loss: 0.7189\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 0.0103 - val_loss: 0.7178\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 0.0100 - val_loss: 0.7182\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 406us/step - loss: 0.0098 - val_loss: 0.7207\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 414us/step - loss: 0.0096 - val_loss: 0.7212\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 362us/step - loss: 0.0094 - val_loss: 0.7208\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 370us/step - loss: 0.0092 - val_loss: 0.7214\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 358us/step - loss: 0.0090 - val_loss: 0.7244\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 362us/step - loss: 0.0088 - val_loss: 0.7264\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 356us/step - loss: 0.0086 - val_loss: 0.7263\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 994us/step - loss: 0.0085 - val_loss: 0.7273\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 0.0083 - val_loss: 0.7290\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 0.0081 - val_loss: 0.7295\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 805us/step - loss: 0.0080 - val_loss: 0.7296\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 836us/step - loss: 0.0078 - val_loss: 0.7293\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 710us/step - loss: 0.0077 - val_loss: 0.7326\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 905us/step - loss: 0.0075 - val_loss: 0.7332\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 792us/step - loss: 0.0074 - val_loss: 0.7327\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.7335\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.7331\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 962us/step - loss: 0.0070 - val_loss: 0.7370\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.7381\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.7399\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.7402\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 821us/step - loss: 0.0065 - val_loss: 0.7394\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.7395\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.7405\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 755us/step - loss: 0.0062 - val_loss: 0.7417\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 608us/step - loss: 0.0061 - val_loss: 0.7432\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.006 - 0s 622us/step - loss: 0.0060 - val_loss: 0.7434\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.7427\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 595us/step - loss: 0.0058 - val_loss: 0.7431\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.7439\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 736us/step - loss: 0.0056 - val_loss: 0.7466\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 651us/step - loss: 0.0055 - val_loss: 0.7472\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 673us/step - loss: 0.0054 - val_loss: 0.7473\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 642us/step - loss: 0.0054 - val_loss: 0.7497\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 622us/step - loss: 0.0053 - val_loss: 0.7510\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 607us/step - loss: 0.0052 - val_loss: 0.7514\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 619us/step - loss: 0.0051 - val_loss: 0.7532\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 624us/step - loss: 0.0050 - val_loss: 0.7543\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 859us/step - loss: 0.0050 - val_loss: 0.7539\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 0.0049 - val_loss: 0.7554\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 680us/step - loss: 0.0048 - val_loss: 0.7543\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 600us/step - loss: 0.0048 - val_loss: 0.7549\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 610us/step - loss: 0.0047 - val_loss: 0.7575\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 599us/step - loss: 0.0046 - val_loss: 0.7587\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 595us/step - loss: 0.0045 - val_loss: 0.7598\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 583us/step - loss: 0.0045 - val_loss: 0.7600\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 0.0044 - val_loss: 0.7609\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 761us/step - loss: 0.0044 - val_loss: 0.7622\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.004 - 0s 882us/step - loss: 0.0043 - val_loss: 0.7621\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 955us/step - loss: 0.0042 - val_loss: 0.7627\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 821us/step - loss: 0.0042 - val_loss: 0.7638\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 864us/step - loss: 0.0041 - val_loss: 0.7659\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 808us/step - loss: 0.0041 - val_loss: 0.7661\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 844us/step - loss: 0.0040 - val_loss: 0.7673\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 815us/step - loss: 0.0040 - val_loss: 0.7679\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 854us/step - loss: 0.0039 - val_loss: 0.7691\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 923us/step - loss: 0.0039 - val_loss: 0.7696\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 795us/step - loss: 0.0038 - val_loss: 0.7699\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 865us/step - loss: 0.0038 - val_loss: 0.7706\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 981us/step - loss: 0.0037 - val_loss: 0.7710\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 799us/step - loss: 0.0037 - val_loss: 0.7715\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 807us/step - loss: 0.0036 - val_loss: 0.7719\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 749us/step - loss: 0.0036 - val_loss: 0.7737\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 854us/step - loss: 0.0035 - val_loss: 0.7735\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 940us/step - loss: 0.0035 - val_loss: 0.7746\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 0.0034 - val_loss: 0.7748\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 771us/step - loss: 0.0034 - val_loss: 0.7757\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 833us/step - loss: 0.0034 - val_loss: 0.7765\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 849us/step - loss: 0.0033 - val_loss: 0.7774\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 868us/step - loss: 0.0033 - val_loss: 0.7783\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 818us/step - loss: 0.0032 - val_loss: 0.7790\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 848us/step - loss: 0.0032 - val_loss: 0.7799\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 778us/step - loss: 0.0032 - val_loss: 0.7805\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 851us/step - loss: 0.0031 - val_loss: 0.7817\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 869us/step - loss: 0.0031 - val_loss: 0.7831\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 788us/step - loss: 0.0030 - val_loss: 0.7845\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 797us/step - loss: 0.0030 - val_loss: 0.7839\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 856us/step - loss: 0.0030 - val_loss: 0.7834\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 794us/step - loss: 0.0029 - val_loss: 0.7844\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 812us/step - loss: 0.0029 - val_loss: 0.7856\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.7880\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 834us/step - loss: 0.0028 - val_loss: 0.7887\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 891us/step - loss: 0.0028 - val_loss: 0.7886\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 877us/step - loss: 0.0028 - val_loss: 0.7894\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 844us/step - loss: 0.0028 - val_loss: 0.7906\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 858us/step - loss: 0.0027 - val_loss: 0.7909\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 947us/step - loss: 0.0027 - val_loss: 0.7905\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 740us/step - loss: 0.0027 - val_loss: 0.7917\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 0.0026 - val_loss: 0.7923\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 0.0026 - val_loss: 0.7926\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 680us/step - loss: 0.0026 - val_loss: 0.7928\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 733us/step - loss: 0.0025 - val_loss: 0.7936\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 698us/step - loss: 0.0025 - val_loss: 0.7952\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 672us/step - loss: 0.0025 - val_loss: 0.7954\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 694us/step - loss: 0.0025 - val_loss: 0.7966\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 712us/step - loss: 0.0024 - val_loss: 0.7979\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 718us/step - loss: 0.0024 - val_loss: 0.7976\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 685us/step - loss: 0.0024 - val_loss: 0.7982\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 574us/step - loss: 0.0024 - val_loss: 0.7992\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 601us/step - loss: 0.0023 - val_loss: 0.7991\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 640us/step - loss: 0.0023 - val_loss: 0.8000\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 676us/step - loss: 0.0023 - val_loss: 0.8021\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 628us/step - loss: 0.0023 - val_loss: 0.8018\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 604us/step - loss: 0.0022 - val_loss: 0.8025\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 596us/step - loss: 0.0022 - val_loss: 0.8022\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 645us/step - loss: 0.0022 - val_loss: 0.8028\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 679us/step - loss: 0.0022 - val_loss: 0.8031\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 624us/step - loss: 0.0022 - val_loss: 0.8047\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 593us/step - loss: 0.0021 - val_loss: 0.8051\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 570us/step - loss: 0.0021 - val_loss: 0.8053\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 635us/step - loss: 0.0021 - val_loss: 0.8056\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 610us/step - loss: 0.0021 - val_loss: 0.8070\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 601us/step - loss: 0.0021 - val_loss: 0.8075\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 595us/step - loss: 0.0020 - val_loss: 0.8086\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 660us/step - loss: 0.0020 - val_loss: 0.8099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 781us/step - loss: 0.0020 - val_loss: 0.8097\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 738us/step - loss: 0.0020 - val_loss: 0.8100\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 767us/step - loss: 0.0020 - val_loss: 0.8111\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 752us/step - loss: 0.0019 - val_loss: 0.8114\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 731us/step - loss: 0.0019 - val_loss: 0.8124\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 869us/step - loss: 0.0019 - val_loss: 0.8131\n",
      "(-0.5, 30)     tanh B\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 10.3928 - val_loss: 10.6504\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 10.0466 - val_loss: 10.3014\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 9.6907 - val_loss: 9.9791\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 358us/step - loss: 9.3740 - val_loss: 9.6765\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 9.0908 - val_loss: 9.4048\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 8.8382 - val_loss: 9.1764\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 8.6351 - val_loss: 8.9788\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 363us/step - loss: 8.4513 - val_loss: 8.8060\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 8.2872 - val_loss: 8.6494\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 8.1386 - val_loss: 8.5046\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 8.0028 - val_loss: 8.3629\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 7.8729 - val_loss: 8.2222\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 7.7438 - val_loss: 8.0902\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 7.6266 - val_loss: 7.9673\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 7.5128 - val_loss: 7.8499\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 7.4074 - val_loss: 7.7290\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 7.3013 - val_loss: 7.6130\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 7.1970 - val_loss: 7.5033\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 7.0975 - val_loss: 7.3977\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 7.0033 - val_loss: 7.2937\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 6.9006 - val_loss: 7.1823\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 6.7948 - val_loss: 7.0514\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 6.6625 - val_loss: 6.9167\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 6.5280 - val_loss: 6.7883\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 6.3995 - val_loss: 6.6660\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 6.2822 - val_loss: 6.5389\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 6.1538 - val_loss: 6.4104\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 343us/step - loss: 6.0276 - val_loss: 6.2914\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 5.9069 - val_loss: 6.1743\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 5.7910 - val_loss: 6.0553\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 5.6762 - val_loss: 5.9358\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 5.5624 - val_loss: 5.8132\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 5.4334 - val_loss: 5.6916\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 5.3111 - val_loss: 5.5562\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 5.1665 - val_loss: 5.4105\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 355us/step - loss: 5.0090 - val_loss: 5.2667\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 4.8547 - val_loss: 5.1284\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 356us/step - loss: 4.7100 - val_loss: 4.9948\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 4.5715 - val_loss: 4.8718\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 4.4406 - val_loss: 4.7509\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 4.3106 - val_loss: 4.6288\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 4.1812 - val_loss: 4.5056\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 4.0545 - val_loss: 4.3832\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 389us/step - loss: 3.9209 - val_loss: 4.2507\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 3.7884 - val_loss: 4.1242\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 355us/step - loss: 3.6558 - val_loss: 4.0067\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 3.5282 - val_loss: 3.8892\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 3.4082 - val_loss: 3.7703\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 263us/step - loss: 3.2756 - val_loss: 3.6500\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 3.1586 - val_loss: 3.5380\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 3.0390 - val_loss: 3.4320\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 2.9258 - val_loss: 3.3223\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 2.8165 - val_loss: 3.2165\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 2.7059 - val_loss: 3.1136\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 2.6031 - val_loss: 3.0172\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 364us/step - loss: 2.5035 - val_loss: 2.9254\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 2.4016 - val_loss: 2.8388\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 2.3173 - val_loss: 2.7589\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 2.2322 - val_loss: 2.6881\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 2.1500 - val_loss: 2.6159\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 395us/step - loss: 2.0705 - val_loss: 2.5455\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 1.9996 - val_loss: 2.4838\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 1.9351 - val_loss: 2.4264\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 1.8669 - val_loss: 2.3660\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 1.8049 - val_loss: 2.3102\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 1.7459 - val_loss: 2.2590\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 374us/step - loss: 1.6908 - val_loss: 2.2102\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 1.6355 - val_loss: 2.1611\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 1.5801 - val_loss: 2.1134\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 1.5308 - val_loss: 2.0672\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 1.4784 - val_loss: 2.0232\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 1.4238 - val_loss: 1.9807\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 287us/step - loss: 1.3649 - val_loss: 1.9378\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 274us/step - loss: 1.3168 - val_loss: 1.8921\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 1.2651 - val_loss: 1.8446\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 356us/step - loss: 1.2209 - val_loss: 1.8047\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 1.1725 - val_loss: 1.7660\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 1.1216 - val_loss: 1.7241\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 1.0684 - val_loss: 1.6772\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 1.0138 - val_loss: 1.6355\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.9733 - val_loss: 1.5969\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.9373 - val_loss: 1.5602\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.9022 - val_loss: 1.5260\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.8682 - val_loss: 1.4949\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.8370 - val_loss: 1.4638\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 389us/step - loss: 0.8073 - val_loss: 1.4353\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.7788 - val_loss: 1.4078\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 0.7516 - val_loss: 1.3831\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.7278 - val_loss: 1.3582\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.7036 - val_loss: 1.3363\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.6796 - val_loss: 1.3169\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.6556 - val_loss: 1.2936\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.6347 - val_loss: 1.2694\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.6108 - val_loss: 1.2442\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.5885 - val_loss: 1.2190\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.5612 - val_loss: 1.1909\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 254us/step - loss: 0.5250 - val_loss: 1.1569\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.4916 - val_loss: 1.1254\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.4657 - val_loss: 1.0971\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.4438 - val_loss: 1.0710\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.4252 - val_loss: 1.0502\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 0.4066 - val_loss: 1.0349\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.383 - 0s 294us/step - loss: 0.3898 - val_loss: 1.0218\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.3725 - val_loss: 1.0089\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.3554 - val_loss: 0.9928\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.3393 - val_loss: 0.9756\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 0.3238 - val_loss: 0.9591\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.3090 - val_loss: 0.9442\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.2935 - val_loss: 0.9303\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.2797 - val_loss: 0.9167\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.2664 - val_loss: 0.9044\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 0.2536 - val_loss: 0.8900\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 0.2403 - val_loss: 0.8760\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.2278 - val_loss: 0.8612\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 0.2162 - val_loss: 0.8472\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 0.2041 - val_loss: 0.8361\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 0.1941 - val_loss: 0.8271\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 0.1838 - val_loss: 0.8181\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.1744 - val_loss: 0.8064\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.1650 - val_loss: 0.7965\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 368us/step - loss: 0.1566 - val_loss: 0.7871\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.1486 - val_loss: 0.7793\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 0.1417 - val_loss: 0.7701\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 0.1343 - val_loss: 0.7622\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 357us/step - loss: 0.1286 - val_loss: 0.7543\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.1219 - val_loss: 0.7480\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 0.1168 - val_loss: 0.7420\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 527us/step - loss: 0.1115 - val_loss: 0.7365\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 501us/step - loss: 0.1067 - val_loss: 0.7306\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.1025 - val_loss: 0.7250\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 0.0984 - val_loss: 0.7199\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0945 - val_loss: 0.7154\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 0.0911 - val_loss: 0.7107\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.0880 - val_loss: 0.7066\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 357us/step - loss: 0.0850 - val_loss: 0.7025\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 353us/step - loss: 0.0821 - val_loss: 0.6991\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 0.0796 - val_loss: 0.6948\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.0772 - val_loss: 0.6916\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 374us/step - loss: 0.0751 - val_loss: 0.6892\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 369us/step - loss: 0.0729 - val_loss: 0.6864\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 353us/step - loss: 0.0710 - val_loss: 0.6835\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 367us/step - loss: 0.0690 - val_loss: 0.6805\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 524us/step - loss: 0.0673 - val_loss: 0.6778\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 364us/step - loss: 0.0656 - val_loss: 0.6750\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 0.0641 - val_loss: 0.6723\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 354us/step - loss: 0.0625 - val_loss: 0.6702\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 383us/step - loss: 0.0612 - val_loss: 0.6685\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 0.0598 - val_loss: 0.6667\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.0586 - val_loss: 0.6643\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 343us/step - loss: 0.0574 - val_loss: 0.6628\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 347us/step - loss: 0.0562 - val_loss: 0.6610\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 0.0551 - val_loss: 0.6592\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 0.0541 - val_loss: 0.6577\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 0.0530 - val_loss: 0.6561\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 352us/step - loss: 0.0521 - val_loss: 0.6544\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.0512 - val_loss: 0.6526\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.0503 - val_loss: 0.6516\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.0494 - val_loss: 0.6502\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 355us/step - loss: 0.0486 - val_loss: 0.6484\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 0.0478 - val_loss: 0.6469\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 343us/step - loss: 0.0470 - val_loss: 0.6459\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 0.0463 - val_loss: 0.6447\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 381us/step - loss: 0.0456 - val_loss: 0.6434\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 0.0449 - val_loss: 0.6423\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 373us/step - loss: 0.0442 - val_loss: 0.6412\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 361us/step - loss: 0.0436 - val_loss: 0.6400\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 374us/step - loss: 0.0429 - val_loss: 0.6391\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.0423 - val_loss: 0.6380\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.0417 - val_loss: 0.6367\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 353us/step - loss: 0.0411 - val_loss: 0.6359\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.0406 - val_loss: 0.6348\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 377us/step - loss: 0.0400 - val_loss: 0.6341\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 0.0395 - val_loss: 0.6333\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 386us/step - loss: 0.0390 - val_loss: 0.6320\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 0.0385 - val_loss: 0.6307\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 0.0380 - val_loss: 0.6300\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0376 - val_loss: 0.6293\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 381us/step - loss: 0.0371 - val_loss: 0.6285\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.0366 - val_loss: 0.6273\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.0362 - val_loss: 0.6264\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 343us/step - loss: 0.0358 - val_loss: 0.6258\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.0354 - val_loss: 0.6251\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0349 - val_loss: 0.6242\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.033 - 0s 327us/step - loss: 0.0346 - val_loss: 0.6237\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.0342 - val_loss: 0.6230\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 357us/step - loss: 0.0338 - val_loss: 0.6217\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 367us/step - loss: 0.0334 - val_loss: 0.6210\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 0.0330 - val_loss: 0.6205\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.0327 - val_loss: 0.6199\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 0.0323 - val_loss: 0.6197\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 369us/step - loss: 0.0320 - val_loss: 0.6187\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.0317 - val_loss: 0.6179\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 0.0313 - val_loss: 0.6174\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 0.0310 - val_loss: 0.6165\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 366us/step - loss: 0.0307 - val_loss: 0.6164\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 0.0304 - val_loss: 0.6159\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 404us/step - loss: 0.0301 - val_loss: 0.6154\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.0298 - val_loss: 0.6149\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 390us/step - loss: 0.0295 - val_loss: 0.6143\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 0.0292 - val_loss: 0.6141\n",
      "(-0.5, 30)     tanh C\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 7.1284 - val_loss: 6.1427\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 604us/step - loss: 5.1532 - val_loss: 4.5146\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 606us/step - loss: 3.9313 - val_loss: 3.6758\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 591us/step - loss: 3.0418 - val_loss: 2.9443\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 583us/step - loss: 2.3884 - val_loss: 2.4376\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 591us/step - loss: 1.8407 - val_loss: 2.0105\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 580us/step - loss: 1.4465 - val_loss: 1.6999\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 564us/step - loss: 1.1182 - val_loss: 1.4566\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 584us/step - loss: 0.8707 - val_loss: 1.2543\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 579us/step - loss: 0.6952 - val_loss: 1.1100\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 611us/step - loss: 0.5658 - val_loss: 0.9958\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 612us/step - loss: 0.4732 - val_loss: 0.9046\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 642us/step - loss: 0.4023 - val_loss: 0.8472\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 570us/step - loss: 0.3339 - val_loss: 0.7923\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 587us/step - loss: 0.2955 - val_loss: 0.7582\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 637us/step - loss: 0.2631 - val_loss: 0.7220\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 612us/step - loss: 0.2274 - val_loss: 0.6814\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 592us/step - loss: 0.2018 - val_loss: 0.6784\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 593us/step - loss: 0.1654 - val_loss: 0.6339\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 596us/step - loss: 0.1513 - val_loss: 0.6121\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 580us/step - loss: 0.1339 - val_loss: 0.6264\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 589us/step - loss: 0.1197 - val_loss: 0.5964\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 566us/step - loss: 0.1064 - val_loss: 0.5758\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 586us/step - loss: 0.0942 - val_loss: 0.5700\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 582us/step - loss: 0.0867 - val_loss: 0.5625\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 592us/step - loss: 0.0786 - val_loss: 0.5599\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 770us/step - loss: 0.0712 - val_loss: 0.5507\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 785us/step - loss: 0.0655 - val_loss: 0.5499\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 0.0603 - val_loss: 0.5459\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 729us/step - loss: 0.0554 - val_loss: 0.5399\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 786us/step - loss: 0.0516 - val_loss: 0.5393\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 758us/step - loss: 0.0485 - val_loss: 0.5337\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 798us/step - loss: 0.0439 - val_loss: 0.5349\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 765us/step - loss: 0.0410 - val_loss: 0.5348\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 698us/step - loss: 0.0385 - val_loss: 0.5267\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 699us/step - loss: 0.0356 - val_loss: 0.5242\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 745us/step - loss: 0.0332 - val_loss: 0.5268\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 790us/step - loss: 0.0311 - val_loss: 0.5263\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 761us/step - loss: 0.0293 - val_loss: 0.5234\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 776us/step - loss: 0.0274 - val_loss: 0.5257\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 820us/step - loss: 0.0259 - val_loss: 0.5265\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 753us/step - loss: 0.0249 - val_loss: 0.5223\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 0.0231 - val_loss: 0.5245\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 782us/step - loss: 0.0216 - val_loss: 0.5248\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 680us/step - loss: 0.0204 - val_loss: 0.5212\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 826us/step - loss: 0.0193 - val_loss: 0.5244\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 735us/step - loss: 0.0183 - val_loss: 0.5231\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 755us/step - loss: 0.0175 - val_loss: 0.5249\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 757us/step - loss: 0.0166 - val_loss: 0.5257\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 0.0160 - val_loss: 0.5256\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 765us/step - loss: 0.0151 - val_loss: 0.5245\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 692us/step - loss: 0.0145 - val_loss: 0.5243\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 731us/step - loss: 0.0138 - val_loss: 0.5245\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 740us/step - loss: 0.0132 - val_loss: 0.5229\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 745us/step - loss: 0.0126 - val_loss: 0.5262\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 0.0121 - val_loss: 0.5247\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 753us/step - loss: 0.0117 - val_loss: 0.5245\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 751us/step - loss: 0.0112 - val_loss: 0.5266\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 737us/step - loss: 0.0107 - val_loss: 0.5256\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 0.0104 - val_loss: 0.5255\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 761us/step - loss: 0.0100 - val_loss: 0.5265\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 738us/step - loss: 0.0096 - val_loss: 0.5263\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 675us/step - loss: 0.0092 - val_loss: 0.5259\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 691us/step - loss: 0.0089 - val_loss: 0.5270\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 706us/step - loss: 0.0086 - val_loss: 0.5266\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 696us/step - loss: 0.0083 - val_loss: 0.5267\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 749us/step - loss: 0.0080 - val_loss: 0.5305\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 714us/step - loss: 0.0078 - val_loss: 0.5307\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 0.0075 - val_loss: 0.5306\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 755us/step - loss: 0.0073 - val_loss: 0.5300\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 767us/step - loss: 0.0070 - val_loss: 0.5305\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 747us/step - loss: 0.0068 - val_loss: 0.5303\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 781us/step - loss: 0.0066 - val_loss: 0.5292\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 705us/step - loss: 0.0064 - val_loss: 0.5303\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 800us/step - loss: 0.0063 - val_loss: 0.5309\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 753us/step - loss: 0.0061 - val_loss: 0.5339\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 0.0059 - val_loss: 0.5350\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 752us/step - loss: 0.0058 - val_loss: 0.5334\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 771us/step - loss: 0.0056 - val_loss: 0.5358\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 0.0054 - val_loss: 0.5365\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 724us/step - loss: 0.0053 - val_loss: 0.5341\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 679us/step - loss: 0.0051 - val_loss: 0.5345\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 607us/step - loss: 0.0050 - val_loss: 0.5356\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 673us/step - loss: 0.0049 - val_loss: 0.5370\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 0.0047 - val_loss: 0.5362\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 705us/step - loss: 0.0046 - val_loss: 0.5395\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 692us/step - loss: 0.0045 - val_loss: 0.5412\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 0.0044 - val_loss: 0.5403\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 738us/step - loss: 0.0043 - val_loss: 0.5392\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 0.0042 - val_loss: 0.5398\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 748us/step - loss: 0.0041 - val_loss: 0.5411\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 766us/step - loss: 0.0040 - val_loss: 0.5414\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 742us/step - loss: 0.0039 - val_loss: 0.5391\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 592us/step - loss: 0.0038 - val_loss: 0.5406\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 594us/step - loss: 0.0037 - val_loss: 0.5429\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 580us/step - loss: 0.0036 - val_loss: 0.5441\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 592us/step - loss: 0.0035 - val_loss: 0.5427\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 592us/step - loss: 0.0035 - val_loss: 0.5440\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 601us/step - loss: 0.0034 - val_loss: 0.5435\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 592us/step - loss: 0.0033 - val_loss: 0.5437\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 599us/step - loss: 0.0032 - val_loss: 0.5444\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 606us/step - loss: 0.0032 - val_loss: 0.5455\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 592us/step - loss: 0.0031 - val_loss: 0.5473\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 609us/step - loss: 0.0030 - val_loss: 0.5471\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 581us/step - loss: 0.0030 - val_loss: 0.5476\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 571us/step - loss: 0.0029 - val_loss: 0.5484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 613us/step - loss: 0.0028 - val_loss: 0.5499\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 589us/step - loss: 0.0028 - val_loss: 0.5514\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 611us/step - loss: 0.0027 - val_loss: 0.5519\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 590us/step - loss: 0.0027 - val_loss: 0.5522\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 610us/step - loss: 0.0026 - val_loss: 0.5532\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 615us/step - loss: 0.0026 - val_loss: 0.5528\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 606us/step - loss: 0.0025 - val_loss: 0.5547\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 586us/step - loss: 0.0025 - val_loss: 0.5556\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 574us/step - loss: 0.0024 - val_loss: 0.5549\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 609us/step - loss: 0.0024 - val_loss: 0.5546\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 617us/step - loss: 0.0023 - val_loss: 0.5557\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 656us/step - loss: 0.0023 - val_loss: 0.5549\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 765us/step - loss: 0.0023 - val_loss: 0.5547\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 728us/step - loss: 0.0022 - val_loss: 0.5559\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 0.0022 - val_loss: 0.5567\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 987us/step - loss: 0.0021 - val_loss: 0.5583\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 737us/step - loss: 0.0021 - val_loss: 0.5589\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 739us/step - loss: 0.0021 - val_loss: 0.5595\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 0.0020 - val_loss: 0.5596\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 728us/step - loss: 0.0020 - val_loss: 0.5595\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 732us/step - loss: 0.0020 - val_loss: 0.5605\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 759us/step - loss: 0.0019 - val_loss: 0.5606\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 695us/step - loss: 0.0019 - val_loss: 0.5620\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 730us/step - loss: 0.0019 - val_loss: 0.5608\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 0.0018 - val_loss: 0.5612\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 788us/step - loss: 0.0018 - val_loss: 0.5635\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 0.0018 - val_loss: 0.5645\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 713us/step - loss: 0.0017 - val_loss: 0.5636\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 0.0017 - val_loss: 0.5633\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 0.0017 - val_loss: 0.5641\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 748us/step - loss: 0.0017 - val_loss: 0.5646\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 746us/step - loss: 0.0016 - val_loss: 0.5645\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 690us/step - loss: 0.0016 - val_loss: 0.5660\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 736us/step - loss: 0.0016 - val_loss: 0.5648\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 742us/step - loss: 0.0016 - val_loss: 0.5659\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 729us/step - loss: 0.0015 - val_loss: 0.5665\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 775us/step - loss: 0.0015 - val_loss: 0.5668\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 696us/step - loss: 0.0015 - val_loss: 0.5683\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 671us/step - loss: 0.0015 - val_loss: 0.5691\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 742us/step - loss: 0.0014 - val_loss: 0.5688\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 0.0014 - val_loss: 0.5694\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 776us/step - loss: 0.0014 - val_loss: 0.5695\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 693us/step - loss: 0.0014 - val_loss: 0.5695\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 0.0014 - val_loss: 0.5708\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 682us/step - loss: 0.0013 - val_loss: 0.5706\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 737us/step - loss: 0.0013 - val_loss: 0.5715\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 758us/step - loss: 0.0013 - val_loss: 0.5721\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 730us/step - loss: 0.0013 - val_loss: 0.5737\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 781us/step - loss: 0.0013 - val_loss: 0.5736\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 713us/step - loss: 0.0012 - val_loss: 0.5735\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 693us/step - loss: 0.0012 - val_loss: 0.5746\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 728us/step - loss: 0.0012 - val_loss: 0.5749\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 732us/step - loss: 0.0012 - val_loss: 0.5755\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 733us/step - loss: 0.0012 - val_loss: 0.5768\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 736us/step - loss: 0.0012 - val_loss: 0.5764\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 714us/step - loss: 0.0011 - val_loss: 0.5773\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 743us/step - loss: 0.0011 - val_loss: 0.5774\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 717us/step - loss: 0.0011 - val_loss: 0.5777\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 749us/step - loss: 0.0011 - val_loss: 0.5781\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 712us/step - loss: 0.0011 - val_loss: 0.5788\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 735us/step - loss: 0.0011 - val_loss: 0.5789\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 738us/step - loss: 0.0010 - val_loss: 0.5809\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 710us/step - loss: 0.0010 - val_loss: 0.5813\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 0.0010 - val_loss: 0.5813\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 729us/step - loss: 0.0010 - val_loss: 0.5802\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 9.9215e-04 - val_loss: 0.5819\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 760us/step - loss: 9.7916e-04 - val_loss: 0.5823\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 722us/step - loss: 9.6648e-04 - val_loss: 0.5824\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 9.5426e-04 - val_loss: 0.5829\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 692us/step - loss: 9.4021e-04 - val_loss: 0.5829\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 9.2852e-04 - val_loss: 0.5839\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 623us/step - loss: 9.1722e-04 - val_loss: 0.5845\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 673us/step - loss: 9.0603e-04 - val_loss: 0.5852\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 722us/step - loss: 8.9458e-04 - val_loss: 0.5854\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 8.8118e-04 - val_loss: 0.5860\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 8.7111e-04 - val_loss: 0.5872\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 710us/step - loss: 8.5957e-04 - val_loss: 0.5870\n",
      "Epoch 184/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 694us/step - loss: 8.4957e-04 - val_loss: 0.5879\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 713us/step - loss: 8.3925e-04 - val_loss: 0.5888\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 680us/step - loss: 8.2775e-04 - val_loss: 0.5890\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 680us/step - loss: 8.1832e-04 - val_loss: 0.5884\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 681us/step - loss: 8.0761e-04 - val_loss: 0.5898\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 660us/step - loss: 7.9740e-04 - val_loss: 0.5899\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 590us/step - loss: 7.8733e-04 - val_loss: 0.5901\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 627us/step - loss: 7.7771e-04 - val_loss: 0.5910\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 655us/step - loss: 7.6878e-04 - val_loss: 0.5913\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 591us/step - loss: 7.6072e-04 - val_loss: 0.5932\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 611us/step - loss: 7.5126e-04 - val_loss: 0.5927\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 584us/step - loss: 7.4164e-04 - val_loss: 0.5927\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 567us/step - loss: 7.3279e-04 - val_loss: 0.5928\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 582us/step - loss: 7.2459e-04 - val_loss: 0.5933\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 607us/step - loss: 7.1481e-04 - val_loss: 0.5943\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 617us/step - loss: 7.0692e-04 - val_loss: 0.5941\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 616us/step - loss: 6.9948e-04 - val_loss: 0.5946\n",
      "   (0, 15)   linear A\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.2407 - val_loss: 2.1445\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 591us/step - loss: 1.9658 - val_loss: 1.9182\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 1.6492 - val_loss: 1.6432\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 1.3281 - val_loss: 1.4115\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 714us/step - loss: 1.0717 - val_loss: 1.2074\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 0.8644 - val_loss: 1.0702\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 0.6872 - val_loss: 0.9319\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 677us/step - loss: 0.5612 - val_loss: 0.8621\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 699us/step - loss: 0.4592 - val_loss: 0.8188\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 706us/step - loss: 0.3808 - val_loss: 0.7925\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 691us/step - loss: 0.3159 - val_loss: 0.7354\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 726us/step - loss: 0.2627 - val_loss: 0.7250\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 758us/step - loss: 0.2133 - val_loss: 0.7134\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 730us/step - loss: 0.1740 - val_loss: 0.6974\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 654us/step - loss: 0.1508 - val_loss: 0.6979\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 0.1267 - val_loss: 0.6871\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 679us/step - loss: 0.1037 - val_loss: 0.6911\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 0.0865 - val_loss: 0.6962\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 685us/step - loss: 0.0758 - val_loss: 0.6986\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 692us/step - loss: 0.0654 - val_loss: 0.6959\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 699us/step - loss: 0.0560 - val_loss: 0.7055\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 723us/step - loss: 0.0488 - val_loss: 0.7016\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 696us/step - loss: 0.0424 - val_loss: 0.7182\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 698us/step - loss: 0.0369 - val_loss: 0.7070\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 0.0335 - val_loss: 0.7226\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 0.0293 - val_loss: 0.7167\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 699us/step - loss: 0.0262 - val_loss: 0.7190\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 0.0231 - val_loss: 0.7351\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 690us/step - loss: 0.0210 - val_loss: 0.7344\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 692us/step - loss: 0.0190 - val_loss: 0.7326\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 701us/step - loss: 0.0173 - val_loss: 0.7487\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 716us/step - loss: 0.0156 - val_loss: 0.7482\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 698us/step - loss: 0.0144 - val_loss: 0.7482\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 680us/step - loss: 0.0132 - val_loss: 0.7613\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 0.0122 - val_loss: 0.7599\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 0.0113 - val_loss: 0.7650\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 737us/step - loss: 0.0104 - val_loss: 0.7687\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 696us/step - loss: 0.0097 - val_loss: 0.7763\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 656us/step - loss: 0.0091 - val_loss: 0.7796\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 0.0085 - val_loss: 0.7788\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 0.0080 - val_loss: 0.7876\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 669us/step - loss: 0.0075 - val_loss: 0.7870\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 704us/step - loss: 0.0070 - val_loss: 0.7922\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 0.0066 - val_loss: 0.8007\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 0.0063 - val_loss: 0.8003\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 713us/step - loss: 0.0059 - val_loss: 0.8020\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 646us/step - loss: 0.0056 - val_loss: 0.7988\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 716us/step - loss: 0.0053 - val_loss: 0.8080\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 0.0051 - val_loss: 0.8135\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 680us/step - loss: 0.0048 - val_loss: 0.8147\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 0.0046 - val_loss: 0.8176\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 655us/step - loss: 0.0044 - val_loss: 0.8198\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 718us/step - loss: 0.0041 - val_loss: 0.8193\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 686us/step - loss: 0.0040 - val_loss: 0.8282\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 676us/step - loss: 0.0038 - val_loss: 0.8313\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 658us/step - loss: 0.0036 - val_loss: 0.8321\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 693us/step - loss: 0.0035 - val_loss: 0.8370\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 678us/step - loss: 0.0033 - val_loss: 0.8368\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 706us/step - loss: 0.0032 - val_loss: 0.8388\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 674us/step - loss: 0.0031 - val_loss: 0.8420\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 691us/step - loss: 0.0029 - val_loss: 0.8469\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 0.0028 - val_loss: 0.8485\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 714us/step - loss: 0.0027 - val_loss: 0.8533\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 677us/step - loss: 0.0026 - val_loss: 0.8535\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 0.0025 - val_loss: 0.8575\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 674us/step - loss: 0.0024 - val_loss: 0.8578\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 663us/step - loss: 0.0023 - val_loss: 0.8623\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 614us/step - loss: 0.0023 - val_loss: 0.8660\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 0.0022 - val_loss: 0.8672\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 620us/step - loss: 0.0021 - val_loss: 0.8705\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 674us/step - loss: 0.0020 - val_loss: 0.8684\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 700us/step - loss: 0.0020 - val_loss: 0.8702\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 671us/step - loss: 0.0019 - val_loss: 0.8750\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 697us/step - loss: 0.0018 - val_loss: 0.8764\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 663us/step - loss: 0.0018 - val_loss: 0.8777\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 644us/step - loss: 0.0017 - val_loss: 0.8799\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 659us/step - loss: 0.0017 - val_loss: 0.8817\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 662us/step - loss: 0.0016 - val_loss: 0.8837\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 627us/step - loss: 0.0016 - val_loss: 0.8856\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 671us/step - loss: 0.0015 - val_loss: 0.8890\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 584us/step - loss: 0.0015 - val_loss: 0.8895\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 546us/step - loss: 0.0015 - val_loss: 0.8921\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 563us/step - loss: 0.0014 - val_loss: 0.8944\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 560us/step - loss: 0.0014 - val_loss: 0.8960\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 584us/step - loss: 0.0013 - val_loss: 0.8971\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 592us/step - loss: 0.0013 - val_loss: 0.9001\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 563us/step - loss: 0.0013 - val_loss: 0.9037\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 563us/step - loss: 0.0012 - val_loss: 0.9040\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 561us/step - loss: 0.0012 - val_loss: 0.9067\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 579us/step - loss: 0.0012 - val_loss: 0.9087\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 537us/step - loss: 0.0011 - val_loss: 0.9123\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 553us/step - loss: 0.0011 - val_loss: 0.9156\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 552us/step - loss: 0.0011 - val_loss: 0.9154\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 550us/step - loss: 0.0011 - val_loss: 0.9173\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 549us/step - loss: 0.0010 - val_loss: 0.9194\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 569us/step - loss: 0.0010 - val_loss: 0.9205\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 572us/step - loss: 9.8643e-04 - val_loss: 0.9210\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 623us/step - loss: 9.6201e-04 - val_loss: 0.9230\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 607us/step - loss: 9.4229e-04 - val_loss: 0.9253\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 588us/step - loss: 9.1970e-04 - val_loss: 0.9269\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 643us/step - loss: 8.9812e-04 - val_loss: 0.9277\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 568us/step - loss: 8.7980e-04 - val_loss: 0.9282\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 561us/step - loss: 8.6167e-04 - val_loss: 0.9301\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 576us/step - loss: 8.4361e-04 - val_loss: 0.9339\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 576us/step - loss: 8.2238e-04 - val_loss: 0.9358\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 557us/step - loss: 8.0277e-04 - val_loss: 0.9368\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 569us/step - loss: 7.8737e-04 - val_loss: 0.9380\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 561us/step - loss: 7.6964e-04 - val_loss: 0.9372\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 549us/step - loss: 7.5457e-04 - val_loss: 0.9396\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 574us/step - loss: 7.3642e-04 - val_loss: 0.9404\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 552us/step - loss: 7.2205e-04 - val_loss: 0.9420\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 574us/step - loss: 7.0740e-04 - val_loss: 0.9452\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 548us/step - loss: 6.9319e-04 - val_loss: 0.9456\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 670us/step - loss: 6.7894e-04 - val_loss: 0.9479\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 756us/step - loss: 6.6436e-04 - val_loss: 0.9487\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 696us/step - loss: 6.5182e-04 - val_loss: 0.9491\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 768us/step - loss: 6.3924e-04 - val_loss: 0.9503\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 801us/step - loss: 6.2686e-04 - val_loss: 0.9524\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 710us/step - loss: 6.1436e-04 - val_loss: 0.9547\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 683us/step - loss: 6.0306e-04 - val_loss: 0.9570\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 689us/step - loss: 5.9174e-04 - val_loss: 0.9563\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 5.8227e-04 - val_loss: 0.9594\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 736us/step - loss: 5.6896e-04 - val_loss: 0.9607\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 5.5974e-04 - val_loss: 0.9610\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 705us/step - loss: 5.4909e-04 - val_loss: 0.9617\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 5.3848e-04 - val_loss: 0.9647\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 686us/step - loss: 5.2895e-04 - val_loss: 0.9663\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 731us/step - loss: 5.1932e-04 - val_loss: 0.9684\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 749us/step - loss: 5.1152e-04 - val_loss: 0.9694\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 764us/step - loss: 5.0124e-04 - val_loss: 0.9709\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 4.9046e-04 - val_loss: 0.9715\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 779us/step - loss: 4.8205e-04 - val_loss: 0.9724\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 755us/step - loss: 4.7355e-04 - val_loss: 0.9730\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 761us/step - loss: 4.6638e-04 - val_loss: 0.9755\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 4.5733e-04 - val_loss: 0.9755\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 731us/step - loss: 4.4986e-04 - val_loss: 0.9766\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 691us/step - loss: 4.4327e-04 - val_loss: 0.9775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 736us/step - loss: 4.3467e-04 - val_loss: 0.9791\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 716us/step - loss: 4.2778e-04 - val_loss: 0.9802\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 701us/step - loss: 4.2076e-04 - val_loss: 0.9808\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 696us/step - loss: 4.1393e-04 - val_loss: 0.9838\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 741us/step - loss: 4.0695e-04 - val_loss: 0.9857\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 753us/step - loss: 4.0098e-04 - val_loss: 0.9862\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 869us/step - loss: 3.9382e-04 - val_loss: 0.9877\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 979us/step - loss: 3.8711e-04 - val_loss: 0.9886\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 899us/step - loss: 3.8144e-04 - val_loss: 0.9893\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 723us/step - loss: 3.7521e-04 - val_loss: 0.9899\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 748us/step - loss: 3.6943e-04 - val_loss: 0.9906\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 742us/step - loss: 3.6466e-04 - val_loss: 0.9920\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 694us/step - loss: 3.5818e-04 - val_loss: 0.9930\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 847us/step - loss: 3.5268e-04 - val_loss: 0.9934\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 755us/step - loss: 3.4759e-04 - val_loss: 0.9947\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 742us/step - loss: 3.4215e-04 - val_loss: 0.9960\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 3.3679e-04 - val_loss: 0.9975\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 3.3193e-04 - val_loss: 0.9998\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 3.2687e-04 - val_loss: 0.9998\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 696us/step - loss: 3.2180e-04 - val_loss: 1.0013\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 698us/step - loss: 3.1719e-04 - val_loss: 1.0039\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 774us/step - loss: 3.1238e-04 - val_loss: 1.0045\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 732us/step - loss: 3.0789e-04 - val_loss: 1.0059\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 730us/step - loss: 3.0305e-04 - val_loss: 1.0066\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 2.9871e-04 - val_loss: 1.0072\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 2.9414e-04 - val_loss: 1.0085\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 2.8991e-04 - val_loss: 1.0093\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 753us/step - loss: 2.8652e-04 - val_loss: 1.0107\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 2.8180e-04 - val_loss: 1.0115\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 956us/step - loss: 2.7806e-04 - val_loss: 1.0130\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 723us/step - loss: 2.7427e-04 - val_loss: 1.0152\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 761us/step - loss: 2.7016e-04 - val_loss: 1.0154\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 671us/step - loss: 2.6668e-04 - val_loss: 1.0153\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 2.6297e-04 - val_loss: 1.0159\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 701us/step - loss: 2.5923e-04 - val_loss: 1.0182\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 716us/step - loss: 2.5548e-04 - val_loss: 1.0208\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 675us/step - loss: 2.5178e-04 - val_loss: 1.0216\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 2.4819e-04 - val_loss: 1.0213\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 797us/step - loss: 2.4480e-04 - val_loss: 1.0223\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 2.4179e-04 - val_loss: 1.0234\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 753us/step - loss: 2.3871e-04 - val_loss: 1.0242\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 736us/step - loss: 2.3492e-04 - val_loss: 1.0264\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 2.3279e-04 - val_loss: 1.0286\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 2.2946e-04 - val_loss: 1.0280\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 781us/step - loss: 2.2595e-04 - val_loss: 1.0285\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 770us/step - loss: 2.2324e-04 - val_loss: 1.0284\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 694us/step - loss: 2.2031e-04 - val_loss: 1.0297\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 587us/step - loss: 2.1733e-04 - val_loss: 1.0302\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 643us/step - loss: 2.1478e-04 - val_loss: 1.0313\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 702us/step - loss: 2.1193e-04 - val_loss: 1.0322\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 2.0916e-04 - val_loss: 1.0341\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 638us/step - loss: 2.0659e-04 - val_loss: 1.0346\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 728us/step - loss: 2.0400e-04 - val_loss: 1.0352\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 730us/step - loss: 2.0152e-04 - val_loss: 1.0365\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 690us/step - loss: 1.9911e-04 - val_loss: 1.0381\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 686us/step - loss: 1.9662e-04 - val_loss: 1.0387\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 2.0508e-0 - 0s 655us/step - loss: 1.9404e-04 - val_loss: 1.0394\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 701us/step - loss: 1.9151e-04 - val_loss: 1.0410\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 1.8920e-04 - val_loss: 1.0419\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 667us/step - loss: 1.8696e-04 - val_loss: 1.0429\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 692us/step - loss: 1.8460e-04 - val_loss: 1.0445\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 551us/step - loss: 1.8238e-04 - val_loss: 1.0456\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 558us/step - loss: 1.8023e-04 - val_loss: 1.0458\n",
      "   (0, 15)   linear B\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 7.2099 - val_loss: 7.3097\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 6.6084 - val_loss: 6.7745\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 6.1272 - val_loss: 6.4968\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 356us/step - loss: 5.8914 - val_loss: 6.2801\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 5.6265 - val_loss: 5.9377\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 5.486 - 0s 322us/step - loss: 5.2945 - val_loss: 5.5890\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 4.9834 - val_loss: 5.2768\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 4.6937 - val_loss: 4.9856\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 4.3997 - val_loss: 4.7136\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 4.1386 - val_loss: 4.4432\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 3.723 - 0s 306us/step - loss: 3.8626 - val_loss: 4.1452\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 315us/step - loss: 3.5556 - val_loss: 3.8369\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 263us/step - loss: 3.2587 - val_loss: 3.5221\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 2.9754 - val_loss: 3.2117\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 2.6711 - val_loss: 2.8944\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 2.3759 - val_loss: 2.5939\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 2.1124 - val_loss: 2.3690\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 1.8768 - val_loss: 2.2155\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 1.6709 - val_loss: 2.0562\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 266us/step - loss: 1.4872 - val_loss: 1.9101\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 1.3441 - val_loss: 1.7694\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 1.2034 - val_loss: 1.6651\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 1.0700 - val_loss: 1.5848\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.9601 - val_loss: 1.4773\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 358us/step - loss: 0.8621 - val_loss: 1.3942\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 0.7751 - val_loss: 1.3333\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 0.7061 - val_loss: 1.2878\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 384us/step - loss: 0.6379 - val_loss: 1.2521\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.5805 - val_loss: 1.2009\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.5269 - val_loss: 1.1666\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.4837 - val_loss: 1.1496\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 349us/step - loss: 0.4436 - val_loss: 1.1298\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.4054 - val_loss: 1.1142\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 378us/step - loss: 0.3703 - val_loss: 1.0935\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 355us/step - loss: 0.3406 - val_loss: 1.0792\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 381us/step - loss: 0.3082 - val_loss: 1.0674\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 349us/step - loss: 0.2871 - val_loss: 1.0683\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 357us/step - loss: 0.2612 - val_loss: 1.0556\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 423us/step - loss: 0.2415 - val_loss: 1.0427\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 0.2226 - val_loss: 1.0328\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 0.2067 - val_loss: 1.0392\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 353us/step - loss: 0.1910 - val_loss: 1.0461\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 355us/step - loss: 0.1766 - val_loss: 1.0335\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 0.1618 - val_loss: 1.0201\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 414us/step - loss: 0.1485 - val_loss: 1.0121\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 0.1388 - val_loss: 1.0117\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 0.1254 - val_loss: 1.0105\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 360us/step - loss: 0.1154 - val_loss: 1.0133\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.1083 - val_loss: 1.0091\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 353us/step - loss: 0.0993 - val_loss: 1.0045\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 366us/step - loss: 0.0929 - val_loss: 0.9982\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 365us/step - loss: 0.0861 - val_loss: 0.9899\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.0807 - val_loss: 0.9849\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 378us/step - loss: 0.0749 - val_loss: 0.9836\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 343us/step - loss: 0.0699 - val_loss: 0.9858\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 0.0658 - val_loss: 0.9848\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 378us/step - loss: 0.0619 - val_loss: 0.9787\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 353us/step - loss: 0.0576 - val_loss: 0.9729\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 0.0546 - val_loss: 0.9726\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 397us/step - loss: 0.0515 - val_loss: 0.9702\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 367us/step - loss: 0.0488 - val_loss: 0.9701\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.0460 - val_loss: 0.9691\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 399us/step - loss: 0.0437 - val_loss: 0.9661\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.0416 - val_loss: 0.9663\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.0394 - val_loss: 0.9652\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 390us/step - loss: 0.0376 - val_loss: 0.9652\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 387us/step - loss: 0.0358 - val_loss: 0.9652\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 380us/step - loss: 0.0341 - val_loss: 0.9662\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 387us/step - loss: 0.0326 - val_loss: 0.9645\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 404us/step - loss: 0.0310 - val_loss: 0.9644\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 436us/step - loss: 0.0298 - val_loss: 0.9650\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 377us/step - loss: 0.0287 - val_loss: 0.9656\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 0.0274 - val_loss: 0.9657\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 377us/step - loss: 0.0262 - val_loss: 0.9638\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 0.0252 - val_loss: 0.9643\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 357us/step - loss: 0.0243 - val_loss: 0.9644\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 349us/step - loss: 0.0233 - val_loss: 0.9658\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 349us/step - loss: 0.0224 - val_loss: 0.9649\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 0.0216 - val_loss: 0.9644\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 401us/step - loss: 0.0208 - val_loss: 0.9640\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 343us/step - loss: 0.0201 - val_loss: 0.9644\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 352us/step - loss: 0.0193 - val_loss: 0.9648\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 395us/step - loss: 0.0187 - val_loss: 0.9645\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 0.0181 - val_loss: 0.9632\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 0.0175 - val_loss: 0.9641\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.0169 - val_loss: 0.9650\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 370us/step - loss: 0.0163 - val_loss: 0.9652\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0158 - val_loss: 0.9666\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 381us/step - loss: 0.0153 - val_loss: 0.9668\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.0148 - val_loss: 0.9684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0143 - val_loss: 0.9683\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 355us/step - loss: 0.0139 - val_loss: 0.9673\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 0.0134 - val_loss: 0.9678\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 0.0130 - val_loss: 0.9677\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 381us/step - loss: 0.0126 - val_loss: 0.9676\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0122 - val_loss: 0.9677\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0118 - val_loss: 0.9682\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 398us/step - loss: 0.0114 - val_loss: 0.9687\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.0111 - val_loss: 0.9685\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 349us/step - loss: 0.0107 - val_loss: 0.9697\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 393us/step - loss: 0.0104 - val_loss: 0.9695\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 352us/step - loss: 0.0101 - val_loss: 0.9699\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 355us/step - loss: 0.0098 - val_loss: 0.9709\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 356us/step - loss: 0.0095 - val_loss: 0.9723\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 0.0093 - val_loss: 0.9721\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 343us/step - loss: 0.0090 - val_loss: 0.9721\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 395us/step - loss: 0.0088 - val_loss: 0.9713\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 0.0085 - val_loss: 0.9721\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 355us/step - loss: 0.0083 - val_loss: 0.9735\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 371us/step - loss: 0.0081 - val_loss: 0.9743\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 352us/step - loss: 0.0079 - val_loss: 0.9747\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 0.0077 - val_loss: 0.9750\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 414us/step - loss: 0.0075 - val_loss: 0.9752\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 0.0073 - val_loss: 0.9770\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 363us/step - loss: 0.0071 - val_loss: 0.9773\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 374us/step - loss: 0.0069 - val_loss: 0.9776\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0068 - val_loss: 0.9781\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 0.0066 - val_loss: 0.9790\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 375us/step - loss: 0.0065 - val_loss: 0.9802\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 353us/step - loss: 0.0063 - val_loss: 0.9799\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 401us/step - loss: 0.0062 - val_loss: 0.9798\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 0.0060 - val_loss: 0.9807\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 362us/step - loss: 0.0059 - val_loss: 0.9815\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 394us/step - loss: 0.0058 - val_loss: 0.9815\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 0.0057 - val_loss: 0.9809\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0055 - val_loss: 0.9818\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 0.0054 - val_loss: 0.9825\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.0053 - val_loss: 0.9836\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 373us/step - loss: 0.0052 - val_loss: 0.9838\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 368us/step - loss: 0.0051 - val_loss: 0.9853\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 390us/step - loss: 0.0050 - val_loss: 0.9854\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 0.0049 - val_loss: 0.9849\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.0048 - val_loss: 0.9855\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 399us/step - loss: 0.0047 - val_loss: 0.9864\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 406us/step - loss: 0.0046 - val_loss: 0.9870\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 402us/step - loss: 0.0045 - val_loss: 0.9873\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 402us/step - loss: 0.0045 - val_loss: 0.9876\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 0.0044 - val_loss: 0.9880\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 380us/step - loss: 0.0043 - val_loss: 0.9887\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 353us/step - loss: 0.0042 - val_loss: 0.9891\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 0.0042 - val_loss: 0.9899\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 365us/step - loss: 0.0041 - val_loss: 0.9904\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 423us/step - loss: 0.0040 - val_loss: 0.9901\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 586us/step - loss: 0.0039 - val_loss: 0.9904\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 538us/step - loss: 0.0039 - val_loss: 0.9915\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 0.0038 - val_loss: 0.9922\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 467us/step - loss: 0.0037 - val_loss: 0.9930\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 399us/step - loss: 0.0037 - val_loss: 0.9930\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 393us/step - loss: 0.0036 - val_loss: 0.9933\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 0.0036 - val_loss: 0.9940\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.0035 - val_loss: 0.9943\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.0035 - val_loss: 0.9947\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 366us/step - loss: 0.0034 - val_loss: 0.9955\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.0033 - val_loss: 0.9957\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 368us/step - loss: 0.0033 - val_loss: 0.9961\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 365us/step - loss: 0.0032 - val_loss: 0.9966\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 352us/step - loss: 0.0032 - val_loss: 0.9968\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 0.0031 - val_loss: 0.9976\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 0.0031 - val_loss: 0.9978\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 0.0030 - val_loss: 0.9980\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 396us/step - loss: 0.0030 - val_loss: 0.9984\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 382us/step - loss: 0.0030 - val_loss: 0.9996\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 379us/step - loss: 0.0029 - val_loss: 1.0006\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 420us/step - loss: 0.0029 - val_loss: 1.0006\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 360us/step - loss: 0.0028 - val_loss: 1.0009\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 375us/step - loss: 0.0028 - val_loss: 1.0013\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 447us/step - loss: 0.0028 - val_loss: 1.0025\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 0.0027 - val_loss: 1.0027\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 364us/step - loss: 0.0027 - val_loss: 1.0027\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 457us/step - loss: 0.0026 - val_loss: 1.0032\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 386us/step - loss: 0.0026 - val_loss: 1.0039\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 353us/step - loss: 0.0026 - val_loss: 1.0041\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 365us/step - loss: 0.0025 - val_loss: 1.0046\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0025 - val_loss: 1.0049\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0025 - val_loss: 1.0056\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 0.0024 - val_loss: 1.0063\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 355us/step - loss: 0.0024 - val_loss: 1.0062\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 396us/step - loss: 0.0024 - val_loss: 1.0065\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 349us/step - loss: 0.0023 - val_loss: 1.0069\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.0023 - val_loss: 1.0077\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 356us/step - loss: 0.0023 - val_loss: 1.0081\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 0.0023 - val_loss: 1.0086\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 391us/step - loss: 0.0022 - val_loss: 1.0089\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 0.0022 - val_loss: 1.0092\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.0022 - val_loss: 1.0100\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0021 - val_loss: 1.0103\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.0021 - val_loss: 1.0102\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 0.0021 - val_loss: 1.0110\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 0.0021 - val_loss: 1.0118\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.0020 - val_loss: 1.0124\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 0.0020 - val_loss: 1.0126\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0020 - val_loss: 1.0132\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.0020 - val_loss: 1.0138\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.0019 - val_loss: 1.0142\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.0019 - val_loss: 1.0141\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 343us/step - loss: 0.0019 - val_loss: 1.0149\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.0019 - val_loss: 1.0153\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0019 - val_loss: 1.0158\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 0.0018 - val_loss: 1.0161\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 0.0018 - val_loss: 1.0165\n",
      "   (0, 15)   linear C\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 4.4568 - val_loss: 4.0546\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 544us/step - loss: 3.6961 - val_loss: 3.4416\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 551us/step - loss: 2.9261 - val_loss: 2.8098\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 587us/step - loss: 2.2482 - val_loss: 2.1980\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 586us/step - loss: 1.7277 - val_loss: 1.7858\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 581us/step - loss: 1.3951 - val_loss: 1.4899\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 840us/step - loss: 1.1226 - val_loss: 1.1951\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 825us/step - loss: 0.9002 - val_loss: 1.0121\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 846us/step - loss: 0.7236 - val_loss: 0.8734\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 589us/step - loss: 0.6043 - val_loss: 0.7927\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 576us/step - loss: 0.4963 - val_loss: 0.7194\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 614us/step - loss: 0.4169 - val_loss: 0.6676\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 588us/step - loss: 0.3407 - val_loss: 0.6302\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 610us/step - loss: 0.2894 - val_loss: 0.5944\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 601us/step - loss: 0.2447 - val_loss: 0.5650\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 649us/step - loss: 0.2041 - val_loss: 0.5670\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 607us/step - loss: 0.1754 - val_loss: 0.5300\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 577us/step - loss: 0.1496 - val_loss: 0.5125\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 565us/step - loss: 0.1234 - val_loss: 0.5075\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 593us/step - loss: 0.1083 - val_loss: 0.5023\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 606us/step - loss: 0.0936 - val_loss: 0.4848\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 615us/step - loss: 0.0808 - val_loss: 0.4775\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 580us/step - loss: 0.0714 - val_loss: 0.4716\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 638us/step - loss: 0.0623 - val_loss: 0.4740\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 798us/step - loss: 0.0549 - val_loss: 0.4697\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 755us/step - loss: 0.0492 - val_loss: 0.4599\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 698us/step - loss: 0.0434 - val_loss: 0.4598\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 702us/step - loss: 0.0398 - val_loss: 0.4654\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 0.0361 - val_loss: 0.4587\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 795us/step - loss: 0.0321 - val_loss: 0.4564\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 713us/step - loss: 0.0285 - val_loss: 0.4530\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 860us/step - loss: 0.0260 - val_loss: 0.4576\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 0.0235 - val_loss: 0.4538\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 767us/step - loss: 0.0215 - val_loss: 0.4536\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 712us/step - loss: 0.0198 - val_loss: 0.4542\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 0.0182 - val_loss: 0.4579\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 745us/step - loss: 0.0169 - val_loss: 0.4561\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 668us/step - loss: 0.0155 - val_loss: 0.4551\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 750us/step - loss: 0.0145 - val_loss: 0.4538\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 0.0135 - val_loss: 0.4567\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 647us/step - loss: 0.0126 - val_loss: 0.4559\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 0.0118 - val_loss: 0.4570\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 762us/step - loss: 0.0110 - val_loss: 0.4588\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 768us/step - loss: 0.0104 - val_loss: 0.4571\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 776us/step - loss: 0.0097 - val_loss: 0.4574\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 739us/step - loss: 0.0091 - val_loss: 0.4583\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 754us/step - loss: 0.0086 - val_loss: 0.4653\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 733us/step - loss: 0.0081 - val_loss: 0.4686\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 678us/step - loss: 0.0076 - val_loss: 0.4653\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 697us/step - loss: 0.0072 - val_loss: 0.4661\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 699us/step - loss: 0.0068 - val_loss: 0.4682\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 768us/step - loss: 0.0065 - val_loss: 0.4678\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 722us/step - loss: 0.0061 - val_loss: 0.4688\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 722us/step - loss: 0.0058 - val_loss: 0.4696\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 0.0056 - val_loss: 0.4761\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 680us/step - loss: 0.0053 - val_loss: 0.4735\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 743us/step - loss: 0.0050 - val_loss: 0.4734\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 790us/step - loss: 0.0048 - val_loss: 0.4753\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 718us/step - loss: 0.0046 - val_loss: 0.4769\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 0.0045 - val_loss: 0.4788\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 0.0043 - val_loss: 0.4771\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 774us/step - loss: 0.0041 - val_loss: 0.4777\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 738us/step - loss: 0.0039 - val_loss: 0.4810\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 661us/step - loss: 0.0038 - val_loss: 0.4822\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 726us/step - loss: 0.0036 - val_loss: 0.4809\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 785us/step - loss: 0.0035 - val_loss: 0.4818\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 737us/step - loss: 0.0034 - val_loss: 0.4836\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 739us/step - loss: 0.0032 - val_loss: 0.4842\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 749us/step - loss: 0.0031 - val_loss: 0.4859\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 816us/step - loss: 0.0030 - val_loss: 0.4870\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 829us/step - loss: 0.0029 - val_loss: 0.4878\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 0.0028 - val_loss: 0.4896\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 745us/step - loss: 0.0027 - val_loss: 0.4921\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 0.0026 - val_loss: 0.4912\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 736us/step - loss: 0.0025 - val_loss: 0.4929\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 764us/step - loss: 0.0025 - val_loss: 0.4924\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 775us/step - loss: 0.0024 - val_loss: 0.4940\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 776us/step - loss: 0.0023 - val_loss: 0.4972\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 785us/step - loss: 0.0023 - val_loss: 0.4973\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 697us/step - loss: 0.0022 - val_loss: 0.4975\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 743us/step - loss: 0.0021 - val_loss: 0.4985\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 737us/step - loss: 0.0021 - val_loss: 0.4985\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 767us/step - loss: 0.0020 - val_loss: 0.4979\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 714us/step - loss: 0.0019 - val_loss: 0.5010\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 761us/step - loss: 0.0019 - val_loss: 0.5021\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 689us/step - loss: 0.0018 - val_loss: 0.5040\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 0.0018 - val_loss: 0.5044\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 958us/step - loss: 0.0017 - val_loss: 0.5055\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 654us/step - loss: 0.0017 - val_loss: 0.5051\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 698us/step - loss: 0.0017 - val_loss: 0.5059\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 716us/step - loss: 0.0016 - val_loss: 0.5057\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 740us/step - loss: 0.0016 - val_loss: 0.5076\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 0.0015 - val_loss: 0.5088\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 695us/step - loss: 0.0015 - val_loss: 0.5088\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 689us/step - loss: 0.0015 - val_loss: 0.5109\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 781us/step - loss: 0.0014 - val_loss: 0.5120\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 763us/step - loss: 0.0014 - val_loss: 0.5115\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 788us/step - loss: 0.0014 - val_loss: 0.5133\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 776us/step - loss: 0.0013 - val_loss: 0.5137\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 685us/step - loss: 0.0013 - val_loss: 0.5131\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 728us/step - loss: 0.0013 - val_loss: 0.5146\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 752us/step - loss: 0.0012 - val_loss: 0.5158\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 0.0012 - val_loss: 0.5162\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 754us/step - loss: 0.0012 - val_loss: 0.5179\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 596us/step - loss: 0.0012 - val_loss: 0.5185\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 642us/step - loss: 0.0011 - val_loss: 0.5190\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 679us/step - loss: 0.0011 - val_loss: 0.5198\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 664us/step - loss: 0.0011 - val_loss: 0.5207\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 726us/step - loss: 0.0011 - val_loss: 0.5220\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 696us/step - loss: 0.0010 - val_loss: 0.5231\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 694us/step - loss: 0.0010 - val_loss: 0.5237\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 682us/step - loss: 0.0010 - val_loss: 0.5237\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 9.8180e-04 - val_loss: 0.5240\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 688us/step - loss: 9.6351e-04 - val_loss: 0.5254\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 9.4317e-04 - val_loss: 0.5256\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 652us/step - loss: 9.2310e-04 - val_loss: 0.5267\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 672us/step - loss: 9.0621e-04 - val_loss: 0.5272\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 8.8894e-04 - val_loss: 0.5276\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 802us/step - loss: 8.7019e-04 - val_loss: 0.5279\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 715us/step - loss: 8.5610e-04 - val_loss: 0.5293\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 626us/step - loss: 8.3841e-04 - val_loss: 0.5319\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 625us/step - loss: 8.2382e-04 - val_loss: 0.5326\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 612us/step - loss: 8.0887e-04 - val_loss: 0.5320\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 633us/step - loss: 7.9380e-04 - val_loss: 0.5318\n",
      "Epoch 125/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 657us/step - loss: 7.7882e-04 - val_loss: 0.5337\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 622us/step - loss: 7.6516e-04 - val_loss: 0.5347\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 618us/step - loss: 7.5022e-04 - val_loss: 0.5358\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 598us/step - loss: 7.3721e-04 - val_loss: 0.5363\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 566us/step - loss: 7.2495e-04 - val_loss: 0.5358\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 597us/step - loss: 7.1239e-04 - val_loss: 0.5381\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 677us/step - loss: 6.9909e-04 - val_loss: 0.5388\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 636us/step - loss: 6.8823e-04 - val_loss: 0.5390\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 659us/step - loss: 6.7517e-04 - val_loss: 0.5396\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 641us/step - loss: 6.6465e-04 - val_loss: 0.5395\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 621us/step - loss: 6.5241e-04 - val_loss: 0.5412\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 667us/step - loss: 6.4184e-04 - val_loss: 0.5422\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 567us/step - loss: 6.3110e-04 - val_loss: 0.5421\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 565us/step - loss: 6.2152e-04 - val_loss: 0.5432\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 6.1053e-04 - val_loss: 0.5435\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 785us/step - loss: 6.0055e-04 - val_loss: 0.5446\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 741us/step - loss: 5.9196e-04 - val_loss: 0.5451\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 718us/step - loss: 5.8246e-04 - val_loss: 0.5455\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 733us/step - loss: 5.7283e-04 - val_loss: 0.5462\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 745us/step - loss: 5.6305e-04 - val_loss: 0.5479\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 758us/step - loss: 5.5390e-04 - val_loss: 0.5484\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 729us/step - loss: 5.4448e-04 - val_loss: 0.5494\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 826us/step - loss: 5.3580e-04 - val_loss: 0.5498\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 728us/step - loss: 5.2784e-04 - val_loss: 0.5510\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 5.1918e-04 - val_loss: 0.5518\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 728us/step - loss: 5.1054e-04 - val_loss: 0.5528\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 699us/step - loss: 5.0166e-04 - val_loss: 0.5531\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 759us/step - loss: 4.9487e-04 - val_loss: 0.5536\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 811us/step - loss: 4.8675e-04 - val_loss: 0.5539\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 766us/step - loss: 4.7897e-04 - val_loss: 0.5542\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 770us/step - loss: 4.7149e-04 - val_loss: 0.5548\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 790us/step - loss: 4.6444e-04 - val_loss: 0.5563\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 846us/step - loss: 4.5745e-04 - val_loss: 0.5574\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 706us/step - loss: 4.5082e-04 - val_loss: 0.5574\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 822us/step - loss: 4.4423e-04 - val_loss: 0.5584\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 821us/step - loss: 4.3810e-04 - val_loss: 0.5596\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 814us/step - loss: 4.3123e-04 - val_loss: 0.5600\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 752us/step - loss: 4.2535e-04 - val_loss: 0.5614\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 723us/step - loss: 4.1877e-04 - val_loss: 0.5617\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 796us/step - loss: 4.1250e-04 - val_loss: 0.5627\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 770us/step - loss: 4.0711e-04 - val_loss: 0.5630\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 797us/step - loss: 4.0142e-04 - val_loss: 0.5632\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 756us/step - loss: 3.9554e-04 - val_loss: 0.5639\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 779us/step - loss: 3.9048e-04 - val_loss: 0.5644\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 781us/step - loss: 3.8510e-04 - val_loss: 0.5648\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 742us/step - loss: 3.8017e-04 - val_loss: 0.5644\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 737us/step - loss: 3.7434e-04 - val_loss: 0.5652\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 760us/step - loss: 3.6937e-04 - val_loss: 0.5661\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 771us/step - loss: 3.6519e-04 - val_loss: 0.5676\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 744us/step - loss: 3.5956e-04 - val_loss: 0.5682\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 714us/step - loss: 3.5453e-04 - val_loss: 0.5689\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 3.5004e-04 - val_loss: 0.5692\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 779us/step - loss: 3.4498e-04 - val_loss: 0.5699\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 3.4038e-04 - val_loss: 0.5708\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 3.3654e-04 - val_loss: 0.5713\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 761us/step - loss: 3.3223e-04 - val_loss: 0.5706\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 744us/step - loss: 3.2737e-04 - val_loss: 0.5715\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 741us/step - loss: 3.2317e-04 - val_loss: 0.5725\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 641us/step - loss: 3.1917e-04 - val_loss: 0.5731\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 618us/step - loss: 3.1537e-04 - val_loss: 0.5738\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 675us/step - loss: 3.1119e-04 - val_loss: 0.5748\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 664us/step - loss: 3.0660e-04 - val_loss: 0.5746\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 674us/step - loss: 3.0290e-04 - val_loss: 0.5751\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 669us/step - loss: 2.9929e-04 - val_loss: 0.5752\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 686us/step - loss: 2.9522e-04 - val_loss: 0.5756\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 715us/step - loss: 2.9183e-04 - val_loss: 0.5761\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 663us/step - loss: 2.8787e-04 - val_loss: 0.5765\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 729us/step - loss: 2.8429e-04 - val_loss: 0.5778\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 2.8107e-04 - val_loss: 0.5779\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 548us/step - loss: 2.7759e-04 - val_loss: 0.5791\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 600us/step - loss: 2.7407e-04 - val_loss: 0.5799\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 581us/step - loss: 2.7051e-04 - val_loss: 0.5805\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 583us/step - loss: 2.6734e-04 - val_loss: 0.5816\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 576us/step - loss: 2.6403e-04 - val_loss: 0.5820\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 574us/step - loss: 2.6107e-04 - val_loss: 0.5827\n",
      "Epoch 200/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 564us/step - loss: 2.5779e-04 - val_loss: 0.5837\n",
      "   (0, 15)     relu A\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.3328 - val_loss: 2.2661\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 776us/step - loss: 2.2089 - val_loss: 2.1748\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 2.0680 - val_loss: 2.0344\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 748us/step - loss: 1.8922 - val_loss: 1.8725\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 735us/step - loss: 1.6726 - val_loss: 1.6918\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 807us/step - loss: 1.4251 - val_loss: 1.4789\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 698us/step - loss: 1.1619 - val_loss: 1.2756\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 764us/step - loss: 0.9040 - val_loss: 1.0880\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 774us/step - loss: 0.7032 - val_loss: 0.9677\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 0.5535 - val_loss: 0.8654\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 729us/step - loss: 0.4285 - val_loss: 0.8087\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 0.3362 - val_loss: 0.7742\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 774us/step - loss: 0.2722 - val_loss: 0.7583\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 751us/step - loss: 0.2154 - val_loss: 0.7425\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 0.1799 - val_loss: 0.7354\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 746us/step - loss: 0.1435 - val_loss: 0.7203\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 0.1188 - val_loss: 0.7449\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 0.0958 - val_loss: 0.7274\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 0.0791 - val_loss: 0.7332\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 726us/step - loss: 0.0669 - val_loss: 0.7294\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 0.0548 - val_loss: 0.7528\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 739us/step - loss: 0.0464 - val_loss: 0.7487\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 736us/step - loss: 0.0411 - val_loss: 0.7570\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 767us/step - loss: 0.0345 - val_loss: 0.7717\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 729us/step - loss: 0.0304 - val_loss: 0.7757\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 730us/step - loss: 0.0269 - val_loss: 0.7663\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 778us/step - loss: 0.0234 - val_loss: 0.7853\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 746us/step - loss: 0.0208 - val_loss: 0.7898\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 728us/step - loss: 0.0189 - val_loss: 0.7941\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 775us/step - loss: 0.0169 - val_loss: 0.7987\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 770us/step - loss: 0.0156 - val_loss: 0.7912\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 744us/step - loss: 0.0142 - val_loss: 0.8175\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 742us/step - loss: 0.0130 - val_loss: 0.8277\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 731us/step - loss: 0.0121 - val_loss: 0.8219\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 762us/step - loss: 0.0110 - val_loss: 0.8270\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 791us/step - loss: 0.0103 - val_loss: 0.8284\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 823us/step - loss: 0.0095 - val_loss: 0.8324\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 602us/step - loss: 0.0088 - val_loss: 0.8422\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 0.0083 - val_loss: 0.8489\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 691us/step - loss: 0.0078 - val_loss: 0.8513\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 706us/step - loss: 0.0073 - val_loss: 0.8534\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 737us/step - loss: 0.0069 - val_loss: 0.8660\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 728us/step - loss: 0.0065 - val_loss: 0.8574\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 729us/step - loss: 0.0061 - val_loss: 0.8622\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 692us/step - loss: 0.0058 - val_loss: 0.8705\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 753us/step - loss: 0.0055 - val_loss: 0.8760\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 681us/step - loss: 0.0052 - val_loss: 0.8706\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 0.0050 - val_loss: 0.8820\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 577us/step - loss: 0.0047 - val_loss: 0.8833\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 585us/step - loss: 0.0045 - val_loss: 0.8852\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 621us/step - loss: 0.0043 - val_loss: 0.8916\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 592us/step - loss: 0.0041 - val_loss: 0.8941\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 613us/step - loss: 0.0039 - val_loss: 0.8961\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 700us/step - loss: 0.0038 - val_loss: 0.9038\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 669us/step - loss: 0.0036 - val_loss: 0.9032\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 607us/step - loss: 0.0035 - val_loss: 0.9028\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 570us/step - loss: 0.0033 - val_loss: 0.9084\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 628us/step - loss: 0.0032 - val_loss: 0.9076\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 606us/step - loss: 0.0031 - val_loss: 0.9147\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 609us/step - loss: 0.0029 - val_loss: 0.9198\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 624us/step - loss: 0.0028 - val_loss: 0.9227\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 644us/step - loss: 0.0027 - val_loss: 0.9239\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 639us/step - loss: 0.0026 - val_loss: 0.9243\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 637us/step - loss: 0.0025 - val_loss: 0.9281\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 612us/step - loss: 0.0025 - val_loss: 0.9340\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 585us/step - loss: 0.0024 - val_loss: 0.9368\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 584us/step - loss: 0.0023 - val_loss: 0.9361\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 590us/step - loss: 0.0022 - val_loss: 0.9371\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 598us/step - loss: 0.0021 - val_loss: 0.9413\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 595us/step - loss: 0.0021 - val_loss: 0.9466\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 715us/step - loss: 0.0020 - val_loss: 0.9441\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 756us/step - loss: 0.0019 - val_loss: 0.9478\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 0.0019 - val_loss: 0.9528\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 739us/step - loss: 0.0018 - val_loss: 0.9554\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 696us/step - loss: 0.0018 - val_loss: 0.9580\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 744us/step - loss: 0.0017 - val_loss: 0.9610\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 733us/step - loss: 0.0017 - val_loss: 0.9617\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 830us/step - loss: 0.0016 - val_loss: 0.9620\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 751us/step - loss: 0.0016 - val_loss: 0.9694\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 0.0015 - val_loss: 0.9711\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 804us/step - loss: 0.0015 - val_loss: 0.9719\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 0.0015 - val_loss: 0.9723\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 792us/step - loss: 0.0014 - val_loss: 0.9770\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 732us/step - loss: 0.0014 - val_loss: 0.9791\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 766us/step - loss: 0.0013 - val_loss: 0.9799\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 757us/step - loss: 0.0013 - val_loss: 0.9825\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 761us/step - loss: 0.0013 - val_loss: 0.9882\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 762us/step - loss: 0.0012 - val_loss: 0.9872\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 730us/step - loss: 0.0012 - val_loss: 0.9882\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 736us/step - loss: 0.0012 - val_loss: 0.9922\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 768us/step - loss: 0.0012 - val_loss: 0.9953\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 821us/step - loss: 0.0011 - val_loss: 0.9946\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 691us/step - loss: 0.0011 - val_loss: 0.9958\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 717us/step - loss: 0.0011 - val_loss: 0.9956\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 700us/step - loss: 0.0011 - val_loss: 0.9983\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 0.0010 - val_loss: 1.0017\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 718us/step - loss: 0.0010 - val_loss: 1.0044\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 717us/step - loss: 9.8134e-04 - val_loss: 1.0058\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 9.6078e-04 - val_loss: 1.0093\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 743us/step - loss: 9.3735e-04 - val_loss: 1.0103\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 698us/step - loss: 9.1735e-04 - val_loss: 1.0100\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 8.9684e-04 - val_loss: 1.0145\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 731us/step - loss: 8.7980e-04 - val_loss: 1.0174\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 728us/step - loss: 8.6026e-04 - val_loss: 1.0188\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 8.4116e-04 - val_loss: 1.0190\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 738us/step - loss: 8.2547e-04 - val_loss: 1.0208\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 702us/step - loss: 8.0845e-04 - val_loss: 1.0220\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 745us/step - loss: 7.9275e-04 - val_loss: 1.0265\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 724us/step - loss: 7.7635e-04 - val_loss: 1.0264\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 7.6097e-04 - val_loss: 1.0262\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 717us/step - loss: 7.4592e-04 - val_loss: 1.0284\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 755us/step - loss: 7.3126e-04 - val_loss: 1.0314\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 713us/step - loss: 7.1695e-04 - val_loss: 1.0331\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 851us/step - loss: 7.0106e-04 - val_loss: 1.0327\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 771us/step - loss: 6.8970e-04 - val_loss: 1.0320\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 6.7750e-04 - val_loss: 1.0368\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 735us/step - loss: 6.6220e-04 - val_loss: 1.0374\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 6.4927e-04 - val_loss: 1.0412\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 706us/step - loss: 6.3694e-04 - val_loss: 1.0433\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 716us/step - loss: 6.2650e-04 - val_loss: 1.0433\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 688us/step - loss: 6.1421e-04 - val_loss: 1.0461\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 642us/step - loss: 6.0307e-04 - val_loss: 1.0486\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 5.9258e-04 - val_loss: 1.0502-0\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 5.8303e-04 - val_loss: 1.0521\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 723us/step - loss: 5.7107e-04 - val_loss: 1.0534\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 746us/step - loss: 5.6128e-04 - val_loss: 1.0539\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 749us/step - loss: 5.5021e-04 - val_loss: 1.0563\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 691us/step - loss: 5.4128e-04 - val_loss: 1.0581\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 694us/step - loss: 5.3071e-04 - val_loss: 1.0592\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 692us/step - loss: 5.2280e-04 - val_loss: 1.0618\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 713us/step - loss: 5.1376e-04 - val_loss: 1.0619\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 667us/step - loss: 5.0440e-04 - val_loss: 1.0621\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 576us/step - loss: 4.9632e-04 - val_loss: 1.0653\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 603us/step - loss: 4.8762e-04 - val_loss: 1.0670\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 600us/step - loss: 4.7952e-04 - val_loss: 1.0684\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 612us/step - loss: 4.7225e-04 - val_loss: 1.0706\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 623us/step - loss: 4.6356e-04 - val_loss: 1.0721\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 604us/step - loss: 4.5641e-04 - val_loss: 1.0726\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 598us/step - loss: 4.4917e-04 - val_loss: 1.0753\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 559us/step - loss: 4.4150e-04 - val_loss: 1.0766\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 598us/step - loss: 4.3521e-04 - val_loss: 1.0769\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 618us/step - loss: 4.2797e-04 - val_loss: 1.0781\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 652us/step - loss: 4.2117e-04 - val_loss: 1.0768\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 625us/step - loss: 4.1383e-04 - val_loss: 1.0796\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 625us/step - loss: 4.0823e-04 - val_loss: 1.0826\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 755us/step - loss: 4.0199e-04 - val_loss: 1.0836\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 603us/step - loss: 3.9565e-04 - val_loss: 1.0850\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 622us/step - loss: 3.9016e-04 - val_loss: 1.0863\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 597us/step - loss: 3.8323e-04 - val_loss: 1.0874\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 593us/step - loss: 3.7725e-04 - val_loss: 1.0893\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 594us/step - loss: 3.7179e-04 - val_loss: 1.0902\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 593us/step - loss: 3.6616e-04 - val_loss: 1.0916\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 583us/step - loss: 3.6071e-04 - val_loss: 1.0931\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 683us/step - loss: 3.5569e-04 - val_loss: 1.0937\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 746us/step - loss: 3.5032e-04 - val_loss: 1.0942\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 728us/step - loss: 3.4496e-04 - val_loss: 1.0951\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 692us/step - loss: 3.4011e-04 - val_loss: 1.0962\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 693us/step - loss: 3.3506e-04 - val_loss: 1.0981\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 706us/step - loss: 3.3044e-04 - val_loss: 1.0998\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 715us/step - loss: 3.2565e-04 - val_loss: 1.1004\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 745us/step - loss: 3.2101e-04 - val_loss: 1.1017\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 694us/step - loss: 3.1737e-04 - val_loss: 1.1020\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 726us/step - loss: 3.1254e-04 - val_loss: 1.1042\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 718us/step - loss: 3.0819e-04 - val_loss: 1.1050\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 742us/step - loss: 3.0342e-04 - val_loss: 1.1054\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 723us/step - loss: 2.9970e-04 - val_loss: 1.1062\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 892us/step - loss: 2.9563e-04 - val_loss: 1.1068\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 818us/step - loss: 2.9111e-04 - val_loss: 1.1088\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 805us/step - loss: 2.8723e-04 - val_loss: 1.1102\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 975us/step - loss: 2.8335e-04 - val_loss: 1.1112\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 763us/step - loss: 2.7972e-04 - val_loss: 1.1116\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 2.7620e-04 - val_loss: 1.1127\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 726us/step - loss: 2.7266e-04 - val_loss: 1.1137\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 718us/step - loss: 2.6955e-04 - val_loss: 1.1149\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 691us/step - loss: 2.6532e-04 - val_loss: 1.1164\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 766us/step - loss: 2.6188e-04 - val_loss: 1.1181\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 697us/step - loss: 2.5888e-04 - val_loss: 1.1184\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 731us/step - loss: 2.5550e-04 - val_loss: 1.1192\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 673us/step - loss: 2.5224e-04 - val_loss: 1.1215\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 706us/step - loss: 2.4926e-04 - val_loss: 1.1228\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 678us/step - loss: 2.4566e-04 - val_loss: 1.1234\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 717us/step - loss: 2.4276e-04 - val_loss: 1.1240\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 690us/step - loss: 2.3975e-04 - val_loss: 1.1261\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 682us/step - loss: 2.3613e-04 - val_loss: 1.1274\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 2.3347e-04 - val_loss: 1.1279\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 715us/step - loss: 2.3045e-04 - val_loss: 1.1295\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 715us/step - loss: 2.2716e-04 - val_loss: 1.1300\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 705us/step - loss: 2.2458e-04 - val_loss: 1.1301\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 754us/step - loss: 2.2193e-04 - val_loss: 1.1304\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 704us/step - loss: 2.1911e-04 - val_loss: 1.1321\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 766us/step - loss: 2.1649e-04 - val_loss: 1.1340\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 705us/step - loss: 2.1356e-04 - val_loss: 1.1349\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 2.1115e-04 - val_loss: 1.1360\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 694us/step - loss: 2.0845e-04 - val_loss: 1.1366\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 2.0620e-04 - val_loss: 1.1377\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 741us/step - loss: 2.0367e-04 - val_loss: 1.1379\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 685us/step - loss: 2.0128e-04 - val_loss: 1.1395\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 696us/step - loss: 1.9873e-04 - val_loss: 1.1416\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 723us/step - loss: 1.9649e-04 - val_loss: 1.1430\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 1.9404e-04 - val_loss: 1.1443\n",
      "   (0, 15)     relu B\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 6.5765 - val_loss: 5.9713\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 6.1718 - val_loss: 5.5158\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 5.6734 - val_loss: 4.9556\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 5.0924 - val_loss: 4.3225\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 4.4421 - val_loss: 3.6441\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 3.7510 - val_loss: 3.0525\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 3.1811 - val_loss: 2.6609\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 2.7804 - val_loss: 2.4063\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 2.277 - 0s 290us/step - loss: 2.4073 - val_loss: 2.1452\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 349us/step - loss: 2.0633 - val_loss: 1.9270\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 1.8100 - val_loss: 1.8028\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 1.613 - 0s 330us/step - loss: 1.6566 - val_loss: 1.7212\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 1.5419 - val_loss: 1.6075\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 1.4025 - val_loss: 1.4757\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 1.2685 - val_loss: 1.3638\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 1.1567 - val_loss: 1.2716\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 1.0608 - val_loss: 1.2033\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.9719 - val_loss: 1.1359\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.8939 - val_loss: 1.0708\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.8267 - val_loss: 1.0171\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 0.7648 - val_loss: 0.9723\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.7117 - val_loss: 0.9351\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.6615 - val_loss: 0.9093\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.6175 - val_loss: 0.8839\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 400us/step - loss: 0.5745 - val_loss: 0.8557\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 0.5366 - val_loss: 0.8308\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.5006 - val_loss: 0.8082\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 0.4667 - val_loss: 0.7927\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 310us/step - loss: 0.4365 - val_loss: 0.7788\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.4071 - val_loss: 0.7679\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.3782 - val_loss: 0.7510\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.3538 - val_loss: 0.7372\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.3269 - val_loss: 0.7341\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.3040 - val_loss: 0.7334\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.2822 - val_loss: 0.7229\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.2619 - val_loss: 0.7069\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.2431 - val_loss: 0.7017\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 0.2249 - val_loss: 0.6901\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.2083 - val_loss: 0.6862\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.1943 - val_loss: 0.6873\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 397us/step - loss: 0.1794 - val_loss: 0.6827\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 358us/step - loss: 0.1659 - val_loss: 0.6727\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 381us/step - loss: 0.1539 - val_loss: 0.6608\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.1427 - val_loss: 0.6545\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 371us/step - loss: 0.1321 - val_loss: 0.6546\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 0.1223 - val_loss: 0.6565\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 358us/step - loss: 0.1136 - val_loss: 0.6502\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 0.1063 - val_loss: 0.6457\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 343us/step - loss: 0.0990 - val_loss: 0.6435\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 388us/step - loss: 0.0928 - val_loss: 0.6446\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.0861 - val_loss: 0.6444\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 387us/step - loss: 0.0811 - val_loss: 0.6464\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 0.0760 - val_loss: 0.6470\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.0718 - val_loss: 0.6474\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 0.0672 - val_loss: 0.6431\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.0632 - val_loss: 0.6432\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 360us/step - loss: 0.0597 - val_loss: 0.6458\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.0564 - val_loss: 0.6491\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 385us/step - loss: 0.0533 - val_loss: 0.6500\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 0.0505 - val_loss: 0.6476\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 375us/step - loss: 0.0480 - val_loss: 0.6446\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 372us/step - loss: 0.0455 - val_loss: 0.6448\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 358us/step - loss: 0.0433 - val_loss: 0.6445\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 409us/step - loss: 0.0411 - val_loss: 0.6457\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 0.0392 - val_loss: 0.6479\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 366us/step - loss: 0.0374 - val_loss: 0.6463\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 363us/step - loss: 0.0358 - val_loss: 0.6452\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.0343 - val_loss: 0.6465\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 390us/step - loss: 0.0326 - val_loss: 0.6468\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 355us/step - loss: 0.0313 - val_loss: 0.6477\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 372us/step - loss: 0.0300 - val_loss: 0.6473\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0287 - val_loss: 0.6487\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 374us/step - loss: 0.0275 - val_loss: 0.6509\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 0.0263 - val_loss: 0.6510\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 395us/step - loss: 0.0253 - val_loss: 0.6506\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 0.0244 - val_loss: 0.6496\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 0.0234 - val_loss: 0.6501\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 385us/step - loss: 0.0225 - val_loss: 0.6520\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.0217 - val_loss: 0.6542\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 404us/step - loss: 0.0209 - val_loss: 0.6541\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.0202 - val_loss: 0.6537\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 381us/step - loss: 0.0195 - val_loss: 0.6543\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.0189 - val_loss: 0.6535\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.0182 - val_loss: 0.6534\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 385us/step - loss: 0.0177 - val_loss: 0.6545\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 0.0171 - val_loss: 0.6559\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 379us/step - loss: 0.0166 - val_loss: 0.6568\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 0.0161 - val_loss: 0.6579\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 367us/step - loss: 0.0156 - val_loss: 0.6563\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 0.0151 - val_loss: 0.6566\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 356us/step - loss: 0.0147 - val_loss: 0.6563\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 367us/step - loss: 0.0143 - val_loss: 0.6583\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 0.0139 - val_loss: 0.6603\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 377us/step - loss: 0.0135 - val_loss: 0.6613\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.0131 - val_loss: 0.6613\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 402us/step - loss: 0.0128 - val_loss: 0.6607\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.0124 - val_loss: 0.6609\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 382us/step - loss: 0.0121 - val_loss: 0.6607\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.0118 - val_loss: 0.6618\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 0.0115 - val_loss: 0.6630\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 366us/step - loss: 0.0112 - val_loss: 0.6636\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.0109 - val_loss: 0.6648\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 356us/step - loss: 0.0107 - val_loss: 0.6652\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 0.0104 - val_loss: 0.6662\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 421us/step - loss: 0.0101 - val_loss: 0.6669\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 388us/step - loss: 0.0099 - val_loss: 0.6670\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 362us/step - loss: 0.0097 - val_loss: 0.6671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 420us/step - loss: 0.0095 - val_loss: 0.6674\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 364us/step - loss: 0.0093 - val_loss: 0.6672\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 385us/step - loss: 0.0090 - val_loss: 0.6682\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 0.0089 - val_loss: 0.6698\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 0.0087 - val_loss: 0.6713\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 0.0085 - val_loss: 0.6720\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 0.0083 - val_loss: 0.6712\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 354us/step - loss: 0.0081 - val_loss: 0.6722\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 0.0079 - val_loss: 0.6723\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 0.0078 - val_loss: 0.6727\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 375us/step - loss: 0.0076 - val_loss: 0.6728\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 375us/step - loss: 0.0075 - val_loss: 0.6740\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 0.0073 - val_loss: 0.6750\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 0.0072 - val_loss: 0.6758\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 389us/step - loss: 0.0070 - val_loss: 0.6768\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 0.0069 - val_loss: 0.6775\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 0.0068 - val_loss: 0.6773\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 363us/step - loss: 0.0066 - val_loss: 0.6773\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 349us/step - loss: 0.0065 - val_loss: 0.6778\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 385us/step - loss: 0.0064 - val_loss: 0.6792\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.0063 - val_loss: 0.6802\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 398us/step - loss: 0.0062 - val_loss: 0.6809\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0060 - val_loss: 0.6817\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 370us/step - loss: 0.0059 - val_loss: 0.6823\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 0.0058 - val_loss: 0.6824\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 369us/step - loss: 0.0057 - val_loss: 0.6824\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 0.0056 - val_loss: 0.6830\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.0055 - val_loss: 0.6843\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 362us/step - loss: 0.0054 - val_loss: 0.6840\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.0054 - val_loss: 0.6844\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 364us/step - loss: 0.0053 - val_loss: 0.6844\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0052 - val_loss: 0.6850\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 358us/step - loss: 0.0051 - val_loss: 0.6860\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 393us/step - loss: 0.0050 - val_loss: 0.6869\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.0049 - val_loss: 0.6874\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 372us/step - loss: 0.0048 - val_loss: 0.6876\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 363us/step - loss: 0.0048 - val_loss: 0.6890\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 795us/step - loss: 0.0047 - val_loss: 0.6895\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 749us/step - loss: 0.0046 - val_loss: 0.6894\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 671us/step - loss: 0.0045 - val_loss: 0.6903\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 421us/step - loss: 0.0045 - val_loss: 0.6900\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 386us/step - loss: 0.0044 - val_loss: 0.6906\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 399us/step - loss: 0.0043 - val_loss: 0.6916\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 371us/step - loss: 0.0043 - val_loss: 0.6923\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 389us/step - loss: 0.0042 - val_loss: 0.6930\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.0041 - val_loss: 0.6930\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 371us/step - loss: 0.0041 - val_loss: 0.6938\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 368us/step - loss: 0.0040 - val_loss: 0.6947\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 401us/step - loss: 0.0040 - val_loss: 0.6945\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 398us/step - loss: 0.0039 - val_loss: 0.6947\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.0038 - val_loss: 0.6955\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0038 - val_loss: 0.6966\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 382us/step - loss: 0.0037 - val_loss: 0.6976\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 394us/step - loss: 0.0037 - val_loss: 0.6974\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 371us/step - loss: 0.0036 - val_loss: 0.6979\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 370us/step - loss: 0.0036 - val_loss: 0.6980\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 370us/step - loss: 0.0035 - val_loss: 0.6981\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 393us/step - loss: 0.0035 - val_loss: 0.6981\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 385us/step - loss: 0.0034 - val_loss: 0.6990\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 368us/step - loss: 0.0034 - val_loss: 0.6994\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 0.0033 - val_loss: 0.7000\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 0.0033 - val_loss: 0.7005\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 0.0032 - val_loss: 0.7002\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.0032 - val_loss: 0.7001\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.0031 - val_loss: 0.7002\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.0031 - val_loss: 0.7005\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 355us/step - loss: 0.0030 - val_loss: 0.7010\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 354us/step - loss: 0.0030 - val_loss: 0.7017\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 373us/step - loss: 0.0030 - val_loss: 0.7023\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 0.0029 - val_loss: 0.7026\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 0.0029 - val_loss: 0.7031\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 0.0028 - val_loss: 0.7042\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 0.0028 - val_loss: 0.7053\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.0028 - val_loss: 0.7056\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0027 - val_loss: 0.7058\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 0.0027 - val_loss: 0.7063\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 275us/step - loss: 0.0027 - val_loss: 0.7067\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.0026 - val_loss: 0.7071\n",
      "Epoch 186/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 307us/step - loss: 0.0026 - val_loss: 0.7078\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 0.0026 - val_loss: 0.7082\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0025 - val_loss: 0.7085\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0025 - val_loss: 0.7090\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 0.0025 - val_loss: 0.7096\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.0024 - val_loss: 0.7094\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 376us/step - loss: 0.0024 - val_loss: 0.7103\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.0024 - val_loss: 0.7111\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 0.0024 - val_loss: 0.7117\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 0.0023 - val_loss: 0.7116\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 0.0023 - val_loss: 0.7115\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.0023 - val_loss: 0.7121\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 0.0023 - val_loss: 0.7129\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 0.0022 - val_loss: 0.7136\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 273us/step - loss: 0.0022 - val_loss: 0.7136\n",
      "   (0, 15)     relu C\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 4.5582 - val_loss: 4.1226\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 552us/step - loss: 3.6597 - val_loss: 3.4585\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 533us/step - loss: 2.8371 - val_loss: 2.7878\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 655us/step - loss: 2.0570 - val_loss: 2.0237\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 1.4022 - val_loss: 1.4637\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9720 - val_loss: 1.2009\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 778us/step - loss: 0.7190 - val_loss: 1.0384\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 752us/step - loss: 0.5528 - val_loss: 0.9216\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 713us/step - loss: 0.4445 - val_loss: 0.8378\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 702us/step - loss: 0.3681 - val_loss: 0.7866\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 737us/step - loss: 0.3071 - val_loss: 0.7360\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 662us/step - loss: 0.2622 - val_loss: 0.7000\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 735us/step - loss: 0.2272 - val_loss: 0.6700\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 663us/step - loss: 0.1918 - val_loss: 0.6551\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 0.1657 - val_loss: 0.6254\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 712us/step - loss: 0.1386 - val_loss: 0.6167\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 774us/step - loss: 0.1195 - val_loss: 0.5957\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 769us/step - loss: 0.1047 - val_loss: 0.5880\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 712us/step - loss: 0.0883 - val_loss: 0.5705\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 0.0777 - val_loss: 0.5714\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 769us/step - loss: 0.0664 - val_loss: 0.5555\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 785us/step - loss: 0.0586 - val_loss: 0.5572\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 758us/step - loss: 0.0526 - val_loss: 0.5534\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 740us/step - loss: 0.0470 - val_loss: 0.5449\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 0.0423 - val_loss: 0.5518\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 751us/step - loss: 0.0381 - val_loss: 0.5472\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 714us/step - loss: 0.0346 - val_loss: 0.5469\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 739us/step - loss: 0.0317 - val_loss: 0.5562\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 751us/step - loss: 0.0296 - val_loss: 0.5434\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 665us/step - loss: 0.0268 - val_loss: 0.5440\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 696us/step - loss: 0.0250 - val_loss: 0.5441\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 0.0231 - val_loss: 0.5446\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 713us/step - loss: 0.0215 - val_loss: 0.5489\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 0.0201 - val_loss: 0.5512\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 665us/step - loss: 0.0190 - val_loss: 0.5472\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 733us/step - loss: 0.0179 - val_loss: 0.5512\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 715us/step - loss: 0.0166 - val_loss: 0.5475\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 788us/step - loss: 0.0157 - val_loss: 0.5479\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 0.0147 - val_loss: 0.5462\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 748us/step - loss: 0.0140 - val_loss: 0.5474\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 693us/step - loss: 0.0133 - val_loss: 0.5525\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 0.0126 - val_loss: 0.5495\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 804us/step - loss: 0.0120 - val_loss: 0.5527\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 769us/step - loss: 0.0114 - val_loss: 0.5579\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 815us/step - loss: 0.0109 - val_loss: 0.5548\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 791us/step - loss: 0.0103 - val_loss: 0.5550\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 799us/step - loss: 0.0098 - val_loss: 0.5534\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 889us/step - loss: 0.0094 - val_loss: 0.5577\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 735us/step - loss: 0.0090 - val_loss: 0.5578\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 0.0086 - val_loss: 0.5586\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 759us/step - loss: 0.0083 - val_loss: 0.5593\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 0.0079 - val_loss: 0.5606\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 714us/step - loss: 0.0076 - val_loss: 0.5605\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 689us/step - loss: 0.0073 - val_loss: 0.5575\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 740us/step - loss: 0.0071 - val_loss: 0.5592\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 801us/step - loss: 0.0068 - val_loss: 0.5634\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 732us/step - loss: 0.0065 - val_loss: 0.5674\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 738us/step - loss: 0.0063 - val_loss: 0.5701\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 674us/step - loss: 0.0061 - val_loss: 0.5673\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 781us/step - loss: 0.0058 - val_loss: 0.5669\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 758us/step - loss: 0.0057 - val_loss: 0.5679\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 716us/step - loss: 0.0055 - val_loss: 0.5681\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 753us/step - loss: 0.0053 - val_loss: 0.5715\n",
      "Epoch 64/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 763us/step - loss: 0.0051 - val_loss: 0.5692\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 749us/step - loss: 0.0050 - val_loss: 0.5700\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 676us/step - loss: 0.0048 - val_loss: 0.5729\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 677us/step - loss: 0.0047 - val_loss: 0.5755\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 685us/step - loss: 0.0045 - val_loss: 0.5737\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 650us/step - loss: 0.0044 - val_loss: 0.5769\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 748us/step - loss: 0.0043 - val_loss: 0.5771\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 695us/step - loss: 0.0041 - val_loss: 0.5759\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 680us/step - loss: 0.0040 - val_loss: 0.5779\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 675us/step - loss: 0.0039 - val_loss: 0.5782\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 692us/step - loss: 0.0038 - val_loss: 0.5793\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 689us/step - loss: 0.0037 - val_loss: 0.5796\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 724us/step - loss: 0.0036 - val_loss: 0.5805\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 755us/step - loss: 0.0035 - val_loss: 0.5837\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 698us/step - loss: 0.0034 - val_loss: 0.5853\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 685us/step - loss: 0.0033 - val_loss: 0.5857\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 746us/step - loss: 0.0032 - val_loss: 0.5860\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 589us/step - loss: 0.0031 - val_loss: 0.5869\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 586us/step - loss: 0.0031 - val_loss: 0.5862\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 566us/step - loss: 0.0030 - val_loss: 0.5909\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 564us/step - loss: 0.0029 - val_loss: 0.5935\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 577us/step - loss: 0.0029 - val_loss: 0.5906\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 598us/step - loss: 0.0028 - val_loss: 0.5894\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 579us/step - loss: 0.0027 - val_loss: 0.5894\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 602us/step - loss: 0.0027 - val_loss: 0.5913\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 600us/step - loss: 0.0026 - val_loss: 0.5921\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 612us/step - loss: 0.0025 - val_loss: 0.5926\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 604us/step - loss: 0.0025 - val_loss: 0.5915\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 575us/step - loss: 0.0024 - val_loss: 0.5938\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 555us/step - loss: 0.0024 - val_loss: 0.5951\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 565us/step - loss: 0.0023 - val_loss: 0.5960\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 603us/step - loss: 0.0023 - val_loss: 0.5975\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 560us/step - loss: 0.0022 - val_loss: 0.5966\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 591us/step - loss: 0.0022 - val_loss: 0.5963\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 560us/step - loss: 0.0021 - val_loss: 0.5981\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 571us/step - loss: 0.0021 - val_loss: 0.5985\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 647us/step - loss: 0.0020 - val_loss: 0.5993\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 598us/step - loss: 0.0020 - val_loss: 0.5998\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 612us/step - loss: 0.0019 - val_loss: 0.6014\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 605us/step - loss: 0.0019 - val_loss: 0.6002\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 641us/step - loss: 0.0019 - val_loss: 0.6017\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 597us/step - loss: 0.0018 - val_loss: 0.6029\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 628us/step - loss: 0.0018 - val_loss: 0.6038\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 580us/step - loss: 0.0018 - val_loss: 0.6051\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 629us/step - loss: 0.0017 - val_loss: 0.6054\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 577us/step - loss: 0.0017 - val_loss: 0.6068\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 625us/step - loss: 0.0017 - val_loss: 0.6061\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 582us/step - loss: 0.0016 - val_loss: 0.6069\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 566us/step - loss: 0.0016 - val_loss: 0.6085\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 559us/step - loss: 0.0016 - val_loss: 0.6086\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 555us/step - loss: 0.0015 - val_loss: 0.6089\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 643us/step - loss: 0.0015 - val_loss: 0.6109\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 0.0015 - val_loss: 0.6119\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 765us/step - loss: 0.0015 - val_loss: 0.6108\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 758us/step - loss: 0.0014 - val_loss: 0.6120\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 0.0014 - val_loss: 0.6128\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 692us/step - loss: 0.0014 - val_loss: 0.6133\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 0.0014 - val_loss: 0.6146\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 728us/step - loss: 0.0013 - val_loss: 0.6152\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 683us/step - loss: 0.0013 - val_loss: 0.6159\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 0.0013 - val_loss: 0.6168\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 0.0013 - val_loss: 0.6170\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 0.0013 - val_loss: 0.6164\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 779us/step - loss: 0.0012 - val_loss: 0.6176\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 757us/step - loss: 0.0012 - val_loss: 0.6184\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 741us/step - loss: 0.0012 - val_loss: 0.6201\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 690us/step - loss: 0.0012 - val_loss: 0.6200\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 854us/step - loss: 0.0012 - val_loss: 0.6200\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 758us/step - loss: 0.0011 - val_loss: 0.6204\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 784us/step - loss: 0.0011 - val_loss: 0.6200\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 774us/step - loss: 0.0011 - val_loss: 0.6219\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 0.0011 - val_loss: 0.6220\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 712us/step - loss: 0.0011 - val_loss: 0.6224\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 689us/step - loss: 0.0011 - val_loss: 0.6240\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 745us/step - loss: 0.0010 - val_loss: 0.6241\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 706us/step - loss: 0.0010 - val_loss: 0.6245\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 0.0010 - val_loss: 0.6250\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 744us/step - loss: 9.8966e-04 - val_loss: 0.6251\n",
      "Epoch 142/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 710us/step - loss: 9.7203e-04 - val_loss: 0.6257\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 9.5916e-04 - val_loss: 0.6266\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 658us/step - loss: 9.4548e-04 - val_loss: 0.6272\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 722us/step - loss: 9.3161e-04 - val_loss: 0.6281\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 704us/step - loss: 9.1772e-04 - val_loss: 0.6293\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 661us/step - loss: 9.0464e-04 - val_loss: 0.6300\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 733us/step - loss: 8.9054e-04 - val_loss: 0.6300\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 679us/step - loss: 8.7854e-04 - val_loss: 0.6303\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 656us/step - loss: 8.6554e-04 - val_loss: 0.6305\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 736us/step - loss: 8.5458e-04 - val_loss: 0.6309\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 698us/step - loss: 8.4199e-04 - val_loss: 0.6316\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 706us/step - loss: 8.2979e-04 - val_loss: 0.6328\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 8.1930e-04 - val_loss: 0.6340\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 782us/step - loss: 8.0717e-04 - val_loss: 0.6348\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 771us/step - loss: 7.9756e-04 - val_loss: 0.6350\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 799us/step - loss: 7.8524e-04 - val_loss: 0.6358\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 784us/step - loss: 7.7404e-04 - val_loss: 0.6371\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 764us/step - loss: 7.6373e-04 - val_loss: 0.6367\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 794us/step - loss: 7.5420e-04 - val_loss: 0.6364\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 718us/step - loss: 7.4245e-04 - val_loss: 0.6365\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 749us/step - loss: 7.3298e-04 - val_loss: 0.6376\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 696us/step - loss: 7.2443e-04 - val_loss: 0.6389\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 619us/step - loss: 7.1429e-04 - val_loss: 0.6396\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 7.0458e-04 - val_loss: 0.6396\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 757us/step - loss: 6.9555e-04 - val_loss: 0.6408\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 909us/step - loss: 6.8568e-04 - val_loss: 0.6412\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 739us/step - loss: 6.7803e-04 - val_loss: 0.6412\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 692us/step - loss: 6.6875e-04 - val_loss: 0.6420\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 668us/step - loss: 6.6069e-04 - val_loss: 0.6416\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 730us/step - loss: 6.5073e-04 - val_loss: 0.6427\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 695us/step - loss: 6.4376e-04 - val_loss: 0.6442\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 683us/step - loss: 6.3527e-04 - val_loss: 0.6445\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 699us/step - loss: 6.2676e-04 - val_loss: 0.6448\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 655us/step - loss: 6.1935e-04 - val_loss: 0.6446\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 6.1203e-04 - val_loss: 0.6446\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 702us/step - loss: 6.0379e-04 - val_loss: 0.6447\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 5.9649e-04 - val_loss: 0.6462\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 690us/step - loss: 5.8935e-04 - val_loss: 0.6468\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 640us/step - loss: 5.8213e-04 - val_loss: 0.6474\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 685us/step - loss: 5.7474e-04 - val_loss: 0.6473\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 5.6826e-04 - val_loss: 0.6473\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 737us/step - loss: 5.6185e-04 - val_loss: 0.6483\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 612us/step - loss: 5.5452e-04 - val_loss: 0.6486\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 674us/step - loss: 5.4736e-04 - val_loss: 0.6486\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 724us/step - loss: 5.4041e-04 - val_loss: 0.6488\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 664us/step - loss: 5.3445e-04 - val_loss: 0.6491\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 682us/step - loss: 5.2791e-04 - val_loss: 0.6492\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 688us/step - loss: 5.2137e-04 - val_loss: 0.6501\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 677us/step - loss: 5.1539e-04 - val_loss: 0.6508\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 675us/step - loss: 5.0944e-04 - val_loss: 0.6518\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 678us/step - loss: 5.0356e-04 - val_loss: 0.6525\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 664us/step - loss: 4.9790e-04 - val_loss: 0.6524\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 683us/step - loss: 4.9223e-04 - val_loss: 0.6529\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 677us/step - loss: 4.8612e-04 - val_loss: 0.6535\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 667us/step - loss: 4.8130e-04 - val_loss: 0.6540\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 4.7451e-04 - val_loss: 0.6545\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 546us/step - loss: 4.6947e-04 - val_loss: 0.6555\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 636us/step - loss: 4.6467e-04 - val_loss: 0.6557\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 617us/step - loss: 4.5929e-04 - val_loss: 0.6562\n",
      "   (0, 15)     tanh A\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.2486 - val_loss: 2.1057\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 594us/step - loss: 1.9518 - val_loss: 1.8837\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 632us/step - loss: 1.6822 - val_loss: 1.6719\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 627us/step - loss: 1.4384 - val_loss: 1.4893\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 600us/step - loss: 1.2203 - val_loss: 1.3233\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 631us/step - loss: 1.0485 - val_loss: 1.1891\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 592us/step - loss: 0.8843 - val_loss: 1.0745\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 627us/step - loss: 0.7595 - val_loss: 0.9856\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 572us/step - loss: 0.6578 - val_loss: 0.9240\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 590us/step - loss: 0.5748 - val_loss: 0.8540\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 578us/step - loss: 0.4996 - val_loss: 0.8257\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 0.4446 - val_loss: 0.7891\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 790us/step - loss: 0.3978 - val_loss: 0.7601\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 838us/step - loss: 0.3527 - val_loss: 0.7397\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 731us/step - loss: 0.3162 - val_loss: 0.7111\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 747us/step - loss: 0.2810 - val_loss: 0.7031\n",
      "Epoch 17/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 712us/step - loss: 0.2542 - val_loss: 0.6835\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 748us/step - loss: 0.2292 - val_loss: 0.6733\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 739us/step - loss: 0.2051 - val_loss: 0.6633\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 0.1825 - val_loss: 0.6499\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 735us/step - loss: 0.1658 - val_loss: 0.6474\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 717us/step - loss: 0.1487 - val_loss: 0.6325\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 749us/step - loss: 0.1361 - val_loss: 0.6287\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 702us/step - loss: 0.1231 - val_loss: 0.6231\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 722us/step - loss: 0.1131 - val_loss: 0.6122\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 0.1036 - val_loss: 0.6166\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 858us/step - loss: 0.0963 - val_loss: 0.6067\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 787us/step - loss: 0.0891 - val_loss: 0.6119\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 801us/step - loss: 0.0828 - val_loss: 0.6078\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 0.0770 - val_loss: 0.6042\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 0.0719 - val_loss: 0.6002\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 718us/step - loss: 0.0676 - val_loss: 0.6022\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 0.0637 - val_loss: 0.6032\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 732us/step - loss: 0.0599 - val_loss: 0.5996\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 693us/step - loss: 0.0565 - val_loss: 0.5945\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 710us/step - loss: 0.0535 - val_loss: 0.6037\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 736us/step - loss: 0.0505 - val_loss: 0.6004\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 689us/step - loss: 0.0480 - val_loss: 0.5960\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 706us/step - loss: 0.0456 - val_loss: 0.6013\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 737us/step - loss: 0.0435 - val_loss: 0.5968\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 693us/step - loss: 0.0416 - val_loss: 0.6047\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 692us/step - loss: 0.0398 - val_loss: 0.6021\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 738us/step - loss: 0.0378 - val_loss: 0.6001\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 713us/step - loss: 0.0362 - val_loss: 0.6006\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 694us/step - loss: 0.0347 - val_loss: 0.6040\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 683us/step - loss: 0.0333 - val_loss: 0.6028\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 0.0319 - val_loss: 0.6054\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 698us/step - loss: 0.0307 - val_loss: 0.6054\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 0.0296 - val_loss: 0.6073\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 740us/step - loss: 0.0285 - val_loss: 0.6090\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 0.0275 - val_loss: 0.6072\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 0.0265 - val_loss: 0.6086\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 693us/step - loss: 0.0256 - val_loss: 0.6128\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 733us/step - loss: 0.0247 - val_loss: 0.6107\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 0.0239 - val_loss: 0.6125\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 753us/step - loss: 0.0231 - val_loss: 0.6127\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 728us/step - loss: 0.0224 - val_loss: 0.6140\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 731us/step - loss: 0.0217 - val_loss: 0.6187\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 705us/step - loss: 0.0210 - val_loss: 0.6148\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 747us/step - loss: 0.0204 - val_loss: 0.6153\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 699us/step - loss: 0.0198 - val_loss: 0.6211\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 0.0192 - val_loss: 0.6198\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 0.0187 - val_loss: 0.6171\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 0.0181 - val_loss: 0.6213\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 669us/step - loss: 0.0176 - val_loss: 0.6246\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 702us/step - loss: 0.0172 - val_loss: 0.6217\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 764us/step - loss: 0.0167 - val_loss: 0.6226\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 0.0163 - val_loss: 0.6253\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 730us/step - loss: 0.0158 - val_loss: 0.6255\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 741us/step - loss: 0.0154 - val_loss: 0.6297\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 776us/step - loss: 0.0151 - val_loss: 0.6296\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 731us/step - loss: 0.0147 - val_loss: 0.6300\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 730us/step - loss: 0.0143 - val_loss: 0.6306\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 764us/step - loss: 0.0140 - val_loss: 0.6322\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 0.0137 - val_loss: 0.6336\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 795us/step - loss: 0.0133 - val_loss: 0.6368\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 643us/step - loss: 0.0130 - val_loss: 0.6363\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 775us/step - loss: 0.0127 - val_loss: 0.6387\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 0.0125 - val_loss: 0.6419\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 614us/step - loss: 0.0122 - val_loss: 0.6405\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 683us/step - loss: 0.0119 - val_loss: 0.6415\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 699us/step - loss: 0.0116 - val_loss: 0.6451\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 691us/step - loss: 0.0114 - val_loss: 0.6453\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 0.0111 - val_loss: 0.6454\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 701us/step - loss: 0.0109 - val_loss: 0.6475\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 688us/step - loss: 0.0107 - val_loss: 0.6468\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 0.0105 - val_loss: 0.6460\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 691us/step - loss: 0.0103 - val_loss: 0.6494\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 0.0100 - val_loss: 0.6529\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 695us/step - loss: 0.0099 - val_loss: 0.6536\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 715us/step - loss: 0.0097 - val_loss: 0.6520\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 0.0095 - val_loss: 0.6555\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 0.0093 - val_loss: 0.6543\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 623us/step - loss: 0.0091 - val_loss: 0.6544\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 618us/step - loss: 0.0090 - val_loss: 0.6562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 670us/step - loss: 0.0088 - val_loss: 0.6559\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 643us/step - loss: 0.0086 - val_loss: 0.6578\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 595us/step - loss: 0.0085 - val_loss: 0.6586\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 608us/step - loss: 0.0083 - val_loss: 0.6612\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 621us/step - loss: 0.0082 - val_loss: 0.6622\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 643us/step - loss: 0.0080 - val_loss: 0.6625\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 669us/step - loss: 0.0079 - val_loss: 0.6635\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 630us/step - loss: 0.0078 - val_loss: 0.6657\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 647us/step - loss: 0.0076 - val_loss: 0.6652\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 614us/step - loss: 0.0075 - val_loss: 0.6670\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 631us/step - loss: 0.0074 - val_loss: 0.6681\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 654us/step - loss: 0.0073 - val_loss: 0.6691\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 641us/step - loss: 0.0071 - val_loss: 0.6702\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 620us/step - loss: 0.0070 - val_loss: 0.6713\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 586us/step - loss: 0.0069 - val_loss: 0.6738\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 568us/step - loss: 0.0068 - val_loss: 0.6740\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 568us/step - loss: 0.0067 - val_loss: 0.6743\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 642us/step - loss: 0.0066 - val_loss: 0.6762\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 623us/step - loss: 0.0064 - val_loss: 0.6778\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 624us/step - loss: 0.0063 - val_loss: 0.6781\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 627us/step - loss: 0.0062 - val_loss: 0.6788\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 622us/step - loss: 0.0061 - val_loss: 0.6797\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 0.0060 - val_loss: 0.6812\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 597us/step - loss: 0.0059 - val_loss: 0.6837\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 609us/step - loss: 0.0058 - val_loss: 0.6837\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 610us/step - loss: 0.0057 - val_loss: 0.6841\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 649us/step - loss: 0.0056 - val_loss: 0.6864\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 610us/step - loss: 0.0056 - val_loss: 0.6877\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 598us/step - loss: 0.0055 - val_loss: 0.6883\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 602us/step - loss: 0.0054 - val_loss: 0.6898\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 596us/step - loss: 0.0053 - val_loss: 0.6905\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 607us/step - loss: 0.0052 - val_loss: 0.6916\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 614us/step - loss: 0.0051 - val_loss: 0.6932\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 613us/step - loss: 0.0051 - val_loss: 0.6951\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 697us/step - loss: 0.0050 - val_loss: 0.6958\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 0.0049 - val_loss: 0.6969\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 743us/step - loss: 0.0048 - val_loss: 0.6969\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 741us/step - loss: 0.0048 - val_loss: 0.6973\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 763us/step - loss: 0.0047 - val_loss: 0.6987\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 706us/step - loss: 0.0046 - val_loss: 0.6996\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 751us/step - loss: 0.0046 - val_loss: 0.7013\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 756us/step - loss: 0.0045 - val_loss: 0.7027\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 748us/step - loss: 0.0045 - val_loss: 0.7045\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 741us/step - loss: 0.0044 - val_loss: 0.7040\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 694us/step - loss: 0.0043 - val_loss: 0.7048\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 0.0043 - val_loss: 0.7057\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 706us/step - loss: 0.0042 - val_loss: 0.7080\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 713us/step - loss: 0.0042 - val_loss: 0.7081\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 718us/step - loss: 0.0041 - val_loss: 0.7087\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 722us/step - loss: 0.0041 - val_loss: 0.7097\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 745us/step - loss: 0.0040 - val_loss: 0.7117\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 746us/step - loss: 0.0039 - val_loss: 0.7124\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 762us/step - loss: 0.0039 - val_loss: 0.7134\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 0.0038 - val_loss: 0.7136\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 713us/step - loss: 0.0038 - val_loss: 0.7138\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 0.0038 - val_loss: 0.7145\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 714us/step - loss: 0.0037 - val_loss: 0.7150\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 705us/step - loss: 0.0037 - val_loss: 0.7154\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 760us/step - loss: 0.0036 - val_loss: 0.7159\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 710us/step - loss: 0.0036 - val_loss: 0.7171\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 735us/step - loss: 0.0035 - val_loss: 0.7181\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 743us/step - loss: 0.0035 - val_loss: 0.7184\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 712us/step - loss: 0.0034 - val_loss: 0.7203\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 677us/step - loss: 0.0034 - val_loss: 0.7214\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 750us/step - loss: 0.0034 - val_loss: 0.7228\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 758us/step - loss: 0.0033 - val_loss: 0.7226\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 736us/step - loss: 0.0033 - val_loss: 0.7233\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 691us/step - loss: 0.0032 - val_loss: 0.7242\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 683us/step - loss: 0.0032 - val_loss: 0.7246\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 816us/step - loss: 0.0032 - val_loss: 0.7253\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 909us/step - loss: 0.0031 - val_loss: 0.7259\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 841us/step - loss: 0.0031 - val_loss: 0.7273\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 779us/step - loss: 0.0031 - val_loss: 0.7286\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 788us/step - loss: 0.0030 - val_loss: 0.7293\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 723us/step - loss: 0.0030 - val_loss: 0.7296\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 692us/step - loss: 0.0030 - val_loss: 0.7291\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 731us/step - loss: 0.0029 - val_loss: 0.7299\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 793us/step - loss: 0.0029 - val_loss: 0.7313\n",
      "Epoch 174/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 718us/step - loss: 0.0029 - val_loss: 0.7324\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 732us/step - loss: 0.0028 - val_loss: 0.7335\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 706us/step - loss: 0.0028 - val_loss: 0.7352\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 673us/step - loss: 0.0028 - val_loss: 0.7349\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 717us/step - loss: 0.0027 - val_loss: 0.7348\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 0.0027 - val_loss: 0.7363\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 742us/step - loss: 0.0027 - val_loss: 0.7365\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 810us/step - loss: 0.0027 - val_loss: 0.7372\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 874us/step - loss: 0.0026 - val_loss: 0.7383\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 0.0026 - val_loss: 0.7381\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 0.0026 - val_loss: 0.7384\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 731us/step - loss: 0.0026 - val_loss: 0.7388\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 740us/step - loss: 0.0025 - val_loss: 0.7403\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 677us/step - loss: 0.0025 - val_loss: 0.7405\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 0.0025 - val_loss: 0.7414\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 768us/step - loss: 0.0024 - val_loss: 0.7418\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 739us/step - loss: 0.0024 - val_loss: 0.7432\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 772us/step - loss: 0.0024 - val_loss: 0.7431\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 739us/step - loss: 0.0024 - val_loss: 0.7438\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 704us/step - loss: 0.0024 - val_loss: 0.7437\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 726us/step - loss: 0.0023 - val_loss: 0.7445\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 0.0023 - val_loss: 0.7453\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 0.0023 - val_loss: 0.7462\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 689us/step - loss: 0.0023 - val_loss: 0.7467\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 0.0022 - val_loss: 0.7476\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 747us/step - loss: 0.0022 - val_loss: 0.7485\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 677us/step - loss: 0.0022 - val_loss: 0.7488\n",
      "   (0, 15)     tanh B\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 5.5712 - val_loss: 5.2204\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 249us/step - loss: 5.2312 - val_loss: 4.9777\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 4.9608 - val_loss: 4.7584\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 4.7115 - val_loss: 4.5484\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 262us/step - loss: 4.4598 - val_loss: 4.3408\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 264us/step - loss: 4.2204 - val_loss: 4.1380\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 3.9929 - val_loss: 3.9391\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 3.7779 - val_loss: 3.7583\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 3.5797 - val_loss: 3.5902\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 3.3954 - val_loss: 3.4374\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 3.2204 - val_loss: 3.2965\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 255us/step - loss: 3.0615 - val_loss: 3.1626\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 2.9055 - val_loss: 3.0346\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 2.7638 - val_loss: 2.9162\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 2.6255 - val_loss: 2.8039\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 2.4911 - val_loss: 2.6855\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 2.3618 - val_loss: 2.5760\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 2.2329 - val_loss: 2.4736\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 2.1135 - val_loss: 2.3773\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 2.0004 - val_loss: 2.2885\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 1.8971 - val_loss: 2.1920\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 1.7948 - val_loss: 2.1128\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 1.6948 - val_loss: 2.0490\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 1.6039 - val_loss: 1.9774\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 1.5161 - val_loss: 1.8959\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 276us/step - loss: 1.4345 - val_loss: 1.8296\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 1.3552 - val_loss: 1.7813\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 1.2819 - val_loss: 1.7294\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 1.2157 - val_loss: 1.6706\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 1.1504 - val_loss: 1.6178\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 1.0863 - val_loss: 1.5861\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 1.0293 - val_loss: 1.5465\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.9755 - val_loss: 1.4920\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 0.9243 - val_loss: 1.4526\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 0.8742 - val_loss: 1.4245\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 0.8296 - val_loss: 1.4017\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.7848 - val_loss: 1.3528\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.7423 - val_loss: 1.3142\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 0.7028 - val_loss: 1.2955\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 0.6630 - val_loss: 1.2736\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 0.6277 - val_loss: 1.2409\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 356us/step - loss: 0.5902 - val_loss: 1.2082\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 356us/step - loss: 0.5573 - val_loss: 1.1777\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 0.5251 - val_loss: 1.1551\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 367us/step - loss: 0.4919 - val_loss: 1.1430\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 0.4618 - val_loss: 1.1109\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 372us/step - loss: 0.4333 - val_loss: 1.0865\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 0.4055 - val_loss: 1.0777\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.3805 - val_loss: 1.0649\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 394us/step - loss: 0.3577 - val_loss: 1.0430\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.3366 - val_loss: 1.0254\n",
      "Epoch 52/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 435us/step - loss: 0.3170 - val_loss: 1.0135\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 0.2990 - val_loss: 1.0072\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 391us/step - loss: 0.2828 - val_loss: 0.9923\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.2674 - val_loss: 0.9771\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 0.2528 - val_loss: 0.9698\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 0.2394 - val_loss: 0.9673\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 354us/step - loss: 0.2275 - val_loss: 0.9538\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 0.2160 - val_loss: 0.9416\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.2059 - val_loss: 0.9356\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 353us/step - loss: 0.1963 - val_loss: 0.9255\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.1873 - val_loss: 0.9237\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 361us/step - loss: 0.1794 - val_loss: 0.9151\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.1715 - val_loss: 0.9082\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 0.1645 - val_loss: 0.9033\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 0.1583 - val_loss: 0.8911\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 0.1517 - val_loss: 0.8923\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.1461 - val_loss: 0.8905\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 0.1408 - val_loss: 0.8853\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.1357 - val_loss: 0.8749\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.1311 - val_loss: 0.8674\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.1264 - val_loss: 0.8648\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 0.1225 - val_loss: 0.8666\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.1184 - val_loss: 0.8623\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 0.1148 - val_loss: 0.8557\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.1115 - val_loss: 0.8542\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 0.1080 - val_loss: 0.8485\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 357us/step - loss: 0.1048 - val_loss: 0.8464\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 357us/step - loss: 0.1018 - val_loss: 0.8430\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.0991 - val_loss: 0.8427\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.0963 - val_loss: 0.8396\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 356us/step - loss: 0.0937 - val_loss: 0.8346\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 352us/step - loss: 0.0913 - val_loss: 0.8304\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 0.0889 - val_loss: 0.8338\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 0.0866 - val_loss: 0.8327\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 378us/step - loss: 0.0845 - val_loss: 0.8297\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 0.0825 - val_loss: 0.8274\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 0.0805 - val_loss: 0.8215\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0786 - val_loss: 0.8214\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 357us/step - loss: 0.0767 - val_loss: 0.8229\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 369us/step - loss: 0.0749 - val_loss: 0.8226\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.0732 - val_loss: 0.8195\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.0716 - val_loss: 0.8169\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 372us/step - loss: 0.0700 - val_loss: 0.8137\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 349us/step - loss: 0.0684 - val_loss: 0.8132\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.0670 - val_loss: 0.8157\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 366us/step - loss: 0.0655 - val_loss: 0.8124\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.0642 - val_loss: 0.8122\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 0.0628 - val_loss: 0.8097\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0615 - val_loss: 0.8098\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 368us/step - loss: 0.0603 - val_loss: 0.8076\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0591 - val_loss: 0.8063\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 365us/step - loss: 0.0579 - val_loss: 0.8052\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0568 - val_loss: 0.8039\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 365us/step - loss: 0.0557 - val_loss: 0.8009\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0546 - val_loss: 0.8019\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 399us/step - loss: 0.0536 - val_loss: 0.8015\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0526 - val_loss: 0.8018\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 360us/step - loss: 0.0516 - val_loss: 0.8005\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 379us/step - loss: 0.0506 - val_loss: 0.7994\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 495us/step - loss: 0.0498 - val_loss: 0.7984\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 361us/step - loss: 0.0489 - val_loss: 0.7983\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 0.0480 - val_loss: 0.7965\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 370us/step - loss: 0.0472 - val_loss: 0.7933\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 0.0464 - val_loss: 0.7945\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 390us/step - loss: 0.0456 - val_loss: 0.7954\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0448 - val_loss: 0.7950\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 362us/step - loss: 0.0441 - val_loss: 0.7932\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.0434 - val_loss: 0.7918\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 0.0427 - val_loss: 0.7916\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 0.0420 - val_loss: 0.7918\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 379us/step - loss: 0.0413 - val_loss: 0.7926\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 511us/step - loss: 0.0406 - val_loss: 0.7934\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 362us/step - loss: 0.0400 - val_loss: 0.7916\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 366us/step - loss: 0.0394 - val_loss: 0.7907\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 0.0388 - val_loss: 0.7893\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 442us/step - loss: 0.0382 - val_loss: 0.7880\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 0.0377 - val_loss: 0.7876\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.0371 - val_loss: 0.7880\n",
      "Epoch 130/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 331us/step - loss: 0.0365 - val_loss: 0.7888\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.0360 - val_loss: 0.7885\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 0.0355 - val_loss: 0.7879\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.0350 - val_loss: 0.7877\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 349us/step - loss: 0.0345 - val_loss: 0.7873\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 0.0340 - val_loss: 0.7870\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 0.0335 - val_loss: 0.7862\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.0331 - val_loss: 0.7868\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 0.0326 - val_loss: 0.7863\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 389us/step - loss: 0.0322 - val_loss: 0.7864\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 0.0318 - val_loss: 0.7851\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 0.0314 - val_loss: 0.7853\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0310 - val_loss: 0.7848\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 0.0306 - val_loss: 0.7843\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0302 - val_loss: 0.7840\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0298 - val_loss: 0.7828\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.0294 - val_loss: 0.7818\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.0291 - val_loss: 0.7820\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.0287 - val_loss: 0.7836\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.029 - 0s 304us/step - loss: 0.0284 - val_loss: 0.7837\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 0.0280 - val_loss: 0.7850\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0277 - val_loss: 0.7838\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 352us/step - loss: 0.0273 - val_loss: 0.7831\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 0.0270 - val_loss: 0.7834\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 0.0267 - val_loss: 0.7829\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0264 - val_loss: 0.7828\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0261 - val_loss: 0.7825\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0258 - val_loss: 0.7824\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0255 - val_loss: 0.7822\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0252 - val_loss: 0.7812\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.0250 - val_loss: 0.7804\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 0.0247 - val_loss: 0.7811\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0244 - val_loss: 0.7814\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.0241 - val_loss: 0.7814\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0239 - val_loss: 0.7820\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.0236 - val_loss: 0.7818\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0234 - val_loss: 0.7817\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 0.0231 - val_loss: 0.7818\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.022 - 0s 293us/step - loss: 0.0229 - val_loss: 0.7818\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.0227 - val_loss: 0.7819\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 259us/step - loss: 0.0224 - val_loss: 0.7814\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 0.0222 - val_loss: 0.7806\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.0220 - val_loss: 0.7805\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.0218 - val_loss: 0.7806\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0215 - val_loss: 0.7804\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 278us/step - loss: 0.0213 - val_loss: 0.7807\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 0.0211 - val_loss: 0.7799\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.0209 - val_loss: 0.7800\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 0.0207 - val_loss: 0.7811\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.0205 - val_loss: 0.7814\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0203 - val_loss: 0.7814\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 0.0201 - val_loss: 0.7815\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0199 - val_loss: 0.7810\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 0.0197 - val_loss: 0.7813\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0196 - val_loss: 0.7806\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 0.0194 - val_loss: 0.7798\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 293us/step - loss: 0.0192 - val_loss: 0.7808\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.0190 - val_loss: 0.7809\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.0188 - val_loss: 0.7806\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.0187 - val_loss: 0.7805\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.0185 - val_loss: 0.7808\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 378us/step - loss: 0.0183 - val_loss: 0.7806\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 0.0182 - val_loss: 0.7812\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 360us/step - loss: 0.0180 - val_loss: 0.7814\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 0.0179 - val_loss: 0.7811\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0177 - val_loss: 0.7807\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 362us/step - loss: 0.0176 - val_loss: 0.7813\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.0174 - val_loss: 0.7808\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 388us/step - loss: 0.0173 - val_loss: 0.7809\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 0.0171 - val_loss: 0.7812\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.0170 - val_loss: 0.7815\n",
      "   (0, 15)     tanh C\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.8225 - val_loss: 3.2845\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 2.8271 - val_loss: 2.8045\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 710us/step - loss: 2.3148 - val_loss: 2.3944\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 964us/step - loss: 1.8910 - val_loss: 2.0329\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 875us/step - loss: 1.5987 - val_loss: 1.7834\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 1.3327 - val_loss: 1.6115\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 1ms/step - loss: 1.1593 - val_loss: 1.4494\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 758us/step - loss: 0.9903 - val_loss: 1.2833\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 770us/step - loss: 0.8361 - val_loss: 1.1543\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 714us/step - loss: 0.6878 - val_loss: 1.0091\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 785us/step - loss: 0.5559 - val_loss: 0.9146\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 749us/step - loss: 0.4298 - val_loss: 0.8323\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 772us/step - loss: 0.3338 - val_loss: 0.7696\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 736us/step - loss: 0.2634 - val_loss: 0.7346\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 761us/step - loss: 0.2180 - val_loss: 0.6997\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 772us/step - loss: 0.1749 - val_loss: 0.6629\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 0.1398 - val_loss: 0.6630\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 882us/step - loss: 0.1160 - val_loss: 0.6391\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 0.0989 - val_loss: 0.6225\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 671us/step - loss: 0.0830 - val_loss: 0.6166\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 743us/step - loss: 0.0722 - val_loss: 0.6225\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 692us/step - loss: 0.0625 - val_loss: 0.6102\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 679us/step - loss: 0.0549 - val_loss: 0.6047\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 706us/step - loss: 0.0485 - val_loss: 0.6095\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 0.0433 - val_loss: 0.6043\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 764us/step - loss: 0.0391 - val_loss: 0.5956\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 697us/step - loss: 0.0359 - val_loss: 0.6039\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 0.0321 - val_loss: 0.6015\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 679us/step - loss: 0.0291 - val_loss: 0.5904\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 681us/step - loss: 0.0266 - val_loss: 0.6065\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 566us/step - loss: 0.0240 - val_loss: 0.5990\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 608us/step - loss: 0.0222 - val_loss: 0.6030\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 634us/step - loss: 0.0206 - val_loss: 0.6016\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 587us/step - loss: 0.0192 - val_loss: 0.6060\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 644us/step - loss: 0.0177 - val_loss: 0.6031\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 595us/step - loss: 0.0168 - val_loss: 0.6041\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 597us/step - loss: 0.0155 - val_loss: 0.6082\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 634us/step - loss: 0.0146 - val_loss: 0.6111\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 644us/step - loss: 0.0136 - val_loss: 0.6108\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 637us/step - loss: 0.0128 - val_loss: 0.6105\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 607us/step - loss: 0.0120 - val_loss: 0.6169\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 614us/step - loss: 0.0114 - val_loss: 0.6146\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 639us/step - loss: 0.0106 - val_loss: 0.6150\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 660us/step - loss: 0.0101 - val_loss: 0.6142\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 615us/step - loss: 0.0096 - val_loss: 0.6180\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 611us/step - loss: 0.0091 - val_loss: 0.6200\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 648us/step - loss: 0.0086 - val_loss: 0.6207\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 564us/step - loss: 0.0083 - val_loss: 0.6238\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 636us/step - loss: 0.0078 - val_loss: 0.6268\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 594us/step - loss: 0.0075 - val_loss: 0.6266\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 591us/step - loss: 0.0071 - val_loss: 0.6298\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 579us/step - loss: 0.0069 - val_loss: 0.6277\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 592us/step - loss: 0.0065 - val_loss: 0.6297\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 650us/step - loss: 0.0063 - val_loss: 0.6369\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 712us/step - loss: 0.0060 - val_loss: 0.6334\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 771us/step - loss: 0.0057 - val_loss: 0.6398\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 756us/step - loss: 0.0055 - val_loss: 0.6361\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 0.0053 - val_loss: 0.6365\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 735us/step - loss: 0.0050 - val_loss: 0.6430\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 732us/step - loss: 0.0049 - val_loss: 0.6456\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 705us/step - loss: 0.0047 - val_loss: 0.6437\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 723us/step - loss: 0.0045 - val_loss: 0.6472\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 751us/step - loss: 0.0044 - val_loss: 0.6505\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 740us/step - loss: 0.0042 - val_loss: 0.6478\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 718us/step - loss: 0.0040 - val_loss: 0.6498\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 746us/step - loss: 0.0039 - val_loss: 0.6518\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 714us/step - loss: 0.0038 - val_loss: 0.6533\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 723us/step - loss: 0.0036 - val_loss: 0.6529\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 714us/step - loss: 0.0035 - val_loss: 0.6533\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 715us/step - loss: 0.0034 - val_loss: 0.6541\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 762us/step - loss: 0.0033 - val_loss: 0.6606\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 747us/step - loss: 0.0032 - val_loss: 0.6590\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 724us/step - loss: 0.0031 - val_loss: 0.6617\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 730us/step - loss: 0.0030 - val_loss: 0.6608\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 712us/step - loss: 0.0029 - val_loss: 0.6649\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 722us/step - loss: 0.0028 - val_loss: 0.6618\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 712us/step - loss: 0.0027 - val_loss: 0.6637\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 814us/step - loss: 0.0027 - val_loss: 0.6655\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 905us/step - loss: 0.0026 - val_loss: 0.6640\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 776us/step - loss: 0.0025 - val_loss: 0.6676\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 0.0025 - val_loss: 0.6686\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 0.0024 - val_loss: 0.6721\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 0.0023 - val_loss: 0.6721\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 686us/step - loss: 0.0023 - val_loss: 0.6732\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 778us/step - loss: 0.0022 - val_loss: 0.6748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 0.0021 - val_loss: 0.6762\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 776us/step - loss: 0.0021 - val_loss: 0.6765\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 787us/step - loss: 0.0020 - val_loss: 0.6779\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 753us/step - loss: 0.0020 - val_loss: 0.6790\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 739us/step - loss: 0.0019 - val_loss: 0.6821\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 742us/step - loss: 0.0019 - val_loss: 0.6814\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 772us/step - loss: 0.0018 - val_loss: 0.6838\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 716us/step - loss: 0.0018 - val_loss: 0.6835\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 744us/step - loss: 0.0018 - val_loss: 0.6820\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 0.0017 - val_loss: 0.6856\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 699us/step - loss: 0.0017 - val_loss: 0.6884\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 741us/step - loss: 0.0016 - val_loss: 0.6890\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 743us/step - loss: 0.0016 - val_loss: 0.6891\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 761us/step - loss: 0.0016 - val_loss: 0.6910\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 0.0015 - val_loss: 0.6922\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 820us/step - loss: 0.0015 - val_loss: 0.6944\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 818us/step - loss: 0.0015 - val_loss: 0.6961\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 800us/step - loss: 0.0014 - val_loss: 0.6960\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 695us/step - loss: 0.0014 - val_loss: 0.6969\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 638us/step - loss: 0.0014 - val_loss: 0.6978\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.001 - 0s 705us/step - loss: 0.0013 - val_loss: 0.6994\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 681us/step - loss: 0.0013 - val_loss: 0.7006\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 672us/step - loss: 0.0013 - val_loss: 0.7008\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 700us/step - loss: 0.0013 - val_loss: 0.7014\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 694us/step - loss: 0.0012 - val_loss: 0.7042\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 682us/step - loss: 0.0012 - val_loss: 0.7034\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 699us/step - loss: 0.0012 - val_loss: 0.7031\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 751us/step - loss: 0.0012 - val_loss: 0.7058\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 724us/step - loss: 0.0011 - val_loss: 0.7076\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 686us/step - loss: 0.0011 - val_loss: 0.7076\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 626us/step - loss: 0.0011 - val_loss: 0.7079\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 599us/step - loss: 0.0011 - val_loss: 0.7077\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 579us/step - loss: 0.0011 - val_loss: 0.7098\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 600us/step - loss: 0.0010 - val_loss: 0.7095\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 628us/step - loss: 0.0010 - val_loss: 0.7125\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 616us/step - loss: 9.9613e-04 - val_loss: 0.7129\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 594us/step - loss: 9.7942e-04 - val_loss: 0.7118\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 583us/step - loss: 9.5977e-04 - val_loss: 0.7127\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 599us/step - loss: 9.4095e-04 - val_loss: 0.7159\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 595us/step - loss: 9.2605e-04 - val_loss: 0.7175\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 612us/step - loss: 9.0948e-04 - val_loss: 0.7174\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 613us/step - loss: 8.9307e-04 - val_loss: 0.7180\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 666us/step - loss: 8.7716e-04 - val_loss: 0.7172\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 614us/step - loss: 8.6366e-04 - val_loss: 0.7179\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 645us/step - loss: 8.4822e-04 - val_loss: 0.7187\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 8.5475e-0 - 0s 625us/step - loss: 8.3286e-04 - val_loss: 0.7225\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 617us/step - loss: 8.1802e-04 - val_loss: 0.7232\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 662us/step - loss: 8.0463e-04 - val_loss: 0.7215\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 632us/step - loss: 7.9075e-04 - val_loss: 0.7217\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 624us/step - loss: 7.7881e-04 - val_loss: 0.7231\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 600us/step - loss: 7.6488e-04 - val_loss: 0.7240\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 598us/step - loss: 7.5301e-04 - val_loss: 0.7258\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 681us/step - loss: 7.3989e-04 - val_loss: 0.7271\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 7.2834e-04 - val_loss: 0.7283\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 700us/step - loss: 7.1628e-04 - val_loss: 0.7283\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 695us/step - loss: 7.0683e-04 - val_loss: 0.7306\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 743us/step - loss: 6.9310e-04 - val_loss: 0.7304\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 759us/step - loss: 6.8181e-04 - val_loss: 0.7311\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 6.7348e-04 - val_loss: 0.7310\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 787us/step - loss: 6.6241e-04 - val_loss: 0.7324\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 756us/step - loss: 6.5320e-04 - val_loss: 0.7332\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 716us/step - loss: 6.4164e-04 - val_loss: 0.7345\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 702us/step - loss: 6.3080e-04 - val_loss: 0.7364\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 713us/step - loss: 6.2116e-04 - val_loss: 0.7375\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 748us/step - loss: 6.1195e-04 - val_loss: 0.7377\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 714us/step - loss: 6.0231e-04 - val_loss: 0.7380\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 664us/step - loss: 5.9449e-04 - val_loss: 0.7403\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 5.8520e-04 - val_loss: 0.7403\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 682us/step - loss: 5.7623e-04 - val_loss: 0.7403\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 692us/step - loss: 5.6857e-04 - val_loss: 0.7422\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 5.5991e-04 - val_loss: 0.7424\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 696us/step - loss: 5.5173e-04 - val_loss: 0.7422\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 770us/step - loss: 5.4358e-04 - val_loss: 0.7442\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 691us/step - loss: 5.3553e-04 - val_loss: 0.7440\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 692us/step - loss: 5.2902e-04 - val_loss: 0.7448\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 5.2109e-04 - val_loss: 0.7450\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 695us/step - loss: 5.1360e-04 - val_loss: 0.7455\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 5.0638e-04 - val_loss: 0.7472\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 755us/step - loss: 4.9904e-04 - val_loss: 0.7486\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 4.9246e-04 - val_loss: 0.7489\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 699us/step - loss: 4.8409e-04 - val_loss: 0.7496\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 676us/step - loss: 4.7736e-04 - val_loss: 0.7505\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 747us/step - loss: 4.7049e-04 - val_loss: 0.7506\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 744us/step - loss: 4.6402e-04 - val_loss: 0.7530\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 756us/step - loss: 4.5706e-04 - val_loss: 0.7520\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 752us/step - loss: 4.5051e-04 - val_loss: 0.7538\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 802us/step - loss: 4.4379e-04 - val_loss: 0.7537\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 739us/step - loss: 4.3833e-04 - val_loss: 0.7532\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 717us/step - loss: 4.3148e-04 - val_loss: 0.7561\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 4.2481e-04 - val_loss: 0.7558\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 701us/step - loss: 4.1824e-04 - val_loss: 0.7572\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 755us/step - loss: 4.1234e-04 - val_loss: 0.7586\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 4.0638e-04 - val_loss: 0.7591\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 4.0053e-04 - val_loss: 0.7575\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 718us/step - loss: 3.9480e-04 - val_loss: 0.7578\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 696us/step - loss: 3.8939e-04 - val_loss: 0.7596\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 3.8366e-04 - val_loss: 0.7605\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 3.7837e-04 - val_loss: 0.7616\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 715us/step - loss: 3.7371e-04 - val_loss: 0.7625\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 3.6897e-04 - val_loss: 0.7639\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 3.6381e-04 - val_loss: 0.7648\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 682us/step - loss: 3.5867e-04 - val_loss: 0.7643\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 625us/step - loss: 3.5405e-04 - val_loss: 0.7643\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 704us/step - loss: 3.4923e-04 - val_loss: 0.7652\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 640us/step - loss: 3.4503e-04 - val_loss: 0.7664\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 752us/step - loss: 3.4062e-04 - val_loss: 0.7678\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 678us/step - loss: 3.3625e-04 - val_loss: 0.7686\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 683us/step - loss: 3.3211e-04 - val_loss: 0.7690\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 3.2822e-04 - val_loss: 0.7694\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 3.2379e-04 - val_loss: 0.7702\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 3.1941e-04 - val_loss: 0.7712\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 666us/step - loss: 3.1592e-04 - val_loss: 0.7705\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 692us/step - loss: 3.1171e-04 - val_loss: 0.7727\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 652us/step - loss: 3.0750e-04 - val_loss: 0.7728\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 625us/step - loss: 3.0352e-04 - val_loss: 0.7729\n",
      "   (0, 30)   linear A\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.1931 - val_loss: 2.0305\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 578us/step - loss: 1.8263 - val_loss: 1.7433\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 574us/step - loss: 1.4814 - val_loss: 1.4578\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 585us/step - loss: 1.1812 - val_loss: 1.2188\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 586us/step - loss: 0.9242 - val_loss: 1.0472\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 566us/step - loss: 0.7333 - val_loss: 0.9164\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 569us/step - loss: 0.5914 - val_loss: 0.8342\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 576us/step - loss: 0.4833 - val_loss: 0.7935\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 557us/step - loss: 0.3876 - val_loss: 0.7595\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 559us/step - loss: 0.3043 - val_loss: 0.7064\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 0.2485 - val_loss: 0.7015\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 715us/step - loss: 0.2110 - val_loss: 0.7078\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 0.1693 - val_loss: 0.6742\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 0.1373 - val_loss: 0.6944\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 679us/step - loss: 0.1116 - val_loss: 0.6895\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 685us/step - loss: 0.0919 - val_loss: 0.7073\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 679us/step - loss: 0.0753 - val_loss: 0.6866\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 874us/step - loss: 0.0619 - val_loss: 0.6893\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.7003\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0432 - val_loss: 0.7301\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0376 - val_loss: 0.7095\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 924us/step - loss: 0.0320 - val_loss: 0.7151\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0279 - val_loss: 0.7315\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.0254 - val_loss: 0.7464\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.0224 - val_loss: 0.7448\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.0198 - val_loss: 0.7415\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.7637\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.7654\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.7690\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.7730\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.7783\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.7842\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.7934\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 895us/step - loss: 0.0097 - val_loss: 0.7960\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 832us/step - loss: 0.0090 - val_loss: 0.7983\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 0.0085 - val_loss: 0.8059\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.8080\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.8171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.8160\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.8210\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.8277\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 998us/step - loss: 0.0058 - val_loss: 0.8333\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 885us/step - loss: 0.0055 - val_loss: 0.8354\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.8409\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.8430\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.8472\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.8536\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 878us/step - loss: 0.0043 - val_loss: 0.8561\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 934us/step - loss: 0.0040 - val_loss: 0.8577\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.8643\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.8680\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.8678\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.0034 - val_loss: 0.8713\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.8786\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.8802\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.8832\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.8825\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.8837\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.8873\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.8948\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.8935\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.9019\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 785us/step - loss: 0.0023 - val_loss: 0.9025\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 984us/step - loss: 0.0022 - val_loss: 0.9040\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.9020\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.9103\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 995us/step - loss: 0.0020 - val_loss: 0.9142\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.9148\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.9156\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.9191\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.9239\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 747us/step - loss: 0.0017 - val_loss: 0.9269\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 909us/step - loss: 0.0017 - val_loss: 0.9254\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 975us/step - loss: 0.0016 - val_loss: 0.9310\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 987us/step - loss: 0.0016 - val_loss: 0.9367\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 781us/step - loss: 0.0015 - val_loss: 0.9344\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 748us/step - loss: 0.0015 - val_loss: 0.9363\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 701us/step - loss: 0.0014 - val_loss: 0.9424\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.9427\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 922us/step - loss: 0.0014 - val_loss: 0.9441\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 924us/step - loss: 0.0013 - val_loss: 0.9461\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.9454\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 897us/step - loss: 0.0012 - val_loss: 0.9507\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 743us/step - loss: 0.0012 - val_loss: 0.9551\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 806us/step - loss: 0.0012 - val_loss: 0.9524\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 868us/step - loss: 0.0012 - val_loss: 0.9571\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 744us/step - loss: 0.0011 - val_loss: 0.9604\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 591us/step - loss: 0.0011 - val_loss: 0.9599\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 613us/step - loss: 0.0011 - val_loss: 0.9626\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 550us/step - loss: 0.0010 - val_loss: 0.9638\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 559us/step - loss: 0.0010 - val_loss: 0.9657\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 560us/step - loss: 9.9316e-04 - val_loss: 0.9678\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 563us/step - loss: 9.6825e-04 - val_loss: 0.9679\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 575us/step - loss: 9.4756e-04 - val_loss: 0.9680\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 648us/step - loss: 9.2739e-04 - val_loss: 0.9729\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 612us/step - loss: 9.0439e-04 - val_loss: 0.9739\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 622us/step - loss: 8.8400e-04 - val_loss: 0.9773\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 592us/step - loss: 8.6703e-04 - val_loss: 0.9804\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 560us/step - loss: 8.4569e-04 - val_loss: 0.9817\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 559us/step - loss: 8.2671e-04 - val_loss: 0.9829\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 587us/step - loss: 8.0802e-04 - val_loss: 0.9822\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 575us/step - loss: 7.8987e-04 - val_loss: 0.9843\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 564us/step - loss: 7.7460e-04 - val_loss: 0.9864\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 588us/step - loss: 7.5974e-04 - val_loss: 0.9882\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 558us/step - loss: 7.4329e-04 - val_loss: 0.9891\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 572us/step - loss: 7.2703e-04 - val_loss: 0.9931\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 592us/step - loss: 7.1169e-04 - val_loss: 0.9928\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 581us/step - loss: 6.9781e-04 - val_loss: 0.9934\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 573us/step - loss: 6.8333e-04 - val_loss: 0.9972\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 566us/step - loss: 6.6980e-04 - val_loss: 0.9968\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 578us/step - loss: 6.5722e-04 - val_loss: 0.9972\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 583us/step - loss: 6.4572e-04 - val_loss: 0.9969\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 574us/step - loss: 6.3195e-04 - val_loss: 1.0011\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 578us/step - loss: 6.1939e-04 - val_loss: 1.0023\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 571us/step - loss: 6.0780e-04 - val_loss: 1.0027\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 575us/step - loss: 5.9499e-04 - val_loss: 1.0044\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 576us/step - loss: 5.8416e-04 - val_loss: 1.0067\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 562us/step - loss: 5.7361e-04 - val_loss: 1.0093\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 651us/step - loss: 5.6287e-04 - val_loss: 1.0109\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 5.5271e-04 - val_loss: 1.0121\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 5.4300e-04 - val_loss: 1.0130\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 698us/step - loss: 5.3267e-04 - val_loss: 1.0136\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 697us/step - loss: 5.2402e-04 - val_loss: 1.0157\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 736us/step - loss: 5.1485e-04 - val_loss: 1.0183\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 739us/step - loss: 5.0406e-04 - val_loss: 1.0186\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 752us/step - loss: 4.9510e-04 - val_loss: 1.0203\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 4.8827e-04 - val_loss: 1.0212\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 4.7970e-04 - val_loss: 1.0236\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 4.7182e-04 - val_loss: 1.0272\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 4.6384e-04 - val_loss: 1.0260\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 726us/step - loss: 4.5541e-04 - val_loss: 1.0261\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 680us/step - loss: 4.4751e-04 - val_loss: 1.0285\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 945us/step - loss: 4.4018e-04 - val_loss: 1.0307\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 681us/step - loss: 4.3228e-04 - val_loss: 1.0321\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 757us/step - loss: 4.2511e-04 - val_loss: 1.0327\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 673us/step - loss: 4.1861e-04 - val_loss: 1.0343\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 4.1213e-04 - val_loss: 1.0363\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 668us/step - loss: 4.0504e-04 - val_loss: 1.0367\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 677us/step - loss: 3.9865e-04 - val_loss: 1.0359\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 3.9254e-04 - val_loss: 1.0383\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 741us/step - loss: 3.8601e-04 - val_loss: 1.0409\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 694us/step - loss: 3.8024e-04 - val_loss: 1.0423\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 3.7420e-04 - val_loss: 1.0424\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 710us/step - loss: 3.6797e-04 - val_loss: 1.0446\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 737us/step - loss: 3.6304e-04 - val_loss: 1.0460\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 3.5726e-04 - val_loss: 1.0481\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 717us/step - loss: 3.5181e-04 - val_loss: 1.0482\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 3.4624e-04 - val_loss: 1.0488\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 693us/step - loss: 3.4114e-04 - val_loss: 1.0512\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 931us/step - loss: 3.3576e-04 - val_loss: 1.0513\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 990us/step - loss: 3.3100e-04 - val_loss: 1.0519\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 767us/step - loss: 3.2602e-04 - val_loss: 1.0551\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 3.2122e-04 - val_loss: 1.0546\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 3.1632e-04 - val_loss: 1.0562\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 837us/step - loss: 3.1173e-04 - val_loss: 1.0578\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 854us/step - loss: 3.0761e-04 - val_loss: 1.0593\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 682us/step - loss: 3.0319e-04 - val_loss: 1.0584\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 716us/step - loss: 2.9860e-04 - val_loss: 1.0603\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 649us/step - loss: 2.9468e-04 - val_loss: 1.0628\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 2.9058e-04 - val_loss: 1.0614\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 658us/step - loss: 2.8638e-04 - val_loss: 1.0638\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 651us/step - loss: 2.8270e-04 - val_loss: 1.0662\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 668us/step - loss: 2.7889e-04 - val_loss: 1.0659\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 650us/step - loss: 2.7454e-04 - val_loss: 1.0672\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 677us/step - loss: 2.7176e-04 - val_loss: 1.0690\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 641us/step - loss: 2.6734e-04 - val_loss: 1.0697\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 665us/step - loss: 2.6390e-04 - val_loss: 1.0712\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 716us/step - loss: 2.6038e-04 - val_loss: 1.0714\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 764us/step - loss: 2.5662e-04 - val_loss: 1.0720\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 723us/step - loss: 2.5329e-04 - val_loss: 1.0742\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 2.5011e-04 - val_loss: 1.0756\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 643us/step - loss: 2.4682e-04 - val_loss: 1.0759\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 683us/step - loss: 2.4390e-04 - val_loss: 1.0752\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 677us/step - loss: 2.4025e-04 - val_loss: 1.0781\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 678us/step - loss: 2.3700e-04 - val_loss: 1.0781\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 676us/step - loss: 2.3397e-04 - val_loss: 1.0793\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 674us/step - loss: 2.3095e-04 - val_loss: 1.0796\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 669us/step - loss: 2.2806e-04 - val_loss: 1.0813\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 716us/step - loss: 2.2506e-04 - val_loss: 1.0838\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 662us/step - loss: 2.2206e-04 - val_loss: 1.0847\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 696us/step - loss: 2.1951e-04 - val_loss: 1.0846\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 559us/step - loss: 2.1654e-04 - val_loss: 1.0857\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 612us/step - loss: 2.1416e-04 - val_loss: 1.0882\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 726us/step - loss: 2.1145e-04 - val_loss: 1.0891\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 633us/step - loss: 2.0858e-04 - val_loss: 1.0905\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 642us/step - loss: 2.0601e-04 - val_loss: 1.0910\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 658us/step - loss: 2.0365e-04 - val_loss: 1.0903\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 653us/step - loss: 2.0115e-04 - val_loss: 1.0920\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 674us/step - loss: 1.9863e-04 - val_loss: 1.0932\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 673us/step - loss: 1.9604e-04 - val_loss: 1.0930\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 632us/step - loss: 1.9365e-04 - val_loss: 1.0934\n",
      "Epoch 192/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 664us/step - loss: 1.9159e-04 - val_loss: 1.0956\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 716us/step - loss: 1.8909e-04 - val_loss: 1.0967\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 647us/step - loss: 1.8669e-04 - val_loss: 1.0977\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 560us/step - loss: 1.8451e-04 - val_loss: 1.0975\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 558us/step - loss: 1.8229e-04 - val_loss: 1.0986\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 559us/step - loss: 1.8034e-04 - val_loss: 1.0997\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 549us/step - loss: 1.7812e-04 - val_loss: 1.1005\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 611us/step - loss: 1.7603e-04 - val_loss: 1.1016\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 558us/step - loss: 1.7408e-04 - val_loss: 1.1036\n",
      "   (0, 30)   linear B\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 12.3523 - val_loss: 11.9116\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 12.1726 - val_loss: 11.7167\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 11.9702 - val_loss: 11.5005\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 11.7720 - val_loss: 11.2640\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 11.5572 - val_loss: 11.0570\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 11.3862 - val_loss: 10.8713\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 11.2147 - val_loss: 10.6273\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 11.0063 - val_loss: 10.3380\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 10.7599 - val_loss: 10.0838\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 10.5489 - val_loss: 9.8168\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 10.2599 - val_loss: 9.4392\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 9.8833 - val_loss: 9.0644\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 9.4267 - val_loss: 8.6258\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 8.8441 - val_loss: 8.1052\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 8.2520 - val_loss: 7.5140\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 7.6042 - val_loss: 6.9887\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 356us/step - loss: 7.1265 - val_loss: 6.8790\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 6.9975 - val_loss: 6.9683\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 6.9713 - val_loss: 6.9118\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 307us/step - loss: 6.8688 - val_loss: 6.7490\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 369us/step - loss: 6.7639 - val_loss: 6.6463\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 6.7238 - val_loss: 6.5887\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 6.6755 - val_loss: 6.5457\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 6.6138 - val_loss: 6.5282\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 6.5620 - val_loss: 6.5251\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 6.5268 - val_loss: 6.5058\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 6.049 - 0s 312us/step - loss: 6.4972 - val_loss: 6.4752\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 6.4716 - val_loss: 6.4448\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 6.4449 - val_loss: 6.4273\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 362us/step - loss: 6.4254 - val_loss: 6.4150\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 6.4055 - val_loss: 6.4124\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 6.3923 - val_loss: 6.4140\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 6.3754 - val_loss: 6.4074\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 6.3617 - val_loss: 6.3942\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 358us/step - loss: 6.3498 - val_loss: 6.3814\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 6.3387 - val_loss: 6.3763\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 6.3281 - val_loss: 6.3738\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 6.3186 - val_loss: 6.3701\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 6.3109 - val_loss: 6.3562\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 6.3029 - val_loss: 6.3485\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 6.2953 - val_loss: 6.3442\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 6.2889 - val_loss: 6.3406\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 357us/step - loss: 6.2822 - val_loss: 6.3376\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 6.2766 - val_loss: 6.3317\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 6.2721 - val_loss: 6.3255\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 353us/step - loss: 6.2676 - val_loss: 6.3214\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 6.2640 - val_loss: 6.3184\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 353us/step - loss: 6.2609 - val_loss: 6.3133\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 362us/step - loss: 6.2573 - val_loss: 6.3083\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 6.2551 - val_loss: 6.3046\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 360us/step - loss: 6.2532 - val_loss: 6.3014\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 6.2510 - val_loss: 6.2985\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 6.2493 - val_loss: 6.2953\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 6.2481 - val_loss: 6.2931\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 6.2469 - val_loss: 6.2900\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 6.2459 - val_loss: 6.2869\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 6.2449 - val_loss: 6.2842\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 6.2441 - val_loss: 6.2817\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 6.2434 - val_loss: 6.2799\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 325us/step - loss: 6.2428 - val_loss: 6.2785\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 6.2422 - val_loss: 6.2766\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 6.2417 - val_loss: 6.2745\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 6.2413 - val_loss: 6.2728\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 6.2409 - val_loss: 6.2715\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 372us/step - loss: 6.2405 - val_loss: 6.2700\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 6.2401 - val_loss: 6.2685\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 6.2398 - val_loss: 6.2674\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 6.2395 - val_loss: 6.2659\n",
      "Epoch 69/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 304us/step - loss: 6.2392 - val_loss: 6.2652\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 6.2389 - val_loss: 6.2645\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 6.2387 - val_loss: 6.2638\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 6.2384 - val_loss: 6.2628\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 6.2382 - val_loss: 6.2623\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 6.2380 - val_loss: 6.2613\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 6.2378 - val_loss: 6.2603\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 6.2376 - val_loss: 6.2591\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 6.2374 - val_loss: 6.2587\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 6.2373 - val_loss: 6.2582\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 6.2371 - val_loss: 6.2577\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 6.2369 - val_loss: 6.2567\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 6.2368 - val_loss: 6.2559\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 6.2367 - val_loss: 6.2548\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 6.2365 - val_loss: 6.2538\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 6.2364 - val_loss: 6.2533\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 6.2363 - val_loss: 6.2527\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 357us/step - loss: 6.2362 - val_loss: 6.2520\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 6.2361 - val_loss: 6.2517\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 308us/step - loss: 6.2360 - val_loss: 6.2515\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 6.2359 - val_loss: 6.2512\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 6.2358 - val_loss: 6.2508\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 6.2357 - val_loss: 6.2504\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 6.2356 - val_loss: 6.2499\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 6.2355 - val_loss: 6.2494\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 6.2354 - val_loss: 6.2488\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 364us/step - loss: 6.2353 - val_loss: 6.2487\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 6.2353 - val_loss: 6.2482\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 6.2352 - val_loss: 6.2478\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 6.2351 - val_loss: 6.2473\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 6.2351 - val_loss: 6.2470\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 389us/step - loss: 6.2350 - val_loss: 6.2466\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 6.2349 - val_loss: 6.2463\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 6.2349 - val_loss: 6.2459\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 365us/step - loss: 6.2348 - val_loss: 6.2456\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 6.2348 - val_loss: 6.2454\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 343us/step - loss: 6.2347 - val_loss: 6.2450\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 6.2347 - val_loss: 6.2447\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 6.2346 - val_loss: 6.2446\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 6.2346 - val_loss: 6.2443\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 6.2345 - val_loss: 6.2441\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 298us/step - loss: 6.2345 - val_loss: 6.2440\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 6.2345 - val_loss: 6.2438\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 6.2344 - val_loss: 6.2435\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 6.2344 - val_loss: 6.2433\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 6.2343 - val_loss: 6.2433\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 6.2343 - val_loss: 6.2429\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 6.2343 - val_loss: 6.2428\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 6.2342 - val_loss: 6.2426\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 6.2342 - val_loss: 6.2425\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 343us/step - loss: 6.2342 - val_loss: 6.2424\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 6.2341 - val_loss: 6.2421\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 6.2341 - val_loss: 6.2419\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 6.2341 - val_loss: 6.2417\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 6.2340 - val_loss: 6.2416\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 6.2340 - val_loss: 6.2414\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 6.2340 - val_loss: 6.2412\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 6.2339 - val_loss: 6.2412\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 6.2339 - val_loss: 6.2408\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 6.2339 - val_loss: 6.2408\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 6.2339 - val_loss: 6.2408\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 6.2338 - val_loss: 6.2406\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 6.2338 - val_loss: 6.2404\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 352us/step - loss: 6.2338 - val_loss: 6.2402\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 6.2338 - val_loss: 6.2400\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 349us/step - loss: 6.2337 - val_loss: 6.2400\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 6.2337 - val_loss: 6.2400\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 6.2337 - val_loss: 6.2400\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 6.2337 - val_loss: 6.2398\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 6.2337 - val_loss: 6.2397\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 6.2336 - val_loss: 6.2396\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 6.2336 - val_loss: 6.2394\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 6.2336 - val_loss: 6.2392\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 6.2336 - val_loss: 6.2392\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 6.2336 - val_loss: 6.2391\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 6.2335 - val_loss: 6.2390\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 461us/step - loss: 6.2335 - val_loss: 6.2389\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 519us/step - loss: 6.2335 - val_loss: 6.2387\n",
      "Epoch 147/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 531us/step - loss: 6.2335 - val_loss: 6.2388\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 733us/step - loss: 6.2335 - val_loss: 6.2387\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 874us/step - loss: 6.2335 - val_loss: 6.2385\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 592us/step - loss: 6.2334 - val_loss: 6.2384\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 619us/step - loss: 6.2334 - val_loss: 6.2385\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 953us/step - loss: 6.2334 - val_loss: 6.2384\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 444us/step - loss: 6.2334 - val_loss: 6.2383\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 474us/step - loss: 6.2334 - val_loss: 6.2384\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 6.2334 - val_loss: 6.2382\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 367us/step - loss: 6.2334 - val_loss: 6.2381\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 6.2333 - val_loss: 6.2381\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 377us/step - loss: 6.2333 - val_loss: 6.2381\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 392us/step - loss: 6.2333 - val_loss: 6.2381\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 402us/step - loss: 6.2333 - val_loss: 6.2382\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 6.2333 - val_loss: 6.2381\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 364us/step - loss: 6.2333 - val_loss: 6.2379\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 403us/step - loss: 6.2333 - val_loss: 6.2377\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 6.2333 - val_loss: 6.2376\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 6.2332 - val_loss: 6.2376\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 355us/step - loss: 6.2332 - val_loss: 6.2377\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 6.2332 - val_loss: 6.2377\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 6.2332 - val_loss: 6.2377\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 352us/step - loss: 6.2332 - val_loss: 6.2375\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 510us/step - loss: 6.2332 - val_loss: 6.2373\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 480us/step - loss: 6.2332 - val_loss: 6.2372\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 483us/step - loss: 6.2332 - val_loss: 6.2372\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 6.2332 - val_loss: 6.2371\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 654us/step - loss: 6.2331 - val_loss: 6.2372\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 644us/step - loss: 6.2331 - val_loss: 6.2371\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 490us/step - loss: 6.2331 - val_loss: 6.2370\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 524us/step - loss: 6.2331 - val_loss: 6.2370\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 6.2331 - val_loss: 6.2370\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 531us/step - loss: 6.2331 - val_loss: 6.2369\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 386us/step - loss: 6.2331 - val_loss: 6.2368\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 6.2331 - val_loss: 6.2368\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 414us/step - loss: 6.2331 - val_loss: 6.2367\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 6.2331 - val_loss: 6.2368\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 430us/step - loss: 6.2331 - val_loss: 6.2367\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 392us/step - loss: 6.2331 - val_loss: 6.2366\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 412us/step - loss: 6.2330 - val_loss: 6.2365\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 357us/step - loss: 6.2330 - val_loss: 6.2365\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 6.2330 - val_loss: 6.2366\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 481us/step - loss: 6.2330 - val_loss: 6.2365\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 439us/step - loss: 6.2330 - val_loss: 6.2365\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 397us/step - loss: 6.2330 - val_loss: 6.2365\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 6.2330 - val_loss: 6.2364\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 6.2330 - val_loss: 6.2363\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 428us/step - loss: 6.2330 - val_loss: 6.2364\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 6.2330 - val_loss: 6.2364\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 6.2330 - val_loss: 6.2363\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 386us/step - loss: 6.2330 - val_loss: 6.2362\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 6.2330 - val_loss: 6.2362\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 432us/step - loss: 6.2330 - val_loss: 6.2362\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 453us/step - loss: 6.2329 - val_loss: 6.2362\n",
      "   (0, 30)   linear C\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 10.5906 - val_loss: 9.5898\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 704us/step - loss: 9.7915 - val_loss: 8.7173\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 991us/step - loss: 8.5435 - val_loss: 7.6478\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 661us/step - loss: 7.5159 - val_loss: 7.1516\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 756us/step - loss: 6.9491 - val_loss: 6.6315\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 646us/step - loss: 6.3960 - val_loss: 6.1641\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 669us/step - loss: 5.9634 - val_loss: 5.9141\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 631us/step - loss: 5.6781 - val_loss: 5.6475\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 748us/step - loss: 5.3803 - val_loss: 5.4276\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 779us/step - loss: 5.1818 - val_loss: 5.2961\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 760us/step - loss: 5.0573 - val_loss: 5.2131\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 863us/step - loss: 4.9834 - val_loss: 5.1801\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 871us/step - loss: 4.9454 - val_loss: 5.1667\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 847us/step - loss: 4.9109 - val_loss: 5.1421\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 752us/step - loss: 4.8947 - val_loss: 5.1229\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 797us/step - loss: 4.8772 - val_loss: 5.1125\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 802us/step - loss: 4.8625 - val_loss: 5.1146\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 650us/step - loss: 4.8491 - val_loss: 5.1065\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 778us/step - loss: 4.8391 - val_loss: 5.0954\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 829us/step - loss: 4.8307 - val_loss: 5.0931\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 776us/step - loss: 4.8251 - val_loss: 5.1000\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 789us/step - loss: 4.8185 - val_loss: 5.0929\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 772us/step - loss: 4.8121 - val_loss: 5.0836\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 765us/step - loss: 4.8085 - val_loss: 5.0779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 762us/step - loss: 4.8050 - val_loss: 5.0749\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 751us/step - loss: 4.8024 - val_loss: 5.0758\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 755us/step - loss: 4.8002 - val_loss: 5.0708\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 4.7986 - val_loss: 5.0691\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 782us/step - loss: 4.7971 - val_loss: 5.0742\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 740us/step - loss: 4.7956 - val_loss: 5.0727\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 796us/step - loss: 4.7944 - val_loss: 5.0728\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 685us/step - loss: 4.7934 - val_loss: 5.0720\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 755us/step - loss: 4.7925 - val_loss: 5.0700\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 743us/step - loss: 4.7916 - val_loss: 5.0696\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 772us/step - loss: 4.7910 - val_loss: 5.0704\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 798us/step - loss: 4.7904 - val_loss: 5.0724\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 785us/step - loss: 4.7898 - val_loss: 5.0716\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 728us/step - loss: 4.7893 - val_loss: 5.0709\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 4.7888 - val_loss: 5.0709\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 723us/step - loss: 4.7883 - val_loss: 5.0711\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 718us/step - loss: 4.7880 - val_loss: 5.0720\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 742us/step - loss: 4.7877 - val_loss: 5.0733\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 4.7874 - val_loss: 5.0724\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 769us/step - loss: 4.7870 - val_loss: 5.0720\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 713us/step - loss: 4.7867 - val_loss: 5.0714\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 688us/step - loss: 4.7865 - val_loss: 5.0705\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 736us/step - loss: 4.7863 - val_loss: 5.0699\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 4.7860 - val_loss: 5.0722\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 821us/step - loss: 4.7858 - val_loss: 5.0735\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 781us/step - loss: 4.7857 - val_loss: 5.0745\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 724us/step - loss: 4.7855 - val_loss: 5.0734\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 738us/step - loss: 4.7853 - val_loss: 5.0728\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 4.7851 - val_loss: 5.0734\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 682us/step - loss: 4.7850 - val_loss: 5.0746\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 4.7849 - val_loss: 5.0737\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 858us/step - loss: 4.7848 - val_loss: 5.0755\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 779us/step - loss: 4.7846 - val_loss: 5.0756\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 4.7845 - val_loss: 5.0766\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 744us/step - loss: 4.7844 - val_loss: 5.0767\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 4.7843 - val_loss: 5.0773\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 726us/step - loss: 4.7842 - val_loss: 5.0785\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 744us/step - loss: 4.7841 - val_loss: 5.0795\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 760us/step - loss: 4.7840 - val_loss: 5.0794\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 726us/step - loss: 4.7839 - val_loss: 5.0794\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 861us/step - loss: 4.7839 - val_loss: 5.0800\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 730us/step - loss: 4.7838 - val_loss: 5.0813\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 804us/step - loss: 4.7837 - val_loss: 5.0818\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 4.7837 - val_loss: 5.0818\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 733us/step - loss: 4.7836 - val_loss: 5.0832\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 4.7835 - val_loss: 5.0841\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 740us/step - loss: 4.7835 - val_loss: 5.0840\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 891us/step - loss: 4.7834 - val_loss: 5.0835\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 848us/step - loss: 4.7834 - val_loss: 5.0823\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 757us/step - loss: 4.7833 - val_loss: 5.0831\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 752us/step - loss: 4.7833 - val_loss: 5.0834\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 779us/step - loss: 4.7832 - val_loss: 5.0840\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 741us/step - loss: 4.7832 - val_loss: 5.0845\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 739us/step - loss: 4.7831 - val_loss: 5.0857\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 715us/step - loss: 4.7831 - val_loss: 5.0862\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 764us/step - loss: 4.7831 - val_loss: 5.0872\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 669us/step - loss: 4.7830 - val_loss: 5.0877\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 697us/step - loss: 4.7830 - val_loss: 5.0879\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 758us/step - loss: 4.7830 - val_loss: 5.0889\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 701us/step - loss: 4.7829 - val_loss: 5.0895\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 798us/step - loss: 4.7829 - val_loss: 5.0897\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 670us/step - loss: 4.7829 - val_loss: 5.0895\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 656us/step - loss: 4.7828 - val_loss: 5.0897\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 4.870 - 0s 862us/step - loss: 4.7828 - val_loss: 5.0898\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 715us/step - loss: 4.7828 - val_loss: 5.0910\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 769us/step - loss: 4.7827 - val_loss: 5.0917\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 866us/step - loss: 4.7827 - val_loss: 5.0917\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 766us/step - loss: 4.7827 - val_loss: 5.0924\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 699us/step - loss: 4.7827 - val_loss: 5.0929\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 771us/step - loss: 4.7827 - val_loss: 5.0934\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 906us/step - loss: 4.7826 - val_loss: 5.0939\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 605us/step - loss: 4.7826 - val_loss: 5.0941\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 574us/step - loss: 4.7826 - val_loss: 5.0945\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 571us/step - loss: 4.7826 - val_loss: 5.0949\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 587us/step - loss: 4.7825 - val_loss: 5.0957\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 578us/step - loss: 4.7825 - val_loss: 5.0961\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 599us/step - loss: 4.7825 - val_loss: 5.0962\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 577us/step - loss: 4.7825 - val_loss: 5.0963\n",
      "Epoch 103/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 562us/step - loss: 4.7825 - val_loss: 5.0965\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 592us/step - loss: 4.7825 - val_loss: 5.0972\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 598us/step - loss: 4.7824 - val_loss: 5.0972\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 769us/step - loss: 4.7824 - val_loss: 5.0977\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 631us/step - loss: 4.7824 - val_loss: 5.0978\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 649us/step - loss: 4.7824 - val_loss: 5.0985\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 616us/step - loss: 4.7824 - val_loss: 5.0992\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 613us/step - loss: 4.7824 - val_loss: 5.0992\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 647us/step - loss: 4.7824 - val_loss: 5.0993\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 597us/step - loss: 4.7824 - val_loss: 5.1003\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 640us/step - loss: 4.7823 - val_loss: 5.1010\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 595us/step - loss: 4.7823 - val_loss: 5.1015\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 604us/step - loss: 4.7823 - val_loss: 5.1018\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 612us/step - loss: 4.7823 - val_loss: 5.1017\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 623us/step - loss: 4.7823 - val_loss: 5.1022\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 676us/step - loss: 4.7823 - val_loss: 5.1025\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 617us/step - loss: 4.7823 - val_loss: 5.1029\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 596us/step - loss: 4.7823 - val_loss: 5.1039\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 591us/step - loss: 4.7822 - val_loss: 5.1043\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 598us/step - loss: 4.7822 - val_loss: 5.1035\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 619us/step - loss: 4.7822 - val_loss: 5.1038\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 621us/step - loss: 4.7822 - val_loss: 5.1041\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 591us/step - loss: 4.7822 - val_loss: 5.1044\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 608us/step - loss: 4.7822 - val_loss: 5.1054\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 606us/step - loss: 4.7822 - val_loss: 5.1057\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 600us/step - loss: 4.7822 - val_loss: 5.1063\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 585us/step - loss: 4.7822 - val_loss: 5.1066\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 622us/step - loss: 4.7822 - val_loss: 5.1070\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 603us/step - loss: 4.7822 - val_loss: 5.1072\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 596us/step - loss: 4.7822 - val_loss: 5.1077\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 575us/step - loss: 4.7821 - val_loss: 5.1082\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 595us/step - loss: 4.7821 - val_loss: 5.1088\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 722us/step - loss: 4.7821 - val_loss: 5.1093\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 677us/step - loss: 4.7821 - val_loss: 5.1097\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 4.7821 - val_loss: 5.1102\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 689us/step - loss: 4.7821 - val_loss: 5.1102\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 4.7821 - val_loss: 5.1110\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 670us/step - loss: 4.7821 - val_loss: 5.1111\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 724us/step - loss: 4.7821 - val_loss: 5.1112\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 871us/step - loss: 4.7821 - val_loss: 5.1119\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 724us/step - loss: 4.7821 - val_loss: 5.1124\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 730us/step - loss: 4.7821 - val_loss: 5.1131\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 741us/step - loss: 4.7821 - val_loss: 5.1132\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 688us/step - loss: 4.7821 - val_loss: 5.1135\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 704us/step - loss: 4.7821 - val_loss: 5.1135\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 670us/step - loss: 4.7821 - val_loss: 5.1137\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 670us/step - loss: 4.7820 - val_loss: 5.1141\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 765us/step - loss: 4.7820 - val_loss: 5.1149\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 700us/step - loss: 4.7820 - val_loss: 5.1153\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 693us/step - loss: 4.7820 - val_loss: 5.1160\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 654us/step - loss: 4.7820 - val_loss: 5.1162\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 691us/step - loss: 4.7820 - val_loss: 5.1169\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 4.7820 - val_loss: 5.1172\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 728us/step - loss: 4.7820 - val_loss: 5.1171\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 686us/step - loss: 4.7820 - val_loss: 5.1177\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 4.7820 - val_loss: 5.1176\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 742us/step - loss: 4.7820 - val_loss: 5.1181\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 663us/step - loss: 4.7820 - val_loss: 5.1188\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 697us/step - loss: 4.7820 - val_loss: 5.1191\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 699us/step - loss: 4.7820 - val_loss: 5.1195\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 682us/step - loss: 4.7820 - val_loss: 5.1198\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 729us/step - loss: 4.7820 - val_loss: 5.1201\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 733us/step - loss: 4.7820 - val_loss: 5.1199\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 701us/step - loss: 4.7820 - val_loss: 5.1203\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 672us/step - loss: 4.7820 - val_loss: 5.1207\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 763us/step - loss: 4.7820 - val_loss: 5.1212\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 705us/step - loss: 4.7820 - val_loss: 5.1218\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 705us/step - loss: 4.7820 - val_loss: 5.1223\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 745us/step - loss: 4.7820 - val_loss: 5.1227\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 668us/step - loss: 4.7819 - val_loss: 5.1230\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 683us/step - loss: 4.7819 - val_loss: 5.1232\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 686us/step - loss: 4.7819 - val_loss: 5.1228\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 692us/step - loss: 4.7819 - val_loss: 5.1231\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 731us/step - loss: 4.7819 - val_loss: 5.1235\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 690us/step - loss: 4.7819 - val_loss: 5.1237\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 726us/step - loss: 4.7819 - val_loss: 5.1243\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 758us/step - loss: 4.7819 - val_loss: 5.1249\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 772us/step - loss: 4.7819 - val_loss: 5.1251\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 714us/step - loss: 4.7819 - val_loss: 5.1254\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 4.7819 - val_loss: 5.1259\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 4.7819 - val_loss: 5.1261\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 651us/step - loss: 4.7819 - val_loss: 5.1261\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 729us/step - loss: 4.7819 - val_loss: 5.1265\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 4.7819 - val_loss: 5.1271\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 670us/step - loss: 4.7819 - val_loss: 5.1274\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 724us/step - loss: 4.7819 - val_loss: 5.1279\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 824us/step - loss: 4.7819 - val_loss: 5.1283\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 5.037 - 0s 715us/step - loss: 4.7819 - val_loss: 5.1288\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 704us/step - loss: 4.7819 - val_loss: 5.1291\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 704us/step - loss: 4.7819 - val_loss: 5.1296\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 704us/step - loss: 4.7819 - val_loss: 5.1299\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 793us/step - loss: 4.7819 - val_loss: 5.1301\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 723us/step - loss: 4.7819 - val_loss: 5.1302\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 694us/step - loss: 4.7819 - val_loss: 5.1305\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 4.7819 - val_loss: 5.1311\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 728us/step - loss: 4.7819 - val_loss: 5.1313\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 4.7819 - val_loss: 5.1316\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 700us/step - loss: 4.7819 - val_loss: 5.1322\n",
      "   (0, 30)     relu A\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.2332 - val_loss: 2.1568\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 685us/step - loss: 2.0247 - val_loss: 1.9741\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 1.8022 - val_loss: 1.7813\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 701us/step - loss: 1.5627 - val_loss: 1.6077\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 690us/step - loss: 1.3446 - val_loss: 1.4330\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 662us/step - loss: 1.1470 - val_loss: 1.3001\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 661us/step - loss: 0.9675 - val_loss: 1.1631\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.830 - 0s 661us/step - loss: 0.7957 - val_loss: 1.0436\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 566us/step - loss: 0.6401 - val_loss: 0.9504\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 610us/step - loss: 0.5117 - val_loss: 0.8667\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 597us/step - loss: 0.4166 - val_loss: 0.8188\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 611us/step - loss: 0.3354 - val_loss: 0.7917\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 582us/step - loss: 0.2706 - val_loss: 0.7753\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 584us/step - loss: 0.2214 - val_loss: 0.7480\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 600us/step - loss: 0.1827 - val_loss: 0.7443\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 643us/step - loss: 0.1492 - val_loss: 0.7357\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 647us/step - loss: 0.1228 - val_loss: 0.7298\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 917us/step - loss: 0.1029 - val_loss: 0.7372\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 603us/step - loss: 0.0867 - val_loss: 0.7464\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 599us/step - loss: 0.0737 - val_loss: 0.7545\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 615us/step - loss: 0.0621 - val_loss: 0.7636\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 560us/step - loss: 0.0539 - val_loss: 0.7518\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 678us/step - loss: 0.0463 - val_loss: 0.7674\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 0.0406 - val_loss: 0.7747\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 717us/step - loss: 0.0364 - val_loss: 0.7758\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 654us/step - loss: 0.0323 - val_loss: 0.7948\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 741us/step - loss: 0.0290 - val_loss: 0.7983\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 702us/step - loss: 0.0262 - val_loss: 0.8007\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 715us/step - loss: 0.0236 - val_loss: 0.8149\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 0.0215 - val_loss: 0.8163\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 0.0195 - val_loss: 0.8201\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 696us/step - loss: 0.0178 - val_loss: 0.8298\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 683us/step - loss: 0.0165 - val_loss: 0.8341\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 0.0154 - val_loss: 0.8424\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 714us/step - loss: 0.0143 - val_loss: 0.8469\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 702us/step - loss: 0.0132 - val_loss: 0.8485\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 750us/step - loss: 0.0124 - val_loss: 0.8542\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 781us/step - loss: 0.0116 - val_loss: 0.8615\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 0.0108 - val_loss: 0.8632\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 0.0102 - val_loss: 0.8704\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 785us/step - loss: 0.0095 - val_loss: 0.8763\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 853us/step - loss: 0.0090 - val_loss: 0.8784\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 769us/step - loss: 0.0085 - val_loss: 0.8837\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 741us/step - loss: 0.0081 - val_loss: 0.8880\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 737us/step - loss: 0.0077 - val_loss: 0.8946\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 678us/step - loss: 0.0073 - val_loss: 0.8991\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 785us/step - loss: 0.0070 - val_loss: 0.9047\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 693us/step - loss: 0.0066 - val_loss: 0.9078\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 695us/step - loss: 0.0063 - val_loss: 0.9089\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 752us/step - loss: 0.0061 - val_loss: 0.9129\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 698us/step - loss: 0.0057 - val_loss: 0.9167\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 689us/step - loss: 0.0055 - val_loss: 0.9213\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 0.0052 - val_loss: 0.9259\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 696us/step - loss: 0.0050 - val_loss: 0.9255\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 722us/step - loss: 0.0048 - val_loss: 0.9310\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 0.0046 - val_loss: 0.9358\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 866us/step - loss: 0.0044 - val_loss: 0.9386\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 790us/step - loss: 0.0042 - val_loss: 0.9411\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 705us/step - loss: 0.0041 - val_loss: 0.9452\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 0.0039 - val_loss: 0.9509\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 731us/step - loss: 0.0038 - val_loss: 0.9520\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 717us/step - loss: 0.0036 - val_loss: 0.9572\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 645us/step - loss: 0.0035 - val_loss: 0.9598\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 0.0034 - val_loss: 0.9623\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 676us/step - loss: 0.0033 - val_loss: 0.9679\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 643us/step - loss: 0.0032 - val_loss: 0.9693\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 701us/step - loss: 0.0031 - val_loss: 0.9721\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 685us/step - loss: 0.0030 - val_loss: 0.9758\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 0.0029 - val_loss: 0.9792\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 671us/step - loss: 0.0028 - val_loss: 0.9825\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 741us/step - loss: 0.0027 - val_loss: 0.9870\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 651us/step - loss: 0.0026 - val_loss: 0.9884\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 615us/step - loss: 0.0025 - val_loss: 0.9906\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 622us/step - loss: 0.0024 - val_loss: 0.9944\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 636us/step - loss: 0.0024 - val_loss: 0.9965\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 634us/step - loss: 0.0023 - val_loss: 0.9988\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 584us/step - loss: 0.0022 - val_loss: 1.0012\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 595us/step - loss: 0.0022 - val_loss: 1.0030\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 585us/step - loss: 0.0021 - val_loss: 1.0053\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 560us/step - loss: 0.0020 - val_loss: 1.0085\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 567us/step - loss: 0.0020 - val_loss: 1.0107\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 590us/step - loss: 0.0019 - val_loss: 1.0130\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 580us/step - loss: 0.0019 - val_loss: 1.0155\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 616us/step - loss: 0.0018 - val_loss: 1.0174\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 604us/step - loss: 0.0018 - val_loss: 1.0221\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 598us/step - loss: 0.0017 - val_loss: 1.0243\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 562us/step - loss: 0.0017 - val_loss: 1.0272\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 587us/step - loss: 0.0017 - val_loss: 1.0293\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 619us/step - loss: 0.0016 - val_loss: 1.0312\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 604us/step - loss: 0.0016 - val_loss: 1.0324\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 594us/step - loss: 0.0015 - val_loss: 1.0342\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 592us/step - loss: 0.0015 - val_loss: 1.0379\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 714us/step - loss: 0.0015 - val_loss: 1.0401\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 724us/step - loss: 0.0014 - val_loss: 1.0417\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 758us/step - loss: 0.0014 - val_loss: 1.0448\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 0.0014 - val_loss: 1.0464\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 701us/step - loss: 0.0013 - val_loss: 1.0485\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 0.0013 - val_loss: 1.0502\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 699us/step - loss: 0.0013 - val_loss: 1.0522\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 0.0013 - val_loss: 1.0543\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 786us/step - loss: 0.0012 - val_loss: 1.0573\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 744us/step - loss: 0.0012 - val_loss: 1.0598\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 757us/step - loss: 0.0012 - val_loss: 1.0604\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 718us/step - loss: 0.0011 - val_loss: 1.0621\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 723us/step - loss: 0.0011 - val_loss: 1.0652\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 0.0011 - val_loss: 1.0670\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 758us/step - loss: 0.0011 - val_loss: 1.0693\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 717us/step - loss: 0.0011 - val_loss: 1.0704\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 744us/step - loss: 0.0010 - val_loss: 1.0723\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 679us/step - loss: 0.0010 - val_loss: 1.0751\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 9.9645e-04 - val_loss: 1.0766\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 817us/step - loss: 9.7703e-04 - val_loss: 1.0788\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 817us/step - loss: 9.5481e-04 - val_loss: 1.0795\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 760us/step - loss: 9.3857e-04 - val_loss: 1.0809\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 9.2009e-04 - val_loss: 1.0835\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 735us/step - loss: 9.0296e-04 - val_loss: 1.0852\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 732us/step - loss: 8.8600e-04 - val_loss: 1.0870\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 733us/step - loss: 8.6854e-04 - val_loss: 1.0898\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 8.5258e-04 - val_loss: 1.0911\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 8.3698e-04 - val_loss: 1.0929\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 680us/step - loss: 8.2157e-04 - val_loss: 1.0938\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 8.0518e-04 - val_loss: 1.0958\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 700us/step - loss: 7.9002e-04 - val_loss: 1.0975\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 7.7509e-04 - val_loss: 1.0994\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 7.6092e-04 - val_loss: 1.1012\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 690us/step - loss: 7.4752e-04 - val_loss: 1.1022\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 713us/step - loss: 7.3573e-04 - val_loss: 1.1040\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 705us/step - loss: 7.2208e-04 - val_loss: 1.1061\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 766us/step - loss: 7.1045e-04 - val_loss: 1.1075\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 750us/step - loss: 6.9828e-04 - val_loss: 1.1093\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 740us/step - loss: 6.8769e-04 - val_loss: 1.1119\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 764us/step - loss: 6.7365e-04 - val_loss: 1.1135\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 731us/step - loss: 6.6367e-04 - val_loss: 1.1150\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 722us/step - loss: 6.5277e-04 - val_loss: 1.1158\n",
      "Epoch 135/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 728us/step - loss: 6.4229e-04 - val_loss: 1.1179\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 6.3196e-04 - val_loss: 1.1196\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 742us/step - loss: 6.2014e-04 - val_loss: 1.1201\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 609us/step - loss: 6.1103e-04 - val_loss: 1.1218\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 697us/step - loss: 6.0135e-04 - val_loss: 1.1233\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 688us/step - loss: 5.9219e-04 - val_loss: 1.1258\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 706us/step - loss: 5.8227e-04 - val_loss: 1.1280\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 740us/step - loss: 5.7395e-04 - val_loss: 1.1289\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 689us/step - loss: 5.6351e-04 - val_loss: 1.1307\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 5.5615e-04 - val_loss: 1.1321\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 690us/step - loss: 5.4591e-04 - val_loss: 1.1328\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 688us/step - loss: 5.3796e-04 - val_loss: 1.1346\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 751us/step - loss: 5.2818e-04 - val_loss: 1.1368\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 766us/step - loss: 5.1985e-04 - val_loss: 1.1381\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 594us/step - loss: 5.1199e-04 - val_loss: 1.1395\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 594us/step - loss: 5.0433e-04 - val_loss: 1.1397\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 620us/step - loss: 4.9687e-04 - val_loss: 1.1415\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 590us/step - loss: 4.8913e-04 - val_loss: 1.1435\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 551us/step - loss: 4.8194e-04 - val_loss: 1.1447\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 563us/step - loss: 4.7459e-04 - val_loss: 1.1447\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 559us/step - loss: 4.6803e-04 - val_loss: 1.1461\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 575us/step - loss: 4.6065e-04 - val_loss: 1.1476\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 644us/step - loss: 4.5419e-04 - val_loss: 1.1497\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 566us/step - loss: 4.4751e-04 - val_loss: 1.1514\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 625us/step - loss: 4.4107e-04 - val_loss: 1.1518\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 652us/step - loss: 4.3483e-04 - val_loss: 1.1529\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 591us/step - loss: 4.2848e-04 - val_loss: 1.1539\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 682us/step - loss: 4.2275e-04 - val_loss: 1.1559\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 647us/step - loss: 4.1670e-04 - val_loss: 1.1571\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 642us/step - loss: 4.1123e-04 - val_loss: 1.1574\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 609us/step - loss: 4.0495e-04 - val_loss: 1.1593\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 567us/step - loss: 3.9947e-04 - val_loss: 1.1606\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 581us/step - loss: 3.9381e-04 - val_loss: 1.1621\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 576us/step - loss: 3.8864e-04 - val_loss: 1.1639\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 608us/step - loss: 3.8261e-04 - val_loss: 1.1651\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 609us/step - loss: 3.7765e-04 - val_loss: 1.1661\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 589us/step - loss: 3.7288e-04 - val_loss: 1.1674\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 594us/step - loss: 3.6749e-04 - val_loss: 1.1687\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 679us/step - loss: 3.6227e-04 - val_loss: 1.1702\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 696us/step - loss: 3.5713e-04 - val_loss: 1.1701\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 716us/step - loss: 3.5270e-04 - val_loss: 1.1715\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 694us/step - loss: 3.4790e-04 - val_loss: 1.1726\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 678us/step - loss: 3.4316e-04 - val_loss: 1.1740\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 760us/step - loss: 3.3893e-04 - val_loss: 1.1753\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 775us/step - loss: 3.3434e-04 - val_loss: 1.1767\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 767us/step - loss: 3.3032e-04 - val_loss: 1.1775\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 754us/step - loss: 3.2638e-04 - val_loss: 1.1797\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 705us/step - loss: 3.2190e-04 - val_loss: 1.1796\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 3.1770e-04 - val_loss: 1.1803\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 744us/step - loss: 3.1359e-04 - val_loss: 1.1820\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 724us/step - loss: 3.1008e-04 - val_loss: 1.1830\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 795us/step - loss: 3.0586e-04 - val_loss: 1.1842\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 724us/step - loss: 3.0171e-04 - val_loss: 1.1855\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 717us/step - loss: 2.9873e-04 - val_loss: 1.1867\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 685us/step - loss: 2.9449e-04 - val_loss: 1.1875\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 680us/step - loss: 2.9072e-04 - val_loss: 1.1885\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 728us/step - loss: 2.8731e-04 - val_loss: 1.1899\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 2.8395e-04 - val_loss: 1.1911\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 673us/step - loss: 2.8075e-04 - val_loss: 1.1926\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 2.7745e-04 - val_loss: 1.1930\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 716us/step - loss: 2.7360e-04 - val_loss: 1.1941\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 2.7033e-04 - val_loss: 1.1942\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 2.6735e-04 - val_loss: 1.1950\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 2.6403e-04 - val_loss: 1.1964\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 2.6092e-04 - val_loss: 1.1972\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 733us/step - loss: 2.5794e-04 - val_loss: 1.1980\n",
      "   (0, 30)     relu B\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 8.3413 - val_loss: 8.6559\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 281us/step - loss: 8.0288 - val_loss: 8.3874\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 7.226 - 0s 327us/step - loss: 7.7451 - val_loss: 8.1069\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 7.4374 - val_loss: 7.8027\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 354us/step - loss: 7.1083 - val_loss: 7.4947\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 6.7984 - val_loss: 7.2033\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 6.5108 - val_loss: 6.9344\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 6.2359 - val_loss: 6.6811\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 5.9806 - val_loss: 6.4258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 380us/step - loss: 5.7414 - val_loss: 6.1791\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 5.4942 - val_loss: 5.9482\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 354us/step - loss: 5.2605 - val_loss: 5.7172\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 5.0177 - val_loss: 5.4891\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 349us/step - loss: 4.7582 - val_loss: 5.2510\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 358us/step - loss: 4.5022 - val_loss: 5.0042\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 358us/step - loss: 4.2302 - val_loss: 4.7474\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 3.9589 - val_loss: 4.4730\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 3.6502 - val_loss: 4.1861\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 3.3264 - val_loss: 3.8792\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 3.0352 - val_loss: 3.6373\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 2.7795 - val_loss: 3.4624\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 2.5626 - val_loss: 3.3046\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 389us/step - loss: 2.3565 - val_loss: 3.1512\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 2.1790 - val_loss: 3.0118\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 2.0328 - val_loss: 2.9075\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 1.9167 - val_loss: 2.8358\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 1.8041 - val_loss: 2.7528\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 1.7049 - val_loss: 2.6757\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 1.6247 - val_loss: 2.5967\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 1.5523 - val_loss: 2.5297\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 1.4857 - val_loss: 2.4461\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 1.3851 - val_loss: 2.2869\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 323us/step - loss: 1.2454 - val_loss: 2.1010\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 1.1129 - val_loss: 1.9004\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 291us/step - loss: 0.9398 - val_loss: 1.7116\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.7831 - val_loss: 1.5407\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.6090 - val_loss: 1.3949\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 311us/step - loss: 0.4917 - val_loss: 1.3142\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 0.4208 - val_loss: 1.2941\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 271us/step - loss: 0.3549 - val_loss: 1.2474\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 0.3048 - val_loss: 1.2291\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 284us/step - loss: 0.2637 - val_loss: 1.2143\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 0.2265 - val_loss: 1.2093\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.1977 - val_loss: 1.2019\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.1740 - val_loss: 1.1923\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 304us/step - loss: 0.1532 - val_loss: 1.1850\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.1355 - val_loss: 1.1773\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.1188 - val_loss: 1.1695\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.1058 - val_loss: 1.1691\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 310us/step - loss: 0.0960 - val_loss: 1.1662\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0866 - val_loss: 1.1604\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 0.0798 - val_loss: 1.1526\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0730 - val_loss: 1.1479\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 0.0665 - val_loss: 1.1424\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 313us/step - loss: 0.0619 - val_loss: 1.1402\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.0575 - val_loss: 1.1371\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 0.0531 - val_loss: 1.1350\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.0491 - val_loss: 1.1324\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 0.0463 - val_loss: 1.1319\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 0.0433 - val_loss: 1.1309\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0406 - val_loss: 1.1313\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0382 - val_loss: 1.1324\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 0.0357 - val_loss: 1.1326\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 303us/step - loss: 0.0341 - val_loss: 1.1329\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 272us/step - loss: 0.0320 - val_loss: 1.1328\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 305us/step - loss: 0.0305 - val_loss: 1.1319\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 324us/step - loss: 0.0291 - val_loss: 1.1324\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 362us/step - loss: 0.0276 - val_loss: 1.1326\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 358us/step - loss: 0.0264 - val_loss: 1.1347\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 360us/step - loss: 0.0251 - val_loss: 1.1359\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0241 - val_loss: 1.1357\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 369us/step - loss: 0.0231 - val_loss: 1.1350\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 355us/step - loss: 0.0221 - val_loss: 1.1345\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 0.0213 - val_loss: 1.1339\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.0205 - val_loss: 1.1343\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 0.0196 - val_loss: 1.1344\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 0.0189 - val_loss: 1.1341\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 0.0183 - val_loss: 1.1352\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 0.0176 - val_loss: 1.1357\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 0.0170 - val_loss: 1.1363\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 0.0164 - val_loss: 1.1366\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 343us/step - loss: 0.0159 - val_loss: 1.1366\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 0.0154 - val_loss: 1.1364\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 0.0149 - val_loss: 1.1367\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 354us/step - loss: 0.0144 - val_loss: 1.1368\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 0.0140 - val_loss: 1.1377\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 0.0136 - val_loss: 1.1375\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 0.0132 - val_loss: 1.1388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 0.0128 - val_loss: 1.1404\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.0125 - val_loss: 1.1411\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 361us/step - loss: 0.0121 - val_loss: 1.1413\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 0.0118 - val_loss: 1.1412\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 374us/step - loss: 0.0115 - val_loss: 1.1419\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 333us/step - loss: 0.0112 - val_loss: 1.1420\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 370us/step - loss: 0.0109 - val_loss: 1.1422\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 0.0106 - val_loss: 1.1426\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 368us/step - loss: 0.0104 - val_loss: 1.1432\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 319us/step - loss: 0.0101 - val_loss: 1.1436\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 0.0099 - val_loss: 1.1445\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 0.0096 - val_loss: 1.1451\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.0094 - val_loss: 1.1461\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 0.0092 - val_loss: 1.1469\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.0089 - val_loss: 1.1474\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 343us/step - loss: 0.0087 - val_loss: 1.1482\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 368us/step - loss: 0.0085 - val_loss: 1.1486\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 0.0084 - val_loss: 1.1495\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 0.0082 - val_loss: 1.1501\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 379us/step - loss: 0.0080 - val_loss: 1.1505\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 390us/step - loss: 0.0078 - val_loss: 1.1511\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 0.0077 - val_loss: 1.1510\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 327us/step - loss: 0.0075 - val_loss: 1.1515\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 367us/step - loss: 0.0074 - val_loss: 1.1521\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 0.0072 - val_loss: 1.1528\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 410us/step - loss: 0.0070 - val_loss: 1.1532\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 396us/step - loss: 0.0069 - val_loss: 1.1535\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.0068 - val_loss: 1.1544\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 377us/step - loss: 0.0066 - val_loss: 1.1543\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 362us/step - loss: 0.0065 - val_loss: 1.1551\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 0.0064 - val_loss: 1.1557\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 0.0063 - val_loss: 1.1559\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 400us/step - loss: 0.0062 - val_loss: 1.1566\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 343us/step - loss: 0.0060 - val_loss: 1.1570\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 364us/step - loss: 0.0059 - val_loss: 1.1576\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 0.0058 - val_loss: 1.1579\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 378us/step - loss: 0.0057 - val_loss: 1.1582\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 343us/step - loss: 0.0056 - val_loss: 1.1591\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 400us/step - loss: 0.0055 - val_loss: 1.1595\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 356us/step - loss: 0.0054 - val_loss: 1.1602\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 362us/step - loss: 0.0053 - val_loss: 1.1609\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 0.0052 - val_loss: 1.1610\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 385us/step - loss: 0.0052 - val_loss: 1.1613\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 372us/step - loss: 0.0051 - val_loss: 1.1618\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 0.0050 - val_loss: 1.1624\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.0049 - val_loss: 1.1627\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 0.0048 - val_loss: 1.1634\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 0.0047 - val_loss: 1.1639\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 363us/step - loss: 0.0047 - val_loss: 1.1644\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.0046 - val_loss: 1.1651\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 352us/step - loss: 0.0045 - val_loss: 1.1658\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 0.0044 - val_loss: 1.1661\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 354us/step - loss: 0.0044 - val_loss: 1.1665\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 317us/step - loss: 0.0043 - val_loss: 1.1667\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 0.0042 - val_loss: 1.1671\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 352us/step - loss: 0.0042 - val_loss: 1.1679\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 354us/step - loss: 0.0041 - val_loss: 1.1682\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 0.0041 - val_loss: 1.1688\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 0.0040 - val_loss: 1.1693\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 328us/step - loss: 0.0039 - val_loss: 1.1699\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 381us/step - loss: 0.0039 - val_loss: 1.1706\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0038 - val_loss: 1.1711\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 365us/step - loss: 0.0038 - val_loss: 1.1713\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 0.0037 - val_loss: 1.1718\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 406us/step - loss: 0.0037 - val_loss: 1.1724\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 361us/step - loss: 0.0036 - val_loss: 1.1728\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 361us/step - loss: 0.0036 - val_loss: 1.1732\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 359us/step - loss: 0.0035 - val_loss: 1.1737\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 362us/step - loss: 0.0035 - val_loss: 1.1737\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 362us/step - loss: 0.0034 - val_loss: 1.1739\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.0034 - val_loss: 1.1743\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 342us/step - loss: 0.0033 - val_loss: 1.1749\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 339us/step - loss: 0.0033 - val_loss: 1.1755\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 389us/step - loss: 0.0032 - val_loss: 1.1761\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 361us/step - loss: 0.0032 - val_loss: 1.1767\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 375us/step - loss: 0.0032 - val_loss: 1.1769\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 365us/step - loss: 0.0031 - val_loss: 1.1774\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 374us/step - loss: 0.0031 - val_loss: 1.1781\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 291us/step - loss: 0.0030 - val_loss: 1.1787\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0030 - val_loss: 1.1791\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 364us/step - loss: 0.0030 - val_loss: 1.1794\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 0.0029 - val_loss: 1.1799\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 0.0029 - val_loss: 1.1800\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 352us/step - loss: 0.0029 - val_loss: 1.1805\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 349us/step - loss: 0.0028 - val_loss: 1.1810\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 0.0028 - val_loss: 1.1812\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 0.0027 - val_loss: 1.1815\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 338us/step - loss: 0.0027 - val_loss: 1.1821\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 347us/step - loss: 0.0027 - val_loss: 1.1823\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 0.0027 - val_loss: 1.1828\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 0.0026 - val_loss: 1.1834\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.0026 - val_loss: 1.1836\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 0.0026 - val_loss: 1.1839\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 345us/step - loss: 0.0025 - val_loss: 1.1840\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 0.0025 - val_loss: 1.1845\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.002 - 0s 323us/step - loss: 0.0025 - val_loss: 1.1846\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 352us/step - loss: 0.0024 - val_loss: 1.1852\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 318us/step - loss: 0.0024 - val_loss: 1.1857\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 329us/step - loss: 0.0024 - val_loss: 1.1862\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 320us/step - loss: 0.0024 - val_loss: 1.1864\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 365us/step - loss: 0.0023 - val_loss: 1.1870\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 302us/step - loss: 0.0023 - val_loss: 1.1871\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 301us/step - loss: 0.0023 - val_loss: 1.1877\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 0.0023 - val_loss: 1.1878\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 0.0022 - val_loss: 1.1884\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 0.0022 - val_loss: 1.1889\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 312us/step - loss: 0.0022 - val_loss: 1.1892\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 0.0022 - val_loss: 1.1891\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 306us/step - loss: 0.0021 - val_loss: 1.1892\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 315us/step - loss: 0.0021 - val_loss: 1.1896\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 309us/step - loss: 0.0021 - val_loss: 1.1902\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 351us/step - loss: 0.0021 - val_loss: 1.1908\n",
      "   (0, 30)     relu C\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 8.6025 - val_loss: 7.7840\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 596us/step - loss: 7.5340 - val_loss: 6.8776\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 577us/step - loss: 6.4243 - val_loss: 5.8678\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 553us/step - loss: 5.1771 - val_loss: 4.7329\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 571us/step - loss: 3.9791 - val_loss: 3.7555\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 568us/step - loss: 3.0506 - val_loss: 3.0391\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 535us/step - loss: 2.3925 - val_loss: 2.5392\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 574us/step - loss: 1.9413 - val_loss: 2.2114\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 667us/step - loss: 1.6089 - val_loss: 1.9260\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 1.3554 - val_loss: 1.7370\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 686us/step - loss: 1.1481 - val_loss: 1.5760\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 665us/step - loss: 0.9678 - val_loss: 1.4481\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 0.7965 - val_loss: 1.3374\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 714us/step - loss: 0.6662 - val_loss: 1.2289\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 759us/step - loss: 0.5346 - val_loss: 1.1458\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 693us/step - loss: 0.4377 - val_loss: 1.0721\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 660us/step - loss: 0.3617 - val_loss: 1.0369\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 0.3022 - val_loss: 0.9660\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 649us/step - loss: 0.2497 - val_loss: 0.9271\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 672us/step - loss: 0.2142 - val_loss: 0.9032\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 0.1956 - val_loss: 0.9021\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 693us/step - loss: 0.1582 - val_loss: 0.8356\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 667us/step - loss: 0.1405 - val_loss: 0.8291\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 710us/step - loss: 0.1205 - val_loss: 0.8131\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 668us/step - loss: 0.1073 - val_loss: 0.8038\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 654us/step - loss: 0.0948 - val_loss: 0.7937\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 0.0840 - val_loss: 0.7811\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 689us/step - loss: 0.0753 - val_loss: 0.7801\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 715us/step - loss: 0.0670 - val_loss: 0.7698\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 710us/step - loss: 0.0611 - val_loss: 0.7542\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 675us/step - loss: 0.0547 - val_loss: 0.7564\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 689us/step - loss: 0.0513 - val_loss: 0.7523\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 745us/step - loss: 0.0470 - val_loss: 0.7353\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 747us/step - loss: 0.0430 - val_loss: 0.7334\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 683us/step - loss: 0.0403 - val_loss: 0.7348\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 0.0373 - val_loss: 0.7315\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 677us/step - loss: 0.0351 - val_loss: 0.7248\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 677us/step - loss: 0.0326 - val_loss: 0.7200\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 0.0302 - val_loss: 0.7208\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 781us/step - loss: 0.0285 - val_loss: 0.7205\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 0.0268 - val_loss: 0.7168\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 746us/step - loss: 0.0252 - val_loss: 0.7189\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 693us/step - loss: 0.0238 - val_loss: 0.7121\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 700us/step - loss: 0.0224 - val_loss: 0.7146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 668us/step - loss: 0.0214 - val_loss: 0.7136\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 679us/step - loss: 0.0202 - val_loss: 0.7130\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 660us/step - loss: 0.0191 - val_loss: 0.7110\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 726us/step - loss: 0.0182 - val_loss: 0.7063\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 0.0174 - val_loss: 0.7059\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 0.0165 - val_loss: 0.7066\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 680us/step - loss: 0.0159 - val_loss: 0.7086\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 675us/step - loss: 0.0152 - val_loss: 0.7049\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 671us/step - loss: 0.0144 - val_loss: 0.7050\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 723us/step - loss: 0.0139 - val_loss: 0.7030\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 622us/step - loss: 0.0133 - val_loss: 0.7035\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 0.0128 - val_loss: 0.7026\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 702us/step - loss: 0.0122 - val_loss: 0.7064\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 0.0119 - val_loss: 0.7086\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 733us/step - loss: 0.0113 - val_loss: 0.7035\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 686us/step - loss: 0.0109 - val_loss: 0.7017\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 732us/step - loss: 0.0105 - val_loss: 0.7027\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 652us/step - loss: 0.0102 - val_loss: 0.7029\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 0.0098 - val_loss: 0.7032\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 680us/step - loss: 0.0095 - val_loss: 0.7034\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 702us/step - loss: 0.0092 - val_loss: 0.7047\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 658us/step - loss: 0.0089 - val_loss: 0.7028\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 733us/step - loss: 0.0086 - val_loss: 0.7065\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 704us/step - loss: 0.0083 - val_loss: 0.7043\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 570us/step - loss: 0.0080 - val_loss: 0.7016\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 622us/step - loss: 0.0078 - val_loss: 0.7029\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 0.0075 - val_loss: 0.7028\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 0.0073 - val_loss: 0.7040\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 679us/step - loss: 0.0071 - val_loss: 0.7041\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 674us/step - loss: 0.0069 - val_loss: 0.7038\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 640us/step - loss: 0.0067 - val_loss: 0.7047\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 668us/step - loss: 0.0065 - val_loss: 0.7034\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 676us/step - loss: 0.0063 - val_loss: 0.7042\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 0.0061 - val_loss: 0.7049\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 0.0060 - val_loss: 0.7055\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 0.0058 - val_loss: 0.7056\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 671us/step - loss: 0.0056 - val_loss: 0.7065\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 551us/step - loss: 0.0055 - val_loss: 0.7043\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 566us/step - loss: 0.0054 - val_loss: 0.7069\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 533us/step - loss: 0.0052 - val_loss: 0.7073\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 549us/step - loss: 0.0051 - val_loss: 0.7060\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 624us/step - loss: 0.0050 - val_loss: 0.7049\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 583us/step - loss: 0.0049 - val_loss: 0.7063\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 624us/step - loss: 0.0047 - val_loss: 0.7079\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 605us/step - loss: 0.0046 - val_loss: 0.7081\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 556us/step - loss: 0.0045 - val_loss: 0.7078\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 542us/step - loss: 0.0044 - val_loss: 0.7088\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 637us/step - loss: 0.0043 - val_loss: 0.7088\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 593us/step - loss: 0.0042 - val_loss: 0.7091\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 670us/step - loss: 0.0041 - val_loss: 0.7093\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 553us/step - loss: 0.0040 - val_loss: 0.7111\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 569us/step - loss: 0.0039 - val_loss: 0.7103\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 570us/step - loss: 0.0038 - val_loss: 0.7088\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 578us/step - loss: 0.0038 - val_loss: 0.7102\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 583us/step - loss: 0.0037 - val_loss: 0.7124\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 614us/step - loss: 0.0036 - val_loss: 0.7120\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 603us/step - loss: 0.0035 - val_loss: 0.7122\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 576us/step - loss: 0.0034 - val_loss: 0.7120\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 589us/step - loss: 0.0034 - val_loss: 0.7128\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 587us/step - loss: 0.0033 - val_loss: 0.7122\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 636us/step - loss: 0.0032 - val_loss: 0.7132\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 610us/step - loss: 0.0032 - val_loss: 0.7136\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 645us/step - loss: 0.0031 - val_loss: 0.7123\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 572us/step - loss: 0.0030 - val_loss: 0.7149\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 594us/step - loss: 0.0030 - val_loss: 0.7161\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 973us/step - loss: 0.0029 - val_loss: 0.7141\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 561us/step - loss: 0.0029 - val_loss: 0.7170\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 569us/step - loss: 0.0028 - val_loss: 0.7171\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 587us/step - loss: 0.0028 - val_loss: 0.7166\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 553us/step - loss: 0.0027 - val_loss: 0.7173\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 688us/step - loss: 0.0027 - val_loss: 0.7190\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 755us/step - loss: 0.0026 - val_loss: 0.7183\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 749us/step - loss: 0.0026 - val_loss: 0.7175\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 676us/step - loss: 0.0025 - val_loss: 0.7182\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 0.0025 - val_loss: 0.7185\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 743us/step - loss: 0.0024 - val_loss: 0.7202\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 673us/step - loss: 0.0024 - val_loss: 0.7200\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 699us/step - loss: 0.0023 - val_loss: 0.7187\n",
      "Epoch 123/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 701us/step - loss: 0.0023 - val_loss: 0.7206\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 696us/step - loss: 0.0023 - val_loss: 0.7215\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 0.0022 - val_loss: 0.7228\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 714us/step - loss: 0.0022 - val_loss: 0.7217\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 739us/step - loss: 0.0022 - val_loss: 0.7212\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 667us/step - loss: 0.0021 - val_loss: 0.7213\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 656us/step - loss: 0.0021 - val_loss: 0.7226\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 713us/step - loss: 0.0020 - val_loss: 0.7236\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 737us/step - loss: 0.0020 - val_loss: 0.7245\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 704us/step - loss: 0.0020 - val_loss: 0.7245\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 0.0019 - val_loss: 0.7250\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 0.0019 - val_loss: 0.7255\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 0.0019 - val_loss: 0.7251\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 0.0019 - val_loss: 0.7265\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 705us/step - loss: 0.0018 - val_loss: 0.7274\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 0.0018 - val_loss: 0.7269\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 715us/step - loss: 0.0018 - val_loss: 0.7259\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 696us/step - loss: 0.0018 - val_loss: 0.7263\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 733us/step - loss: 0.0017 - val_loss: 0.7267\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 0.0017 - val_loss: 0.7276\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 660us/step - loss: 0.0017 - val_loss: 0.7289\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 705us/step - loss: 0.0016 - val_loss: 0.7291\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 731us/step - loss: 0.0016 - val_loss: 0.7297\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 754us/step - loss: 0.0016 - val_loss: 0.7293\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 676us/step - loss: 0.0016 - val_loss: 0.7299\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 772us/step - loss: 0.0016 - val_loss: 0.7294\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 771us/step - loss: 0.0015 - val_loss: 0.7302\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 770us/step - loss: 0.0015 - val_loss: 0.7299\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 739us/step - loss: 0.0015 - val_loss: 0.7293\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.001 - 0s 648us/step - loss: 0.0015 - val_loss: 0.7306\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 735us/step - loss: 0.0014 - val_loss: 0.7316\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 705us/step - loss: 0.0014 - val_loss: 0.7313\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 743us/step - loss: 0.0014 - val_loss: 0.7308\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 706us/step - loss: 0.0014 - val_loss: 0.7314\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 636us/step - loss: 0.0014 - val_loss: 0.7336\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 741us/step - loss: 0.0013 - val_loss: 0.7339\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 742us/step - loss: 0.0013 - val_loss: 0.7340\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 801us/step - loss: 0.0013 - val_loss: 0.7345\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 665us/step - loss: 0.0013 - val_loss: 0.7353\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 743us/step - loss: 0.0013 - val_loss: 0.7356\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 731us/step - loss: 0.0013 - val_loss: 0.7360\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 729us/step - loss: 0.0012 - val_loss: 0.7369\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 0.0012 - val_loss: 0.7360\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 676us/step - loss: 0.0012 - val_loss: 0.7366\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 0.0012 - val_loss: 0.7374\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 754us/step - loss: 0.0012 - val_loss: 0.7389\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 733us/step - loss: 0.0012 - val_loss: 0.7388\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 691us/step - loss: 0.0011 - val_loss: 0.7390\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 677us/step - loss: 0.0011 - val_loss: 0.7389\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 691us/step - loss: 0.0011 - val_loss: 0.7397\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 0.0011 - val_loss: 0.7402\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 729us/step - loss: 0.0011 - val_loss: 0.7401\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 713us/step - loss: 0.0011 - val_loss: 0.7406\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 644us/step - loss: 0.0011 - val_loss: 0.7412\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 666us/step - loss: 0.0010 - val_loss: 0.7410\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 671us/step - loss: 0.0010 - val_loss: 0.7408\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 561us/step - loss: 0.0010 - val_loss: 0.7416\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 681us/step - loss: 0.0010 - val_loss: 0.7412\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 628us/step - loss: 9.9701e-04 - val_loss: 0.7422\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 665us/step - loss: 9.8437e-04 - val_loss: 0.7423\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 712us/step - loss: 9.7265e-04 - val_loss: 0.7426\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 667us/step - loss: 9.6089e-04 - val_loss: 0.7438\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 680us/step - loss: 9.5029e-04 - val_loss: 0.7435\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 675us/step - loss: 9.3708e-04 - val_loss: 0.7438\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 641us/step - loss: 9.2579e-04 - val_loss: 0.7446\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 664us/step - loss: 9.1394e-04 - val_loss: 0.7453\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 662us/step - loss: 9.0556e-04 - val_loss: 0.7467\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 635us/step - loss: 8.9311e-04 - val_loss: 0.7470\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 678us/step - loss: 8.8292e-04 - val_loss: 0.7466\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 574us/step - loss: 8.7279e-04 - val_loss: 0.7470\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 595us/step - loss: 8.6203e-04 - val_loss: 0.7484\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 572us/step - loss: 8.5291e-04 - val_loss: 0.7485\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 595us/step - loss: 8.4278e-04 - val_loss: 0.7486\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 598us/step - loss: 8.3380e-04 - val_loss: 0.7493\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 608us/step - loss: 8.2340e-04 - val_loss: 0.7494\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 584us/step - loss: 8.1451e-04 - val_loss: 0.7500\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 561us/step - loss: 8.0543e-04 - val_loss: 0.7500\n",
      "Epoch 200/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 606us/step - loss: 7.9613e-04 - val_loss: 0.7505\n",
      "   (0, 30)     tanh A\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.2437 - val_loss: 2.1307\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 575us/step - loss: 1.9497 - val_loss: 1.9232\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 600us/step - loss: 1.6959 - val_loss: 1.7270\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 594us/step - loss: 1.4606 - val_loss: 1.5340\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 700us/step - loss: 1.2556 - val_loss: 1.3639\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 742us/step - loss: 1.0699 - val_loss: 1.2221\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 758us/step - loss: 0.9071 - val_loss: 1.0993\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 731us/step - loss: 0.7745 - val_loss: 1.0076\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 0.6590 - val_loss: 0.9317\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 759us/step - loss: 0.5677 - val_loss: 0.8787\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 714us/step - loss: 0.4947 - val_loss: 0.8285\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 738us/step - loss: 0.4305 - val_loss: 0.7897\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 0.3736 - val_loss: 0.7612\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 688us/step - loss: 0.3225 - val_loss: 0.7310\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 713us/step - loss: 0.2822 - val_loss: 0.7193\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 736us/step - loss: 0.2558 - val_loss: 0.6942\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 0.2188 - val_loss: 0.6808\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1956 - val_loss: 0.6747\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1781 - val_loss: 0.6612\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1589 - val_loss: 0.6580\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1427 - val_loss: 0.6472\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 908us/step - loss: 0.1279 - val_loss: 0.6519\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 704us/step - loss: 0.1168 - val_loss: 0.6442\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 0.1063 - val_loss: 0.6370\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 0.0976 - val_loss: 0.6436\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 718us/step - loss: 0.0901 - val_loss: 0.6346\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 0.0832 - val_loss: 0.6372\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 712us/step - loss: 0.0776 - val_loss: 0.6321\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 0.0722 - val_loss: 0.6357\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 0.0673 - val_loss: 0.6337\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 915us/step - loss: 0.0630 - val_loss: 0.6351\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 923us/step - loss: 0.0592 - val_loss: 0.6315\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0560 - val_loss: 0.6385\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 902us/step - loss: 0.0527 - val_loss: 0.6333\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 794us/step - loss: 0.0500 - val_loss: 0.6319\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 742us/step - loss: 0.0472 - val_loss: 0.6351\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 717us/step - loss: 0.0449 - val_loss: 0.6326\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 700us/step - loss: 0.0426 - val_loss: 0.6330\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 0.0407 - val_loss: 0.6408\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 0.0387 - val_loss: 0.6366\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 739us/step - loss: 0.0370 - val_loss: 0.6363\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 729us/step - loss: 0.0353 - val_loss: 0.6403\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 736us/step - loss: 0.0338 - val_loss: 0.6381\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 733us/step - loss: 0.0323 - val_loss: 0.6419\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 0.0311 - val_loss: 0.6409\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 746us/step - loss: 0.0297 - val_loss: 0.6388\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 852us/step - loss: 0.0286 - val_loss: 0.6404\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 822us/step - loss: 0.0275 - val_loss: 0.6448\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 757us/step - loss: 0.0265 - val_loss: 0.6437\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 722us/step - loss: 0.0256 - val_loss: 0.6424\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 676us/step - loss: 0.0246 - val_loss: 0.6458\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 748us/step - loss: 0.0238 - val_loss: 0.6487\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 702us/step - loss: 0.0230 - val_loss: 0.6471\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 726us/step - loss: 0.0222 - val_loss: 0.6457\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 712us/step - loss: 0.0215 - val_loss: 0.6504\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 0.0208 - val_loss: 0.6510\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 726us/step - loss: 0.0202 - val_loss: 0.6505\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 0.0196 - val_loss: 0.6517\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 740us/step - loss: 0.0190 - val_loss: 0.6539\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 662us/step - loss: 0.0184 - val_loss: 0.6569\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 704us/step - loss: 0.0179 - val_loss: 0.6533\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 715us/step - loss: 0.0173 - val_loss: 0.6545\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 701us/step - loss: 0.0169 - val_loss: 0.6567\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 694us/step - loss: 0.0164 - val_loss: 0.6606\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 697us/step - loss: 0.0159 - val_loss: 0.6611\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 0.0155 - val_loss: 0.6620\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 0.0151 - val_loss: 0.6614\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 718us/step - loss: 0.0147 - val_loss: 0.6636\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 603us/step - loss: 0.0144 - val_loss: 0.6650\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 677us/step - loss: 0.0140 - val_loss: 0.6628\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 710us/step - loss: 0.0137 - val_loss: 0.6623\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 0.0133 - val_loss: 0.6652\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 757us/step - loss: 0.0130 - val_loss: 0.6686\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 723us/step - loss: 0.0127 - val_loss: 0.6688\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 0.0124 - val_loss: 0.6669\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 0.0121 - val_loss: 0.6679\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 705us/step - loss: 0.0119 - val_loss: 0.6700\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 784us/step - loss: 0.0116 - val_loss: 0.6719\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 730us/step - loss: 0.0113 - val_loss: 0.6728\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 705us/step - loss: 0.0111 - val_loss: 0.6730\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 692us/step - loss: 0.0108 - val_loss: 0.6771\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 666us/step - loss: 0.0106 - val_loss: 0.6768\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 581us/step - loss: 0.0104 - val_loss: 0.6744\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 616us/step - loss: 0.0102 - val_loss: 0.6781\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 633us/step - loss: 0.0100 - val_loss: 0.6817\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 588us/step - loss: 0.0098 - val_loss: 0.6812\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 602us/step - loss: 0.0096 - val_loss: 0.6823\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 603us/step - loss: 0.0094 - val_loss: 0.6841\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 641us/step - loss: 0.0092 - val_loss: 0.6836\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 570us/step - loss: 0.0090 - val_loss: 0.6840\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 574us/step - loss: 0.0089 - val_loss: 0.6870\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 584us/step - loss: 0.0087 - val_loss: 0.6880\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 589us/step - loss: 0.0085 - val_loss: 0.6885\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 609us/step - loss: 0.0084 - val_loss: 0.6893\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 882us/step - loss: 0.0082 - val_loss: 0.6897\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 779us/step - loss: 0.0081 - val_loss: 0.6891\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.6926\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 674us/step - loss: 0.0078 - val_loss: 0.6937\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 622us/step - loss: 0.0077 - val_loss: 0.6934\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 595us/step - loss: 0.0075 - val_loss: 0.6966\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 659us/step - loss: 0.0074 - val_loss: 0.6953\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 668us/step - loss: 0.0073 - val_loss: 0.6971\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 639us/step - loss: 0.0071 - val_loss: 0.6968\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 607us/step - loss: 0.0070 - val_loss: 0.6997\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 620us/step - loss: 0.0069 - val_loss: 0.7001\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 583us/step - loss: 0.0068 - val_loss: 0.7020\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 0.0067 - val_loss: 0.7030\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 608us/step - loss: 0.0066 - val_loss: 0.7034\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 600us/step - loss: 0.0065 - val_loss: 0.7027\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 615us/step - loss: 0.0064 - val_loss: 0.7042\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 633us/step - loss: 0.0063 - val_loss: 0.7051\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 671us/step - loss: 0.0062 - val_loss: 0.7062\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 619us/step - loss: 0.0061 - val_loss: 0.7071\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 630us/step - loss: 0.0060 - val_loss: 0.7082\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 613us/step - loss: 0.0059 - val_loss: 0.7092\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 619us/step - loss: 0.0058 - val_loss: 0.7090\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 609us/step - loss: 0.0057 - val_loss: 0.7113\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 757us/step - loss: 0.0056 - val_loss: 0.7116\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 713us/step - loss: 0.0056 - val_loss: 0.7123\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 681us/step - loss: 0.0055 - val_loss: 0.7127\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 0.0054 - val_loss: 0.7149\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 717us/step - loss: 0.0053 - val_loss: 0.7155\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 715us/step - loss: 0.0052 - val_loss: 0.7158\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 650us/step - loss: 0.0052 - val_loss: 0.7179\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 0.0051 - val_loss: 0.7185\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 0.0050 - val_loss: 0.7181\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 645us/step - loss: 0.0050 - val_loss: 0.7189\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 716us/step - loss: 0.0049 - val_loss: 0.7205\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 715us/step - loss: 0.0048 - val_loss: 0.7209\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 700us/step - loss: 0.0048 - val_loss: 0.7212\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 674us/step - loss: 0.0047 - val_loss: 0.7219\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 678us/step - loss: 0.0046 - val_loss: 0.7226\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 706us/step - loss: 0.0046 - val_loss: 0.7229\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 705us/step - loss: 0.0045 - val_loss: 0.7234\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 736us/step - loss: 0.0044 - val_loss: 0.7251\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 729us/step - loss: 0.0044 - val_loss: 0.7266\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 705us/step - loss: 0.0043 - val_loss: 0.7288\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 0.0043 - val_loss: 0.7299\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 747us/step - loss: 0.0042 - val_loss: 0.7287\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 726us/step - loss: 0.0042 - val_loss: 0.7294\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 670us/step - loss: 0.0041 - val_loss: 0.7312\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 656us/step - loss: 0.0041 - val_loss: 0.7316\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.7332\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 633us/step - loss: 0.0040 - val_loss: 0.7337\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 679us/step - loss: 0.0039 - val_loss: 0.7347\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 680us/step - loss: 0.0039 - val_loss: 0.7350\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 653us/step - loss: 0.0038 - val_loss: 0.7365\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 640us/step - loss: 0.0038 - val_loss: 0.7369\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 647us/step - loss: 0.0037 - val_loss: 0.7380\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 679us/step - loss: 0.0037 - val_loss: 0.7387\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 657us/step - loss: 0.0036 - val_loss: 0.7399\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 628us/step - loss: 0.0036 - val_loss: 0.7412\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 675us/step - loss: 0.0035 - val_loss: 0.7420\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 0.0035 - val_loss: 0.7432\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 667us/step - loss: 0.0035 - val_loss: 0.7440\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 622us/step - loss: 0.0034 - val_loss: 0.7452\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 644us/step - loss: 0.0034 - val_loss: 0.7440\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 678us/step - loss: 0.0033 - val_loss: 0.7443\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 631us/step - loss: 0.0033 - val_loss: 0.7456\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 755us/step - loss: 0.0033 - val_loss: 0.7460\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 791us/step - loss: 0.0032 - val_loss: 0.7470\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 781us/step - loss: 0.0032 - val_loss: 0.7484\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 0.0032 - val_loss: 0.7495\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 0.0031 - val_loss: 0.7504\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 654us/step - loss: 0.0031 - val_loss: 0.7517\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 641us/step - loss: 0.0031 - val_loss: 0.7517\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 671us/step - loss: 0.0030 - val_loss: 0.7532\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 668us/step - loss: 0.0030 - val_loss: 0.7542\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 659us/step - loss: 0.0030 - val_loss: 0.7536\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 658us/step - loss: 0.0029 - val_loss: 0.7553\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 656us/step - loss: 0.0029 - val_loss: 0.7551\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 665us/step - loss: 0.0029 - val_loss: 0.7562\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 661us/step - loss: 0.0028 - val_loss: 0.7571\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 632us/step - loss: 0.0028 - val_loss: 0.7580\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 657us/step - loss: 0.0028 - val_loss: 0.7579\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 667us/step - loss: 0.0027 - val_loss: 0.7588\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 716us/step - loss: 0.0027 - val_loss: 0.7594\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 622us/step - loss: 0.0027 - val_loss: 0.7603\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 674us/step - loss: 0.0027 - val_loss: 0.7606\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 657us/step - loss: 0.0026 - val_loss: 0.7614\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 664us/step - loss: 0.0026 - val_loss: 0.7624\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 659us/step - loss: 0.0026 - val_loss: 0.7634\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 649us/step - loss: 0.0025 - val_loss: 0.7645\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 627us/step - loss: 0.0025 - val_loss: 0.7652\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.002 - 0s 658us/step - loss: 0.0025 - val_loss: 0.7661\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 698us/step - loss: 0.0025 - val_loss: 0.7662\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 704us/step - loss: 0.0024 - val_loss: 0.7670\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 654us/step - loss: 0.0024 - val_loss: 0.7681\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 655us/step - loss: 0.0024 - val_loss: 0.7681\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 644us/step - loss: 0.0024 - val_loss: 0.7694\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 671us/step - loss: 0.0023 - val_loss: 0.7702\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 624us/step - loss: 0.0023 - val_loss: 0.7705\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 652us/step - loss: 0.0023 - val_loss: 0.7714\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 632us/step - loss: 0.0023 - val_loss: 0.7720\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 641us/step - loss: 0.0023 - val_loss: 0.7730\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 644us/step - loss: 0.0022 - val_loss: 0.7740\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 645us/step - loss: 0.0022 - val_loss: 0.7745\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 669us/step - loss: 0.0022 - val_loss: 0.7745\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 663us/step - loss: 0.0022 - val_loss: 0.7750\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 643us/step - loss: 0.0022 - val_loss: 0.7761\n",
      "   (0, 30)     tanh B\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 9.3984 - val_loss: 9.4495\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 267us/step - loss: 8.8667 - val_loss: 8.9366\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 283us/step - loss: 8.3678 - val_loss: 8.4723\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 7.9345 - val_loss: 8.0299\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 295us/step - loss: 7.5241 - val_loss: 7.6121\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 260us/step - loss: 7.1491 - val_loss: 7.2384\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 6.8145 - val_loss: 6.9176\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 6.5308 - val_loss: 6.6393\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 6.2778 - val_loss: 6.3994\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 268us/step - loss: 6.0600 - val_loss: 6.1827\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 5.8523 - val_loss: 5.9799\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 270us/step - loss: 5.6622 - val_loss: 5.7921\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 5.899 - 0s 340us/step - loss: 5.4954 - val_loss: 5.6160\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 341us/step - loss: 5.3293 - val_loss: 5.4417\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 265us/step - loss: 5.1733 - val_loss: 5.2684\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 300us/step - loss: 5.0175 - val_loss: 5.1051\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 4.8696 - val_loss: 4.9477\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 4.7251 - val_loss: 4.7961\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 4.5855 - val_loss: 4.6450\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 288us/step - loss: 4.4529 - val_loss: 4.4899\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 297us/step - loss: 4.3172 - val_loss: 4.3379\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 285us/step - loss: 4.1841 - val_loss: 4.1935\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 405us/step - loss: 4.0581 - val_loss: 4.0533\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 387us/step - loss: 3.9327 - val_loss: 3.9164\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 3.8094 - val_loss: 3.7840\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 269us/step - loss: 3.6879 - val_loss: 3.6587\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 279us/step - loss: 3.5777 - val_loss: 3.5393\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 3.4740 - val_loss: 3.4249\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 290us/step - loss: 3.3725 - val_loss: 3.3128\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 3.2763 - val_loss: 3.2102\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 289us/step - loss: 3.1867 - val_loss: 3.1156\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 280us/step - loss: 3.1036 - val_loss: 3.0270\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 286us/step - loss: 3.0255 - val_loss: 2.9443\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 287us/step - loss: 2.9494 - val_loss: 2.8665\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 286us/step - loss: 2.8828 - val_loss: 2.7930\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 253us/step - loss: 2.8168 - val_loss: 2.7262\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 299us/step - loss: 2.7589 - val_loss: 2.6632\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 294us/step - loss: 2.7044 - val_loss: 2.6035\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 296us/step - loss: 2.6499 - val_loss: 2.5482\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 2.5994 - val_loss: 2.4957\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 2.5513 - val_loss: 2.4453\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 282us/step - loss: 2.5059 - val_loss: 2.3976\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 277us/step - loss: 2.4606 - val_loss: 2.3535\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 251us/step - loss: 2.4190 - val_loss: 2.3124\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 292us/step - loss: 2.3779 - val_loss: 2.2738\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 2.3406 - val_loss: 2.2356\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 316us/step - loss: 2.3055 - val_loss: 2.1969\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 346us/step - loss: 2.2732 - val_loss: 2.1605\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 2.2436 - val_loss: 2.1292\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 2.2158 - val_loss: 2.1002\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 663us/step - loss: 2.1895 - val_loss: 2.0728\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 508us/step - loss: 2.1636 - val_loss: 2.0474\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 2.1424 - val_loss: 2.0230\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 2.1202 - val_loss: 2.0026\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 2.1034 - val_loss: 1.9836\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 2.0858 - val_loss: 1.9667\n",
      "Epoch 57/200\n",
      "100/300 [=========>....................] - ETA: 0s - loss: 2.4044WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.433025). Check your callbacks.\n",
      "200/300 [===================>..........] - ETA: 0s - loss: 2.2215WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.218882). Check your callbacks.\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 2.0695 - val_loss: 1.9502\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 508us/step - loss: 2.0553 - val_loss: 1.9359\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 429us/step - loss: 2.0427 - val_loss: 1.9233\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 474us/step - loss: 2.0295 - val_loss: 1.9126\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 691us/step - loss: 2.0180 - val_loss: 1.9025\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 454us/step - loss: 2.0068 - val_loss: 1.8944\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 407us/step - loss: 1.9962 - val_loss: 1.8861\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 427us/step - loss: 1.9868 - val_loss: 1.8765\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 486us/step - loss: 1.9766 - val_loss: 1.8685\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 594us/step - loss: 1.9670 - val_loss: 1.8622\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 1.9580 - val_loss: 1.8575\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 1.9500 - val_loss: 1.8524\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 1.9415 - val_loss: 1.8447\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 1.9340 - val_loss: 1.8380\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 1.9267 - val_loss: 1.8333\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 908us/step - loss: 1.9193 - val_loss: 1.8266\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 960us/step - loss: 1.9126 - val_loss: 1.8207\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 970us/step - loss: 1.9061 - val_loss: 1.8152\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 1.9000 - val_loss: 1.8084\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 580us/step - loss: 1.8938 - val_loss: 1.8052\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 541us/step - loss: 1.8878 - val_loss: 1.8013\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 1.8822 - val_loss: 1.7971\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 630us/step - loss: 1.8766 - val_loss: 1.7935\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 1.8713 - val_loss: 1.7894\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 1.8660 - val_loss: 1.7854\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 1.8612 - val_loss: 1.7833\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 894us/step - loss: 1.8564 - val_loss: 1.7800\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 1.8518 - val_loss: 1.7771\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 1.8470 - val_loss: 1.7751\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 1.8428 - val_loss: 1.7725\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 1.8386 - val_loss: 1.7684\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 1.8341 - val_loss: 1.7651\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 1.8297 - val_loss: 1.7642\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 417us/step - loss: 1.8252 - val_loss: 1.7633\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 523us/step - loss: 1.8203 - val_loss: 1.7635\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 584us/step - loss: 1.8154 - val_loss: 1.7637\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 984us/step - loss: 1.8111 - val_loss: 1.7613\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 633us/step - loss: 1.8072 - val_loss: 1.7578\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 903us/step - loss: 1.8032 - val_loss: 1.7539\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 823us/step - loss: 1.7994 - val_loss: 1.7512\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 499us/step - loss: 1.7955 - val_loss: 1.7493\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 365us/step - loss: 1.7922 - val_loss: 1.7473\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 369us/step - loss: 1.7888 - val_loss: 1.7457\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 380us/step - loss: 1.7856 - val_loss: 1.7448\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 444us/step - loss: 1.7824 - val_loss: 1.7408\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 1.7794 - val_loss: 1.7360\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 353us/step - loss: 1.7764 - val_loss: 1.7343\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 400us/step - loss: 1.7735 - val_loss: 1.7314\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 1.7708 - val_loss: 1.7286\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 661us/step - loss: 1.7682 - val_loss: 1.7279\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 536us/step - loss: 1.7654 - val_loss: 1.7246\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 492us/step - loss: 1.7625 - val_loss: 1.7198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 548us/step - loss: 1.7597 - val_loss: 1.7173\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 654us/step - loss: 1.7569 - val_loss: 1.7178\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 637us/step - loss: 1.7538 - val_loss: 1.7155\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 413us/step - loss: 1.7510 - val_loss: 1.7132\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 408us/step - loss: 1.7480 - val_loss: 1.7095\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 367us/step - loss: 1.7450 - val_loss: 1.7075\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 1.7421 - val_loss: 1.7040\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 1.7392 - val_loss: 1.7019\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 385us/step - loss: 1.7363 - val_loss: 1.6986\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 353us/step - loss: 1.7336 - val_loss: 1.6966\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 314us/step - loss: 1.7309 - val_loss: 1.6930\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 336us/step - loss: 1.7281 - val_loss: 1.6895\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 340us/step - loss: 1.7255 - val_loss: 1.6886\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 382us/step - loss: 1.7229 - val_loss: 1.6855\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 348us/step - loss: 1.7204 - val_loss: 1.6815\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 400us/step - loss: 1.7177 - val_loss: 1.6819\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 366us/step - loss: 1.7154 - val_loss: 1.6800\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 377us/step - loss: 1.7131 - val_loss: 1.6739\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 373us/step - loss: 1.7111 - val_loss: 1.6696\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 344us/step - loss: 1.7091 - val_loss: 1.6667\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 368us/step - loss: 1.7073 - val_loss: 1.6655\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 1.7055 - val_loss: 1.6672\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 389us/step - loss: 1.7038 - val_loss: 1.6642\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 539us/step - loss: 1.7020 - val_loss: 1.6618\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 512us/step - loss: 1.7003 - val_loss: 1.6583\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 390us/step - loss: 1.6986 - val_loss: 1.6571\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 468us/step - loss: 1.6970 - val_loss: 1.6558\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 431us/step - loss: 1.6953 - val_loss: 1.6560\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 386us/step - loss: 1.6937 - val_loss: 1.6537\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 428us/step - loss: 1.6920 - val_loss: 1.6516\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 458us/step - loss: 1.6905 - val_loss: 1.6481\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 750us/step - loss: 1.6889 - val_loss: 1.6482\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 666us/step - loss: 1.6873 - val_loss: 1.6468\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 476us/step - loss: 1.6858 - val_loss: 1.6442\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 562us/step - loss: 1.6844 - val_loss: 1.6424\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 470us/step - loss: 1.6832 - val_loss: 1.6425\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 504us/step - loss: 1.6818 - val_loss: 1.6397\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 499us/step - loss: 1.6805 - val_loss: 1.6367\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 792us/step - loss: 1.6792 - val_loss: 1.6360\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 406us/step - loss: 1.6780 - val_loss: 1.6358\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 385us/step - loss: 1.6768 - val_loss: 1.6352\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 353us/step - loss: 1.6757 - val_loss: 1.6333\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 525us/step - loss: 1.6747 - val_loss: 1.6317\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 548us/step - loss: 1.6737 - val_loss: 1.6305\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 1.6727 - val_loss: 1.6286\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 420us/step - loss: 1.6718 - val_loss: 1.6281\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 623us/step - loss: 1.6709 - val_loss: 1.6280\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 405us/step - loss: 1.6701 - val_loss: 1.6276\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 405us/step - loss: 1.6693 - val_loss: 1.6263\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 429us/step - loss: 1.6685 - val_loss: 1.6249\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 379us/step - loss: 1.6677 - val_loss: 1.6241\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 444us/step - loss: 1.6670 - val_loss: 1.6244\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 717us/step - loss: 1.6663 - val_loss: 1.6242\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 568us/step - loss: 1.6656 - val_loss: 1.6233\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 637us/step - loss: 1.6649 - val_loss: 1.6225\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 667us/step - loss: 1.6642 - val_loss: 1.6217\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 614us/step - loss: 1.6636 - val_loss: 1.6210\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 594us/step - loss: 1.6629 - val_loss: 1.6210\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 691us/step - loss: 1.6623 - val_loss: 1.6200\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 337us/step - loss: 1.6617 - val_loss: 1.6198\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 322us/step - loss: 1.6611 - val_loss: 1.6191\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 331us/step - loss: 1.6605 - val_loss: 1.6187\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 406us/step - loss: 1.6600 - val_loss: 1.6183\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 633us/step - loss: 1.6594 - val_loss: 1.6187\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 640us/step - loss: 1.6589 - val_loss: 1.6182\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 965us/step - loss: 1.6584 - val_loss: 1.6183\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 409us/step - loss: 1.6578 - val_loss: 1.6174\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 430us/step - loss: 1.6573 - val_loss: 1.6161\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 651us/step - loss: 1.6568 - val_loss: 1.6155\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 556us/step - loss: 1.6563 - val_loss: 1.6152\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 639us/step - loss: 1.6558 - val_loss: 1.6156\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 563us/step - loss: 1.6553 - val_loss: 1.6157\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 451us/step - loss: 1.6548 - val_loss: 1.6148\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 379us/step - loss: 1.6544 - val_loss: 1.6152\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 423us/step - loss: 1.6539 - val_loss: 1.6148\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 726us/step - loss: 1.6534 - val_loss: 1.6143\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 592us/step - loss: 1.6529 - val_loss: 1.6136\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 549us/step - loss: 1.6525 - val_loss: 1.6129\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 806us/step - loss: 1.6520 - val_loss: 1.6128\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 506us/step - loss: 1.6515 - val_loss: 1.6138\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 514us/step - loss: 1.6511 - val_loss: 1.6137\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 408us/step - loss: 1.6506 - val_loss: 1.6134\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 383us/step - loss: 1.6501 - val_loss: 1.6138\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 332us/step - loss: 1.6496 - val_loss: 1.6141\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 326us/step - loss: 1.6491 - val_loss: 1.6138\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 1.6485 - val_loss: 1.6143\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 369us/step - loss: 1.6481 - val_loss: 1.6142\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 321us/step - loss: 1.6476 - val_loss: 1.6146\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 350us/step - loss: 1.6471 - val_loss: 1.6147\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 335us/step - loss: 1.6467 - val_loss: 1.6139\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 334us/step - loss: 1.6462 - val_loss: 1.6142\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 330us/step - loss: 1.6458 - val_loss: 1.6138\n",
      "   (0, 30)     tanh C\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 7.4861 - val_loss: 6.2413\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 672us/step - loss: 5.2556 - val_loss: 4.1298\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 702us/step - loss: 3.3118 - val_loss: 3.1820\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 666us/step - loss: 2.5042 - val_loss: 2.2945\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 685us/step - loss: 1.8158 - val_loss: 1.6336\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 656us/step - loss: 1.3485 - val_loss: 1.2828\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 659us/step - loss: 1.0440 - val_loss: 1.0963\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 670us/step - loss: 0.8393 - val_loss: 0.9320\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 584us/step - loss: 0.6899 - val_loss: 0.8367\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 632us/step - loss: 0.5678 - val_loss: 0.7847\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 705us/step - loss: 0.4827 - val_loss: 0.7201\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 683us/step - loss: 0.4074 - val_loss: 0.6631\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 651us/step - loss: 0.3467 - val_loss: 0.6278\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 676us/step - loss: 0.3027 - val_loss: 0.5899\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 591us/step - loss: 0.2587 - val_loss: 0.5686\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 574us/step - loss: 0.2223 - val_loss: 0.5497\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 629us/step - loss: 0.1946 - val_loss: 0.5218\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 644us/step - loss: 0.1718 - val_loss: 0.5142\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 592us/step - loss: 0.1490 - val_loss: 0.5051\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 669us/step - loss: 0.1331 - val_loss: 0.4859\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 619us/step - loss: 0.1169 - val_loss: 0.4819\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 604us/step - loss: 0.1042 - val_loss: 0.4681\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 633us/step - loss: 0.0941 - val_loss: 0.4622\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 608us/step - loss: 0.0855 - val_loss: 0.4564\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 701us/step - loss: 0.0767 - val_loss: 0.4619\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 689us/step - loss: 0.0696 - val_loss: 0.4550\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 676us/step - loss: 0.0629 - val_loss: 0.4493\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 701us/step - loss: 0.0578 - val_loss: 0.4448\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 0.0528 - val_loss: 0.4463\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 672us/step - loss: 0.0483 - val_loss: 0.4468\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 686us/step - loss: 0.0449 - val_loss: 0.4415\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 682us/step - loss: 0.0413 - val_loss: 0.4409\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 682us/step - loss: 0.0382 - val_loss: 0.4380\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 677us/step - loss: 0.0355 - val_loss: 0.4400\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 652us/step - loss: 0.0328 - val_loss: 0.4376\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 672us/step - loss: 0.0305 - val_loss: 0.4367\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 697us/step - loss: 0.0281 - val_loss: 0.4406\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 655us/step - loss: 0.0259 - val_loss: 0.4402\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 697us/step - loss: 0.0240 - val_loss: 0.4388\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.020 - 0s 661us/step - loss: 0.0222 - val_loss: 0.4396\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 0.0208 - val_loss: 0.4399\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 679us/step - loss: 0.0192 - val_loss: 0.4359\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 688us/step - loss: 0.0180 - val_loss: 0.4350\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 686us/step - loss: 0.0168 - val_loss: 0.4371\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 685us/step - loss: 0.0157 - val_loss: 0.4370\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 754us/step - loss: 0.0148 - val_loss: 0.4387\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 680us/step - loss: 0.0139 - val_loss: 0.4377\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 698us/step - loss: 0.0131 - val_loss: 0.4357\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 688us/step - loss: 0.0125 - val_loss: 0.4372\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 712us/step - loss: 0.0118 - val_loss: 0.4400\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 695us/step - loss: 0.0113 - val_loss: 0.4391\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 714us/step - loss: 0.0106 - val_loss: 0.4382\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 741us/step - loss: 0.0101 - val_loss: 0.4385\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 722us/step - loss: 0.0096 - val_loss: 0.4396\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 743us/step - loss: 0.0093 - val_loss: 0.4451\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 702us/step - loss: 0.0088 - val_loss: 0.4406\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 706us/step - loss: 0.0084 - val_loss: 0.4403\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 0.0082 - val_loss: 0.4488\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 688us/step - loss: 0.0076 - val_loss: 0.4453\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 691us/step - loss: 0.0072 - val_loss: 0.4422\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 695us/step - loss: 0.0069 - val_loss: 0.4432\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 695us/step - loss: 0.0066 - val_loss: 0.4463\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 635us/step - loss: 0.0064 - val_loss: 0.4492\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 0.0061 - val_loss: 0.4495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 696us/step - loss: 0.0058 - val_loss: 0.4469\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 717us/step - loss: 0.0056 - val_loss: 0.4477\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 714us/step - loss: 0.0054 - val_loss: 0.4501\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 637us/step - loss: 0.0053 - val_loss: 0.4515\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 718us/step - loss: 0.0051 - val_loss: 0.4534\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 599us/step - loss: 0.0049 - val_loss: 0.4518\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 659us/step - loss: 0.0047 - val_loss: 0.4517\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 604us/step - loss: 0.0045 - val_loss: 0.4542\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 591us/step - loss: 0.0044 - val_loss: 0.4555\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 623us/step - loss: 0.0042 - val_loss: 0.4573\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 792us/step - loss: 0.0041 - val_loss: 0.4577\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 701us/step - loss: 0.0040 - val_loss: 0.4575\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 871us/step - loss: 0.0039 - val_loss: 0.4583\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 804us/step - loss: 0.0037 - val_loss: 0.4612\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 878us/step - loss: 0.0036 - val_loss: 0.4622\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 826us/step - loss: 0.0035 - val_loss: 0.4617\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 787us/step - loss: 0.0034 - val_loss: 0.4627\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 746us/step - loss: 0.0033 - val_loss: 0.4627\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 877us/step - loss: 0.0032 - val_loss: 0.4640\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 958us/step - loss: 0.0031 - val_loss: 0.4652\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 0.0030 - val_loss: 0.4659\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 670us/step - loss: 0.0029 - val_loss: 0.4665\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.4676\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 674us/step - loss: 0.0028 - val_loss: 0.4677\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 731us/step - loss: 0.0027 - val_loss: 0.4692\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 647us/step - loss: 0.0026 - val_loss: 0.4701\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 0.0025 - val_loss: 0.4706\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 653us/step - loss: 0.0025 - val_loss: 0.4708\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 890us/step - loss: 0.0024 - val_loss: 0.4708\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.4709\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 966us/step - loss: 0.0023 - val_loss: 0.4726\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 977us/step - loss: 0.0022 - val_loss: 0.4717\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 0.0022 - val_loss: 0.4746\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.4746\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 848us/step - loss: 0.0021 - val_loss: 0.4761\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 760us/step - loss: 0.0020 - val_loss: 0.4766\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 728us/step - loss: 0.0020 - val_loss: 0.4793\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 710us/step - loss: 0.0019 - val_loss: 0.4794\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 709us/step - loss: 0.0019 - val_loss: 0.4800\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 0.0018 - val_loss: 0.4808\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.4812\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.4817\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.4828\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.4834\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 728us/step - loss: 0.0016 - val_loss: 0.4847\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 691us/step - loss: 0.0016 - val_loss: 0.4853\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 0.0015 - val_loss: 0.4858\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 739us/step - loss: 0.0015 - val_loss: 0.4871\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 685us/step - loss: 0.0015 - val_loss: 0.4881\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 680us/step - loss: 0.0014 - val_loss: 0.4891\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 757us/step - loss: 0.0014 - val_loss: 0.4893\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 753us/step - loss: 0.0014 - val_loss: 0.4905\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 763us/step - loss: 0.0013 - val_loss: 0.4909\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 776us/step - loss: 0.0013 - val_loss: 0.4924\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 669us/step - loss: 0.0013 - val_loss: 0.4932\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 713us/step - loss: 0.0013 - val_loss: 0.4942\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 0.0012 - val_loss: 0.4947\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 700us/step - loss: 0.0012 - val_loss: 0.4944\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 760us/step - loss: 0.0012 - val_loss: 0.4958\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 720us/step - loss: 0.0012 - val_loss: 0.4968\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 0.0012 - val_loss: 0.4975\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 767us/step - loss: 0.0011 - val_loss: 0.4973\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 734us/step - loss: 0.0011 - val_loss: 0.4987\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 696us/step - loss: 0.0011 - val_loss: 0.4994\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 751us/step - loss: 0.0011 - val_loss: 0.5008\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 714us/step - loss: 0.0011 - val_loss: 0.5011\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 731us/step - loss: 0.0010 - val_loss: 0.5026\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 699us/step - loss: 0.0010 - val_loss: 0.5025\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 771us/step - loss: 9.9789e-04 - val_loss: 0.5041\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 680us/step - loss: 9.7949e-04 - val_loss: 0.5032\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 653us/step - loss: 9.5895e-04 - val_loss: 0.5046\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 9.3996e-04 - val_loss: 0.5073\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 652us/step - loss: 9.2595e-04 - val_loss: 0.5079\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 9.0745e-04 - val_loss: 0.5080\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 631us/step - loss: 8.9253e-04 - val_loss: 0.5083\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 634us/step - loss: 8.7697e-04 - val_loss: 0.5104\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 712us/step - loss: 8.5845e-04 - val_loss: 0.5110\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 682us/step - loss: 8.4436e-04 - val_loss: 0.5118\n",
      "Epoch 143/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 659us/step - loss: 8.3517e-04 - val_loss: 0.5101\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 705us/step - loss: 8.1723e-04 - val_loss: 0.5134\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 649us/step - loss: 8.0280e-04 - val_loss: 0.5138\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 690us/step - loss: 7.8611e-04 - val_loss: 0.5155\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 572us/step - loss: 7.7512e-04 - val_loss: 0.5153\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 607us/step - loss: 7.6363e-04 - val_loss: 0.5167\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 622us/step - loss: 7.5042e-04 - val_loss: 0.5181\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 650us/step - loss: 7.3672e-04 - val_loss: 0.5177\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 593us/step - loss: 7.2530e-04 - val_loss: 0.5179\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 617us/step - loss: 7.1395e-04 - val_loss: 0.5179\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 616us/step - loss: 7.0522e-04 - val_loss: 0.5194\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 660us/step - loss: 6.9130e-04 - val_loss: 0.5193\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 689us/step - loss: 6.7881e-04 - val_loss: 0.5192\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 678us/step - loss: 6.6908e-04 - val_loss: 0.5207\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 679us/step - loss: 6.5861e-04 - val_loss: 0.5206\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 613us/step - loss: 6.4921e-04 - val_loss: 0.5230\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 632us/step - loss: 6.3964e-04 - val_loss: 0.5230\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 638us/step - loss: 6.2765e-04 - val_loss: 0.5239\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 604us/step - loss: 6.1740e-04 - val_loss: 0.5251\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 592us/step - loss: 6.1007e-04 - val_loss: 0.5248\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 593us/step - loss: 5.9991e-04 - val_loss: 0.5262\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 607us/step - loss: 5.9193e-04 - val_loss: 0.5271\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 604us/step - loss: 5.8269e-04 - val_loss: 0.5271\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 606us/step - loss: 5.7320e-04 - val_loss: 0.5287\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 661us/step - loss: 5.6566e-04 - val_loss: 0.5307\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 729us/step - loss: 5.5836e-04 - val_loss: 0.5312\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 695us/step - loss: 5.4793e-04 - val_loss: 0.5303\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 676us/step - loss: 5.4173e-04 - val_loss: 0.5331\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 652us/step - loss: 5.3234e-04 - val_loss: 0.5326\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 663us/step - loss: 5.2465e-04 - val_loss: 0.5336\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 667us/step - loss: 5.1854e-04 - val_loss: 0.5338\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 641us/step - loss: 5.0980e-04 - val_loss: 0.5350\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 702us/step - loss: 5.0289e-04 - val_loss: 0.5360\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 644us/step - loss: 4.9561e-04 - val_loss: 0.5359\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 665us/step - loss: 4.8815e-04 - val_loss: 0.5373\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 665us/step - loss: 4.8264e-04 - val_loss: 0.5373\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 4.7522e-04 - val_loss: 0.5374\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 4.6943e-04 - val_loss: 0.5390\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 806us/step - loss: 4.6338e-04 - val_loss: 0.5410\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 638us/step - loss: 4.5773e-04 - val_loss: 0.5399\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 675us/step - loss: 4.5054e-04 - val_loss: 0.5400\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 722us/step - loss: 4.4528e-04 - val_loss: 0.5420\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 660us/step - loss: 4.3892e-04 - val_loss: 0.5427\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 643us/step - loss: 4.3403e-04 - val_loss: 0.5424\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 693us/step - loss: 4.2869e-04 - val_loss: 0.5423\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 655us/step - loss: 4.2387e-04 - val_loss: 0.5443\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 663us/step - loss: 4.1691e-04 - val_loss: 0.5440\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 698us/step - loss: 4.1192e-04 - val_loss: 0.5449\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 745us/step - loss: 4.0684e-04 - val_loss: 0.5455\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 4.0147e-04 - val_loss: 0.5467\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 710us/step - loss: 3.9674e-04 - val_loss: 0.5476\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 641us/step - loss: 3.9178e-04 - val_loss: 0.5475\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 3.8574e-0 - 0s 660us/step - loss: 3.8694e-04 - val_loss: 0.5483\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 696us/step - loss: 3.8213e-04 - val_loss: 0.5484\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 3.7759e-04 - val_loss: 0.5503\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 673us/step - loss: 3.7248e-04 - val_loss: 0.5513\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 662us/step - loss: 3.6806e-04 - val_loss: 0.5508\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 659us/step - loss: 3.6351e-04 - val_loss: 0.5518\n",
      "      None   linear A\n",
      "Train on 300 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.2062 - val_loss: 2.0630\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 622us/step - loss: 1.8712 - val_loss: 1.8075\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 678us/step - loss: 1.5643 - val_loss: 1.5738\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 650us/step - loss: 1.2982 - val_loss: 1.3504\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 626us/step - loss: 1.0476 - val_loss: 1.1566\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 716us/step - loss: 0.8424 - val_loss: 0.9825\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 629us/step - loss: 0.6615 - val_loss: 0.8677\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 626us/step - loss: 0.5415 - val_loss: 0.8027\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 663us/step - loss: 0.4336 - val_loss: 0.7464\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 687us/step - loss: 0.3612 - val_loss: 0.7041\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 620us/step - loss: 0.2924 - val_loss: 0.6960\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 660us/step - loss: 0.2530 - val_loss: 0.6754\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 683us/step - loss: 0.2061 - val_loss: 0.6694\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 594us/step - loss: 0.1729 - val_loss: 0.6402\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 577us/step - loss: 0.1411 - val_loss: 0.6621\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 661us/step - loss: 0.1184 - val_loss: 0.6513\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 638us/step - loss: 0.0997 - val_loss: 0.6703\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 640us/step - loss: 0.0834 - val_loss: 0.6540\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 607us/step - loss: 0.0717 - val_loss: 0.6644\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 667us/step - loss: 0.0609 - val_loss: 0.6591\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 625us/step - loss: 0.0527 - val_loss: 0.6660\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 704us/step - loss: 0.0455 - val_loss: 0.6704\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 695us/step - loss: 0.0396 - val_loss: 0.6734\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 738us/step - loss: 0.0342 - val_loss: 0.6892\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 738us/step - loss: 0.0311 - val_loss: 0.6889\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 741us/step - loss: 0.0275 - val_loss: 0.6880\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 723us/step - loss: 0.0247 - val_loss: 0.7078\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 0.0226 - val_loss: 0.7128\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 683us/step - loss: 0.0200 - val_loss: 0.6997\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 798us/step - loss: 0.0184 - val_loss: 0.7176\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 769us/step - loss: 0.0166 - val_loss: 0.7251\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 785us/step - loss: 0.0153 - val_loss: 0.7197\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 739us/step - loss: 0.0141 - val_loss: 0.7332\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 705us/step - loss: 0.0131 - val_loss: 0.7350\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 689us/step - loss: 0.0120 - val_loss: 0.7438\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 699us/step - loss: 0.0113 - val_loss: 0.7491\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 718us/step - loss: 0.0104 - val_loss: 0.7493\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 713us/step - loss: 0.0096 - val_loss: 0.7598\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 682us/step - loss: 0.0091 - val_loss: 0.7610\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 753us/step - loss: 0.0085 - val_loss: 0.7633\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 691us/step - loss: 0.0080 - val_loss: 0.7725\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 719us/step - loss: 0.0075 - val_loss: 0.7754\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 0.0072 - val_loss: 0.7776\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 741us/step - loss: 0.0067 - val_loss: 0.7796\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 717us/step - loss: 0.0064 - val_loss: 0.7851\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 0.0060 - val_loss: 0.7888\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 691us/step - loss: 0.0057 - val_loss: 0.7896\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 750us/step - loss: 0.0054 - val_loss: 0.7975\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 702us/step - loss: 0.0052 - val_loss: 0.8004\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 706us/step - loss: 0.0049 - val_loss: 0.8013\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 736us/step - loss: 0.0047 - val_loss: 0.8078\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 735us/step - loss: 0.0045 - val_loss: 0.8093\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 0.0043 - val_loss: 0.8149\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 794us/step - loss: 0.0041 - val_loss: 0.8145\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 761us/step - loss: 0.0039 - val_loss: 0.8203\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 758us/step - loss: 0.0038 - val_loss: 0.8244\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 763us/step - loss: 0.0036 - val_loss: 0.8245\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 0.0035 - val_loss: 0.8285\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 740us/step - loss: 0.0033 - val_loss: 0.8317\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 0.0032 - val_loss: 0.8365\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 718us/step - loss: 0.0031 - val_loss: 0.8388\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 718us/step - loss: 0.0030 - val_loss: 0.8417\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 724us/step - loss: 0.0029 - val_loss: 0.8471\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 0.0028 - val_loss: 0.8460\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 655us/step - loss: 0.0027 - val_loss: 0.8480\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 651us/step - loss: 0.0026 - val_loss: 0.8547\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 698us/step - loss: 0.0025 - val_loss: 0.8558\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 677us/step - loss: 0.0024 - val_loss: 0.8573\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.002 - 0s 661us/step - loss: 0.0023 - val_loss: 0.8605\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 640us/step - loss: 0.0023 - val_loss: 0.8616\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 700us/step - loss: 0.0022 - val_loss: 0.8638\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 690us/step - loss: 0.0021 - val_loss: 0.8646\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 686us/step - loss: 0.0021 - val_loss: 0.8686\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 601us/step - loss: 0.0020 - val_loss: 0.8712\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 627us/step - loss: 0.0019 - val_loss: 0.8735\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 672us/step - loss: 0.0019 - val_loss: 0.8747\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.001 - 0s 657us/step - loss: 0.0018 - val_loss: 0.8797\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 704us/step - loss: 0.0018 - val_loss: 0.8799\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 643us/step - loss: 0.0017 - val_loss: 0.8809\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 638us/step - loss: 0.0017 - val_loss: 0.8840\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 662us/step - loss: 0.0016 - val_loss: 0.8863\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 654us/step - loss: 0.0016 - val_loss: 0.8877\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 659us/step - loss: 0.0015 - val_loss: 0.8919\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 637us/step - loss: 0.0015 - val_loss: 0.8953\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 607us/step - loss: 0.0015 - val_loss: 0.8957\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 618us/step - loss: 0.0014 - val_loss: 0.8974\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 656us/step - loss: 0.0014 - val_loss: 0.8981\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 614us/step - loss: 0.0013 - val_loss: 0.9006\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 652us/step - loss: 0.0013 - val_loss: 0.9036\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 676us/step - loss: 0.0013 - val_loss: 0.9043\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 634us/step - loss: 0.0013 - val_loss: 0.9060\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 683us/step - loss: 0.0012 - val_loss: 0.9080\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 632us/step - loss: 0.0012 - val_loss: 0.9095\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 620us/step - loss: 0.0012 - val_loss: 0.9122\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 660us/step - loss: 0.0011 - val_loss: 0.9140\n",
      "Epoch 96/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 631us/step - loss: 0.0011 - val_loss: 0.9145\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 695us/step - loss: 0.0011 - val_loss: 0.9153\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 635us/step - loss: 0.0011 - val_loss: 0.9173\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 619us/step - loss: 0.0010 - val_loss: 0.9201\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 621us/step - loss: 0.0010 - val_loss: 0.9242\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 677us/step - loss: 9.9181e-04 - val_loss: 0.9244\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 812us/step - loss: 9.6924e-04 - val_loss: 0.9256\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 715us/step - loss: 9.5159e-04 - val_loss: 0.9270\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 707us/step - loss: 9.3113e-04 - val_loss: 0.9299\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 694us/step - loss: 9.1156e-04 - val_loss: 0.9324\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 671us/step - loss: 8.9090e-04 - val_loss: 0.9319\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 747us/step - loss: 8.7169e-04 - val_loss: 0.9361\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 745us/step - loss: 8.5446e-04 - val_loss: 0.9384\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 693us/step - loss: 8.3692e-04 - val_loss: 0.9388\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 729us/step - loss: 8.1909e-04 - val_loss: 0.9400\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 743us/step - loss: 8.0482e-04 - val_loss: 0.9414\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 678us/step - loss: 7.8696e-04 - val_loss: 0.9421\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 722us/step - loss: 7.7233e-04 - val_loss: 0.9417\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 718us/step - loss: 7.5761e-04 - val_loss: 0.9452\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 706us/step - loss: 7.4425e-04 - val_loss: 0.9494\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 712us/step - loss: 7.2840e-04 - val_loss: 0.9493\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 7.1605e-04 - val_loss: 0.9473\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 6.9954e-04 - val_loss: 0.9498\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 724us/step - loss: 6.8699e-04 - val_loss: 0.9527\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 693us/step - loss: 6.7405e-04 - val_loss: 0.9533\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 695us/step - loss: 6.5987e-04 - val_loss: 0.9544\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 716us/step - loss: 6.4733e-04 - val_loss: 0.9561\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 698us/step - loss: 6.3479e-04 - val_loss: 0.9588\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 718us/step - loss: 6.2326e-04 - val_loss: 0.9602\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 738us/step - loss: 6.1177e-04 - val_loss: 0.9603\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 718us/step - loss: 6.0114e-04 - val_loss: 0.9626\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 5.9107e-04 - val_loss: 0.9650\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 706us/step - loss: 5.8012e-04 - val_loss: 0.9669\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 711us/step - loss: 5.6984e-04 - val_loss: 0.9687\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 698us/step - loss: 5.6105e-04 - val_loss: 0.9679\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 716us/step - loss: 5.5013e-04 - val_loss: 0.9692\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 5.4129e-04 - val_loss: 0.9709\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 722us/step - loss: 5.3168e-04 - val_loss: 0.9720\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 750us/step - loss: 5.2285e-04 - val_loss: 0.9731\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 704us/step - loss: 5.1393e-04 - val_loss: 0.9736\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 5.0636e-04 - val_loss: 0.9749\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 715us/step - loss: 4.9738e-04 - val_loss: 0.9771\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 733us/step - loss: 4.9094e-04 - val_loss: 0.9776\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 710us/step - loss: 4.8103e-04 - val_loss: 0.9801\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 695us/step - loss: 4.7375e-04 - val_loss: 0.9815\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 703us/step - loss: 4.6613e-04 - val_loss: 0.9826\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 691us/step - loss: 4.5854e-04 - val_loss: 0.9840\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 721us/step - loss: 4.5087e-04 - val_loss: 0.9848\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 712us/step - loss: 4.4466e-04 - val_loss: 0.9858\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 715us/step - loss: 4.3726e-04 - val_loss: 0.9869\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 655us/step - loss: 4.3038e-04 - val_loss: 0.9877\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 633us/step - loss: 4.2416e-04 - val_loss: 0.9892\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 712us/step - loss: 4.1752e-04 - val_loss: 0.9907\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 666us/step - loss: 4.1102e-04 - val_loss: 0.9937\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 693us/step - loss: 4.0501e-04 - val_loss: 0.9945\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 659us/step - loss: 3.9815e-04 - val_loss: 0.9931\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 670us/step - loss: 3.9338e-04 - val_loss: 0.9934\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 670us/step - loss: 3.8705e-04 - val_loss: 0.9971\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 674us/step - loss: 3.8051e-04 - val_loss: 0.9994\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 605us/step - loss: 3.7433e-04 - val_loss: 0.9986\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 611us/step - loss: 3.6922e-04 - val_loss: 0.9989\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 637us/step - loss: 3.6415e-04 - val_loss: 0.9998\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 684us/step - loss: 3.5792e-04 - val_loss: 1.0025-0\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 595us/step - loss: 3.5342e-04 - val_loss: 1.0052\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 708us/step - loss: 3.4749e-04 - val_loss: 1.0064\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 628us/step - loss: 3.4249e-04 - val_loss: 1.0067\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 710us/step - loss: 3.3839e-04 - val_loss: 1.0065-0\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 650us/step - loss: 3.3328e-04 - val_loss: 1.0089\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 685us/step - loss: 3.2843e-04 - val_loss: 1.0104\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 633us/step - loss: 3.2385e-04 - val_loss: 1.0109\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 675us/step - loss: 3.1912e-04 - val_loss: 1.0136\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 700us/step - loss: 3.1468e-04 - val_loss: 1.0150\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 671us/step - loss: 3.1028e-04 - val_loss: 1.0153\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 605us/step - loss: 3.0614e-04 - val_loss: 1.0161\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 595us/step - loss: 3.0211e-04 - val_loss: 1.0174\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - ETA: 0s - loss: 3.3124e-0 - 0s 662us/step - loss: 2.9828e-04 - val_loss: 1.0182\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 666us/step - loss: 2.9392e-04 - val_loss: 1.0196\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 642us/step - loss: 2.9019e-04 - val_loss: 1.0210\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 639us/step - loss: 2.8632e-04 - val_loss: 1.0208\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 652us/step - loss: 2.8273e-04 - val_loss: 1.0210\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 701us/step - loss: 2.7877e-04 - val_loss: 1.0226\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 661us/step - loss: 2.7494e-04 - val_loss: 1.0239\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 664us/step - loss: 2.7153e-04 - val_loss: 1.0257\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 691us/step - loss: 2.6810e-04 - val_loss: 1.0260\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 634us/step - loss: 2.6471e-04 - val_loss: 1.0274\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 662us/step - loss: 2.6098e-04 - val_loss: 1.0281\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 637us/step - loss: 2.5782e-04 - val_loss: 1.0291\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 660us/step - loss: 2.5461e-04 - val_loss: 1.0305\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 618us/step - loss: 2.5130e-04 - val_loss: 1.0311\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 660us/step - loss: 2.4817e-04 - val_loss: 1.0332\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 700us/step - loss: 2.4521e-04 - val_loss: 1.0340\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 675us/step - loss: 2.4175e-04 - val_loss: 1.0350\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 694us/step - loss: 2.3902e-04 - val_loss: 1.0359\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 775us/step - loss: 2.3612e-04 - val_loss: 1.0363\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 764us/step - loss: 2.3298e-04 - val_loss: 1.0375\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 724us/step - loss: 2.3037e-04 - val_loss: 1.0380\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 727us/step - loss: 2.2763e-04 - val_loss: 1.0394\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 729us/step - loss: 2.2511e-04 - val_loss: 1.0381\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 688us/step - loss: 2.2226e-04 - val_loss: 1.0394\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 744us/step - loss: 2.1927e-04 - val_loss: 1.0407\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 725us/step - loss: 2.1692e-04 - val_loss: 1.0431\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 753us/step - loss: 2.1429e-04 - val_loss: 1.0428\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 820us/step - loss: 2.1163e-04 - val_loss: 1.0438\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 742us/step - loss: 2.0898e-04 - val_loss: 1.0451\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 746us/step - loss: 2.0672e-04 - val_loss: 1.0469\n",
      "      None   linear B\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-dd8784f985dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0march\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'B'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mX_train_extra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_extra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_X_extra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_B\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_info_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_extra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms3_activation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_extra\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_oh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_extra\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_oh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "for k, act, arch in itertools.product(k_set, act_set, arch_set):\n",
    "    \n",
    "    print \"%10s %8s %1s\"%(str(k), act, arch)    \n",
    "    \n",
    "    if arch == 'A':\n",
    "        model = get_model_A(input_dim=X.shape[1], s1=50, s2=30, s3=20,s3_activation=act)\n",
    "        model.fit(X_train, y_train_oh, epochs=200, batch_size=32, validation_data=(X_test, y_test_oh)) \n",
    "        preds_test = model.predict(X_test).argmax(axis=1)    \n",
    "      \n",
    "    if arch == 'B':\n",
    "        X_train_extra, X_test_extra = get_X_extra(y_train, y_test, k0=k[0], k1=k[1])\n",
    "        model = get_model_B(input_dim=X.shape[1], extra_info_dim=X_train_extra.shape[1], s1=50, s2=30, s3=20, s3_activation=act)\n",
    "        model.fit([X_train, X_train_extra], y_train_oh, epochs=200, batch_size=100, validation_data=([X_test, X_test_extra], y_test_oh))\n",
    "        preds_test = model.predict([X_test, X_test_extra]).argmax(axis=1)\n",
    "        \n",
    "   \n",
    "    if arch=='C' and k!=None:\n",
    "        X_train_extra, X_test_extra = get_X_extra(y_train, y_test, k0=k[0], k1=k[1])\n",
    "        model = get_model_C(input_dim=X.shape[1], extra_info_dim=X_train_extra.shape[1], s1=50, s2=30, s3=20, s3_activation=act)\n",
    "        model.fit([X_train, X_train_extra], y_train_oh, epochs=200, batch_size=32, validation_data=([X_test, X_test_extra], y_test_oh))\n",
    "        preds_test = model.predict([X_test, X_test_extra]).argmax(axis=1)\n",
    "\n",
    "    \n",
    "   \n",
    "    acc = np.mean(preds_test==y_test)\n",
    "    model_act = arch+\"-\"+act\n",
    "    r_test.set_value(model_act, str(k), acc)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(0, 1)</th>\n",
       "      <th>(-0.5, 2)</th>\n",
       "      <th>(-0.5, 30)</th>\n",
       "      <th>(0, 15)</th>\n",
       "      <th>(0, 30)</th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A-linear</th>\n",
       "      <td>0.810833</td>\n",
       "      <td>0.815833</td>\n",
       "      <td>0.792500</td>\n",
       "      <td>0.817500</td>\n",
       "      <td>0.801667</td>\n",
       "      <td>0.7975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-relu</th>\n",
       "      <td>0.810833</td>\n",
       "      <td>0.814167</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.799167</td>\n",
       "      <td>0.785833</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-tanh</th>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.809167</td>\n",
       "      <td>0.798333</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-linear</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.801667</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.567500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-relu</th>\n",
       "      <td>0.785833</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.844167</td>\n",
       "      <td>0.839167</td>\n",
       "      <td>0.784167</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-tanh</th>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>0.818333</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.814167</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-linear</th>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.875833</td>\n",
       "      <td>0.860833</td>\n",
       "      <td>0.630833</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-relu</th>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.815833</td>\n",
       "      <td>0.864167</td>\n",
       "      <td>0.868333</td>\n",
       "      <td>0.830833</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C-tanh</th>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.823333</td>\n",
       "      <td>0.861667</td>\n",
       "      <td>0.851667</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            (0, 1)  (-0.5, 2)  (-0.5, 30)   (0, 15)   (0, 30)    None\n",
       "A-linear  0.810833   0.815833    0.792500  0.817500  0.801667  0.7975\n",
       "A-relu    0.810833   0.814167    0.790000  0.799167  0.785833     NaN\n",
       "A-tanh    0.826667   0.809167    0.798333  0.816667  0.820833     NaN\n",
       "B-linear  0.800000   0.801667    0.780000  0.800000  0.567500     NaN\n",
       "B-relu    0.785833   0.810000    0.844167  0.839167  0.784167     NaN\n",
       "B-tanh    0.795000   0.806667    0.818333  0.810000  0.814167     NaN\n",
       "C-linear  0.825000   0.816667    0.875833  0.860833  0.630833     NaN\n",
       "C-relu    0.804167   0.815833    0.864167  0.868333  0.830833     NaN\n",
       "C-tanh    0.816667   0.823333    0.861667  0.851667  0.871667     NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.figure(figsize=(8,3))\n",
    "\n",
    "plt.pcolor(r_test)\n",
    "plt.yticks(np.arange(0.5, len(r_test.index), 1), r_test.index)\n",
    "plt.xticks(np.arange(0.5, len(r_test.columns), 1), r_test.columns)\n",
    "plt.title('test Accuracy')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(211)\n",
    "plt.bar(np.arange(np.shape(r_test)[0]), r_test.mean(axis=1), align='center', alpha=0.5)\n",
    "plt.xticks(np.arange(np.shape(r_test)[0]), r_test.index)\n",
    "plt.ylim((0.768, 0.85))\n",
    "plt.ylabel('test Accuracy')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(212)\n",
    "plt.bar(np.arange(np.shape(r_test)[1]), r_test.mean(axis=0), align='center', alpha=0.5)\n",
    "plt.xticks(np.arange(np.shape(r_test)[1]), r_test.columns)\n",
    "plt.ylim((0.8, 0.85))\n",
    "plt.ylabel('test Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
