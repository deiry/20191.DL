{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, concatenate, Input\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow import keras\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab vanishing gradient\n",
    "\n",
    "\n",
    "In this lab you will impement a complete exploration and results visualization for the following experiment configurations  with dense neural networks:\n",
    "\n",
    "- with the following numbers of layers [2,3,4,5,6,7,8,9,10]\n",
    "- with the following neurons per layer [3,5,10,30]\n",
    "- with activations ReLU, Sigmoid and LeakyReLU\n",
    "\n",
    "In total, you must train and test 36 network architectures for each activation function.\n",
    "\n",
    "The experimentation must be done with the MNIST Digits datasets (1500 items) using a random partition of 50/50 for train and test.\n",
    "\n",
    "For each configuration you must record the **accuracy in test** and the **time used to train** the model.\n",
    "\n",
    "Then, you will need to build the following visualizations\n",
    "\n",
    "- one heat map for each activation function illustrating the **accuracy in test** for each configuration\n",
    "- one heat map for each activation function illustrating the **time used to train** for each configuration\n",
    "- a scatter plot of all your experiments, showing:\n",
    "    - the time used to train in the x-axis\n",
    "    - the accuracy in test in the y-axis\n",
    "    - the number of layers as the size of the dots\n",
    "    - expetiments for each activation function in different colors   \n",
    "- a bar plot showing the average performance of each activation function for each number of layers.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension de las imagenes y las clases (1500, 784) (1500,)\n"
     ]
    }
   ],
   "source": [
    "layers = [2,3,4,5,6,7,8,9,10]\n",
    "neurons = [3,5,10,30]\n",
    "activation = ['relu','sigmoid',tf.nn.leaky_relu]\n",
    "reluAcc= np.zeros((len(layers), len(neurons)))\n",
    "reluTime = np.zeros((len(layers), len(neurons)))\n",
    "leakyAcc= np.zeros((len(layers), len(neurons)))\n",
    "leakyTime= np.zeros((len(layers), len(neurons)))\n",
    "\n",
    "sigTime= np.zeros((len(layers), len(neurons)))\n",
    "sigAcc= np.zeros((len(layers), len(neurons)))\n",
    "\n",
    "\n",
    "mnist = pd.read_csv(\"data/mnist1.5k.csv.gz\", compression=\"gzip\", header=None).values\n",
    "X=mnist[:,1:785]/255.\n",
    "y=mnist[:,0]\n",
    "print \"dimension de las imagenes y las clases\", X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 784) (5, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5)\n",
    "X_train = X_train[:5]\n",
    "X_test  = X_test[:5]\n",
    "y_train_oh = np.eye(10)[y_train[:5]]\n",
    "y_test_oh  = np.eye(10)[y_test[:5]]\n",
    "print X_train.shape, y_train_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_dim=784, output_dim=10, num_hidden_layers=6, hidden_size=10, activation=\"relu\"):\n",
    "\n",
    "    clear_session()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_size, activation=activation, input_dim=input_dim, name=\"Layer_%02d_Input\"%(0)))\n",
    "    \n",
    "    for i in range(num_hidden_layers):\n",
    "        model.add(Dense(hidden_size, activation=activation, name=\"Layer_%02d_Hidden\"%(i+1)))\n",
    "   \n",
    "    model.add(Dense(output_dim, activation=\"softmax\", name=\"Layer_%02d_Output\"%(num_hidden_layers+1)))\n",
    "        \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.reset_states()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 2.3218 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 27ms/step\n",
      "(0, 0, (0.0, 1.6469919681549072))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 2.4852 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 16ms/step\n",
      "(0, 0, (0.2, 1.1050379276275635))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 2.3102 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 19ms/step\n",
      "(0, 0, (0.4, 1.425050973892212))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 2.3172 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 20ms/step\n",
      "(0, 1, (0.0, 2.031301975250244))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 2.3770 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 17ms/step\n",
      "(0, 1, (0.2, 1.1855289936065674))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 2.3096 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 21ms/step\n",
      "(0, 1, (0.0, 1.7608060836791992))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 2.3375 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 21ms/step\n",
      "(0, 2, (0.0, 1.3336718082427979))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 2.4435 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 37ms/step\n",
      "(0, 2, (0.0, 1.5445501804351807))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 2.3600 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 22ms/step\n",
      "(0, 2, (0.2, 1.5425100326538086))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 2.2239 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 18ms/step\n",
      "(0, 3, (0.2, 1.2909009456634521))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 2.7781 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 19ms/step\n",
      "(0, 3, (0.0, 1.5710008144378662))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 2.2569 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 19ms/step\n",
      "(0, 3, (0.2, 1.322983980178833))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 2.3816 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 20ms/step\n",
      "(1, 0, (0.2, 1.6975820064544678))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 2.4172 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 20ms/step\n",
      "(1, 0, (0.0, 1.575148105621338))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 192ms/step - loss: 2.2655 - acc: 0.4000\n",
      "5/5 [==============================] - 0s 25ms/step\n",
      "(1, 0, (0.2, 1.9576189517974854))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 2.2924 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 19ms/step\n",
      "(1, 1, (0.0, 1.7401540279388428))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 2.1975 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 21ms/step\n",
      "(1, 1, (0.2, 1.9995739459991455))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 2.2705 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 21ms/step\n",
      "(1, 1, (0.0, 1.5591328144073486))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 2.3322 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 23ms/step\n",
      "(1, 2, (0.2, 1.8199989795684814))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 2.7885 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 17ms/step\n",
      "(1, 2, (0.0, 1.497553825378418))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 2.2413 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 22ms/step\n",
      "(1, 2, (0.0, 1.808772087097168))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 2.2859 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 18ms/step\n",
      "(1, 3, (0.2, 1.2487819194793701))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 2.2779 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 19ms/step\n",
      "(1, 3, (0.0, 1.2698731422424316))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 2.3118 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 20ms/step\n",
      "(1, 3, (0.0, 1.414458990097046))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 2.2977 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 21ms/step\n",
      "(2, 0, (0.2, 1.4143428802490234))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 2.2801 - acc: 0.4000\n",
      "5/5 [==============================] - 0s 21ms/step\n",
      "(2, 0, (0.2, 1.8110871315002441))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 2.3109 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 23ms/step\n",
      "(2, 0, (0.0, 1.6112339496612549))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 2.3011 - acc: 0.4000\n",
      "5/5 [==============================] - 0s 29ms/step\n",
      "(2, 1, (0.0, 1.8287010192871094))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 261ms/step - loss: 2.3599 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 52ms/step\n",
      "(2, 1, (0.0, 1.9393889904022217))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 2.3127 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 33ms/step\n",
      "(2, 1, (0.0, 1.8681979179382324))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 2.3182 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 21ms/step\n",
      "(2, 2, (0.2, 1.879093885421753))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 353ms/step - loss: 2.4724 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 51ms/step\n",
      "(2, 2, (0.2, 2.371469020843506))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 2.2233 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 25ms/step\n",
      "(2, 2, (0.0, 2.619377851486206))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 2.2882 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 51ms/step\n",
      "(2, 3, (0.0, 1.847661018371582))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 1.9693 - acc: 0.4000\n",
      "5/5 [==============================] - 0s 22ms/step\n",
      "(2, 3, (0.2, 2.3021039962768555))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 2.2809 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 27ms/step\n",
      "(2, 3, (0.0, 2.054302930831909))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 2.3023 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 22ms/step\n",
      "(3, 0, (0.0, 1.6358768939971924))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 2.3595 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 25ms/step\n",
      "(3, 0, (0.0, 1.9826269149780273))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 2.2996 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 30ms/step\n",
      "(3, 0, (0.0, 2.4142801761627197))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 182ms/step - loss: 2.2663 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 52ms/step\n",
      "(3, 1, (0.0, 1.5903818607330322))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 2.2694 - acc: 0.4000\n",
      "5/5 [==============================] - 0s 25ms/step\n",
      "(3, 1, (0.2, 2.199120044708252))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 2.2949 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 33ms/step\n",
      "(3, 1, (0.0, 2.4719979763031006))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 2.3028 - acc: 0.4000\n",
      "5/5 [==============================] - 0s 23ms/step\n",
      "(3, 2, (0.0, 1.6113190650939941))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 2.3127 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 23ms/step\n",
      "(3, 2, (0.4, 2.014064073562622))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 279ms/step - loss: 2.2594 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 33ms/step\n",
      "(3, 2, (0.0, 2.5267179012298584))\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 196ms/step - loss: 2.2946 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 26ms/step\n",
      "(3, 3, (0.0, 1.6953661441802979))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 2.6442 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 23ms/step\n",
      "(3, 3, (0.0, 2.0190579891204834))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 2.3111 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 28ms/step\n",
      "(3, 3, (0.2, 2.3682289123535156))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 2.3025 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 24ms/step\n",
      "(4, 0, (0.2, 1.754270076751709))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 2.3414 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 22ms/step\n",
      "(4, 0, (0.0, 2.125605821609497))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 490ms/step - loss: 2.3132 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 69ms/step\n",
      "(4, 0, (0.0, 3.687894105911255))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 2.2998 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 27ms/step\n",
      "(4, 1, (0.0, 2.5741829872131348))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 329ms/step - loss: 2.5214 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 26ms/step\n",
      "(4, 1, (0.0, 2.8546910285949707))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 2.3071 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 27ms/step\n",
      "(4, 1, (0.2, 2.473798990249634))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 2.3701 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 26ms/step\n",
      "(4, 2, (0.0, 2.161540985107422))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 292ms/step - loss: 2.3764 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 26ms/step\n",
      "(4, 2, (0.0, 2.2491331100463867))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 266ms/step - loss: 2.3102 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 36ms/step\n",
      "(4, 2, (0.2, 2.7550110816955566))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 2.2884 - acc: 0.4000\n",
      "5/5 [==============================] - 0s 61ms/step\n",
      "(4, 3, (0.2, 2.4685750007629395))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 220ms/step - loss: 2.0696 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 25ms/step\n",
      "(4, 3, (0.0, 2.4027791023254395))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 261ms/step - loss: 2.3128 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 29ms/step\n",
      "(4, 3, (0.0, 2.5013179779052734))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 2.3238 - acc: 0.4000\n",
      "5/5 [==============================] - 0s 25ms/step\n",
      "(5, 0, (0.2, 1.9699790477752686))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 2.4590 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 26ms/step\n",
      "(5, 0, (0.4, 2.530319929122925))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 2.3031 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 28ms/step\n",
      "(5, 0, (0.0, 2.6042048931121826))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 2.3018 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 27ms/step\n",
      "(5, 1, (0.2, 2.38749098777771))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 2.8765 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 27ms/step\n",
      "(5, 1, (0.0, 2.3345189094543457))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 545ms/step - loss: 2.3025 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 50ms/step\n",
      "(5, 1, (0.2, 3.7377231121063232))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 300ms/step - loss: 2.3061 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 24ms/step\n",
      "(5, 2, (0.2, 2.571153163909912))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 2.3493 - acc: 0.4000\n",
      "5/5 [==============================] - 0s 24ms/step\n",
      "(5, 2, (0.2, 2.757460832595825))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 364ms/step - loss: 2.3050 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 30ms/step\n",
      "(5, 2, (0.0, 3.4205269813537598))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 292ms/step - loss: 2.3112 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 39ms/step\n",
      "(5, 3, (0.0, 2.7157249450683594))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 308ms/step - loss: 2.9830 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 27ms/step\n",
      "(5, 3, (0.0, 2.9859049320220947))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 259ms/step - loss: 2.3202 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 28ms/step\n",
      "(5, 3, (0.0, 2.3556320667266846))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 2.3057 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 28ms/step\n",
      "(6, 0, (0.2, 2.111828088760376))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 2.2430 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 24ms/step\n",
      "(6, 0, (0.0, 2.4011850357055664))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 285ms/step - loss: 2.3033 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 30ms/step\n",
      "(6, 0, (0.0, 2.880650043487549))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 263ms/step - loss: 2.3017 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 27ms/step\n",
      "(6, 1, (0.2, 2.544635057449341))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 334ms/step - loss: 2.3288 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 26ms/step\n",
      "(6, 1, (0.4, 3.013427972793579))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 305ms/step - loss: 2.3045 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 32ms/step\n",
      "(6, 1, (0.4, 2.9182591438293457))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 305ms/step - loss: 2.3028 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 42ms/step\n",
      "(6, 2, (0.0, 3.1104319095611572))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 442ms/step - loss: 2.1531 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 34ms/step\n",
      "(6, 2, (0.2, 4.2950170040130615))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 495ms/step - loss: 2.2881 - acc: 0.4000\n",
      "5/5 [==============================] - 0s 87ms/step\n",
      "(6, 2, (0.2, 3.877575159072876))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 268ms/step - loss: 2.3083 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 26ms/step\n",
      "(6, 3, (0.0, 2.2972989082336426))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 1s 273ms/step - loss: 2.4083 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 30ms/step\n",
      "(6, 3, (0.2, 2.41554594039917))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 382ms/step - loss: 2.3146 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 35ms/step\n",
      "(6, 3, (0.0, 3.978931188583374))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 472ms/step - loss: 2.3026 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 51ms/step\n",
      "(7, 0, (0.0, 3.9486398696899414))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 316ms/step - loss: 2.5239 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 29ms/step\n",
      "(7, 0, (0.0, 3.2556979656219482))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 313ms/step - loss: 2.3033 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 36ms/step\n",
      "(7, 0, (0.2, 3.2768847942352295))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 372ms/step - loss: 2.3024 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 46ms/step\n",
      "(7, 1, (0.2, 3.5985331535339355))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 341ms/step - loss: 2.3003 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 28ms/step\n",
      "(7, 1, (0.4, 3.1569039821624756))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 499ms/step - loss: 2.3063 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 38ms/step\n",
      "(7, 1, (0.2, 4.672399044036865))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 462ms/step - loss: 2.3044 - acc: 0.2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 37ms/step\n",
      "(7, 2, (0.0, 4.439890146255493))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 365ms/step - loss: 2.5046 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 31ms/step\n",
      "(7, 2, (0.0, 3.491238832473755))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 533ms/step - loss: 2.2978 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 39ms/step\n",
      "(7, 2, (0.0, 4.990422964096069))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 325ms/step - loss: 2.3066 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 43ms/step\n",
      "(7, 3, (0.2, 3.4792640209198))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 3s 511ms/step - loss: 2.3033 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 38ms/step\n",
      "(7, 3, (0.2, 4.90941596031189))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 478ms/step - loss: 2.3006 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 35ms/step\n",
      "(7, 3, (0.0, 5.413500070571899))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 322ms/step - loss: 2.3023 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 39ms/step\n",
      "(8, 0, (0.0, 3.0649631023406982))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 465ms/step - loss: 2.4167 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 54ms/step\n",
      "(8, 0, (0.0, 4.407750129699707))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 380ms/step - loss: 2.3022 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 35ms/step\n",
      "(8, 0, (0.2, 4.2158379554748535))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 343ms/step - loss: 2.3052 - acc: 0.2000\n",
      "5/5 [==============================] - 0s 31ms/step\n",
      "(8, 1, (0.2, 3.1012279987335205))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 410ms/step - loss: 2.3251 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 46ms/step\n",
      "(8, 1, (0.0, 3.666534900665283))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 392ms/step - loss: 2.3049 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 39ms/step\n",
      "(8, 1, (0.0, 4.542107820510864))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 436ms/step - loss: 2.3001 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 68ms/step\n",
      "(8, 2, (0.0, 4.03110408782959))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 307ms/step - loss: 2.0618 - acc: 0.4000\n",
      "5/5 [==============================] - 0s 29ms/step\n",
      "(8, 2, (0.2, 3.4238970279693604))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 357ms/step - loss: 2.3023 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 35ms/step\n",
      "(8, 2, (0.0, 3.4278628826141357))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 340ms/step - loss: 2.3079 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 31ms/step\n",
      "(8, 3, (0.0, 2.7714438438415527))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 453ms/step - loss: 2.0141 - acc: 0.4000\n",
      "5/5 [==============================] - 0s 34ms/step\n",
      "(8, 3, (0.2, 3.432692050933838))\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 2s 417ms/step - loss: 2.3060 - acc: 0.0000e+00\n",
      "5/5 [==============================] - 0s 43ms/step\n",
      "(8, 3, (0.4, 3.969409942626953))\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(layers, start=0):\n",
    "    for j, neuron in enumerate(neurons, start=0):\n",
    "        for k, act in enumerate(activation, start=0):\n",
    "            model = get_model(num_hidden_layers=layer, hidden_size=neuron,activation=act)\n",
    "            #!rm -rf log/sigmoid\n",
    "            #tb_callback = keras.callbacks.TensorBoard(log_dir='./log/', histogram_freq=1,  write_grads=True, write_graph=True, write_images=True)\n",
    "            startFit =time.time()\n",
    "            #time_callback = TimeHistory()\n",
    "            model.fit(X_train, y_train_oh, epochs=1, batch_size=1)\n",
    "            endFit = time.time() - startFit \n",
    "            score, acc = model.evaluate(X_test, y_test_oh,\n",
    "                            batch_size=1)\n",
    "            value = (acc,endFit)\n",
    "            print(i,j,value)\n",
    "            if (k == 'relu'):\n",
    "                reluAcc[i][j] = acc\n",
    "                reluTime[i][j] = endFit\n",
    "            elif (k == 'sigmoid'):\n",
    "                sigTime[i][j] = endFit\n",
    "                sigAcc[i][j] = acc\n",
    "            elif (k == tf.nn.leaky_relu):\n",
    "                leakyAcc[i][j]= acc\n",
    "                leakyTime[i][j] = endFit\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "ax = sns.heatmap(reluTime)\n",
    "print(reluTime[:10,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your visualizations must look similar to these ones:\n",
    "\n",
    "![alt text](./Images/lab_vanishing_01.png)\n",
    "![alt text](./Images/lab_vanishing_02.png)\n",
    "![alt text](./Images/lab_vanishing_03.png)\n",
    "![alt text](./Images/lab_vanishing_04.png)\n",
    "![alt text](./Images/lab_vanishing_05.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
